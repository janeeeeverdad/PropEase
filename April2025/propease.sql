-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Apr 27, 2025 at 07:39 AM
-- Server version: 10.4.32-MariaDB
-- PHP Version: 8.2.12

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `propease`
--

-- --------------------------------------------------------

--
-- Table structure for table `files`
--

CREATE TABLE `files` (
  `id` int(11) NOT NULL,
  `user_email` varchar(255) NOT NULL,
  `file_name` varchar(255) NOT NULL,
  `file_path` varchar(255) NOT NULL,
  `upload_date` timestamp NOT NULL DEFAULT current_timestamp(),
  `extracted_text` longtext NOT NULL,
  `speech_transcript` text NOT NULL,
  `analysis_json` longtext NOT NULL,
  `archived` tinyint(1) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `files`
--

INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(97, 'mia.villarica@gmail.com', 'NEWG1.PDF', 'uploads/bd50884a1a12401fa8e575dd79ff76fc.PDF', '2025-04-23 08:38:15', '                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                     Concept Paper                                  \n                                                                                    \n           A. BasicInformation                                                      \n                                                                                    \n           Project Title:                                                           \n           GreeneryRecognition and ObservationOptimization Tool(GROOT): A MobileApplication\n           for DigitalIdentificationof MajorPests andDiseasesin SelectedIndigenousTreesinSta.\n           Maria,Laguna                                                             \n                                                                                    \n           Topic: ComputerVision, Forestry                                          \n                                                                                    \n           Proponent:DELA CRUZ, ARIANEJOYM. |GONZALODO, PAUL JOSHUAF.               \n           VILLADIEGO, TRISH P.                                                     \n                                                                                    \n                                                                                    \n           B.Technical Description                                                  \n                                                                                    \n                                                                                    \n           An application that is easier and gives information about pests and diseases in selected\n           indigenous trees (Almon, Mayapis, Narra, Tanguile, and White Lauan). The present manual\n           methods, such physical observation and pen and paper recording. To improve their current\n           process, our answer is a portable gadget or user-friendly mobile application with a large\n           database and cutting-edge picture recognition technology. By facilitating rapid species\n           detection and offering comprehensive information on illnesses and pests, this application\n           completely transforms the identification of major pests and diseases in selected indigenous\n           trees.                                                                   \n                                                                                    \n           By scanning bark or foliage, users can access vital information, enhancing monitoring efforts\n           and fosteringastronger connection withnature.Thisinnovationbenefits forestryprofessionals\n                                                                                    \n           by improving workflows and enriches forestry education for students. The application offers\n           detailed profiles of trees, including common and scientific names, habitats, growth patterns,\n           and ecological significance. It also diagnoses pests and diseases, offering management and\n           treatment recommendations.                                               \n                                                                                    \n           Through technology and environmental administration, we empower communities to protect\n           local woodlands and support conservation efforts, leading the way for a more sustainable\n           future.                                                                  \n                                                                                    \n                                                                                    \n           Statement of the Problem:                                                \n                                                                                    \n           To address the challenges faced by the Department of Environment and Natural Resources\n           (DENR) in effectively monitoring and preservingtree species,especiallyinthe contextoftree\n           cutting activities and ecosystem conservation, we proposed the development of a specialized\n           application by virtualizing the recordingprocess andintegratingtechnical termsto identifythe\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           signs andsymptoms of pests, anddiseases inselected indigenoustrees.This studywill address\n           thefollowing:                                                            \n                                                                                    \n             1. What arethecommonpestsinforest plantation treesinSanta Maria,Laguna?\n                                                                                    \n             2. What arethecommondiseases offorest plantation treesinSanta Maria,Laguna?\n             3. What applicationisused toidentifycommon pestsanddiseases?           \n             4. Howcantheapplicationprovideassistance onidentifyingmajor pestsanddiseases?\n             5. Howeffective GROOTapplication inidentifying the majorpestsanddiseases in\n                selected indigenous treesin SantaMaria, Laguna?                     \n                                                                                    \n                                                                                    \n           Objectives: GeneralandSpecific GeneralObjective:                         \n           This studyisambitiousandhas thepotential tobeagame-changer for forestry,ecology,and\n           evencitizenscience.Thegoalis todevelop auser-friendlyapplication toeasilyidentify major\n           pestsand diseasesin selectedindigenoustrees inSta.Maria, Laguna.         \n                                                                                    \n           Specifically,it aimsto:                                                  \n                                                                                    \n             1. Collect imagesshowcasingcommon pestsaffectingthespecifiedtree specieslike,\n                Ambrosia Beetle,Ips Calligraphus,Lymantria, andTeakDefoliator Mealybug,\n                showcasingdifferentstages ofinfestationand associateddamagefromERDBand\n                                                                                    \n                CFNR.                                                               \n             2. Collect imagesshowcasingcommon diseases affectingthespecifiedtreespecies like\n                leaf blight,leaf spot, powderymildew, gall rust,andblack raydisease fromERDB and\n                CFNR.                                                               \n                                                                                    \n             3. Developan application thatutilizes YOLO,apre-trained Convolutional Neural\n                Network,for advanced objectdetectionandrecognition.                 \n             4. Developa mobileapplication thatwouldprovidea platform toidentifymajor pestsand\n                diseases inselected indigenoustreesthrough the datagathered.        \n             5. Determine theaccuracyof theoutput ofthe imageprocessingmodel.       \n           Howdid otherssolvethe problem?                                           \n             1. Theresearchers addressedthe problemofbark identification byutilizinga combination\n                of techniques. They applied random square cropping with thresholding to the images\n                before inputting them into the convolutional neural networks (CNNs). This approach\n                involved randomly selecting a pixel length in the range of 40-60% of the total width\n                                                                                    \n                for each crop, and then randomly sampling the position of the cropping square.\n                Additionally, they used a data augmentation process called \'RandAugment\' to increase\n                the training data by giving slight modifications. This involved randomly selecting a\n                predefined number of augmentation functions and applying them with a randomly\n                sampled magnitude from a predefined range. These techniques aimed to minimize the\n                loss of bark features, provide flexible cropping,andincreasethe trainingdata for more\n                robust model training.The researchers addressed the problem of bark identification by\n                                                                                    \n                utilizing a combination of techniques. They applied random square cropping with\n                thresholding to the images before inputting them into the convolutional neural\n                networks (CNNs). This approach involved randomly selecting a pixel length in the\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                range of 40-60% of the total width for each crop, and then randomly sampling the\n                                                                                    \n                position of the cropping square. Additionally, they used a data augmentation process\n                called \'RandAugment\' to increase the training data bygiving slightmodifications.This\n                involved randomly selecting a predefined number of augmentation functions and\n                applying them with a randomly sampled magnitude from a predefined range. These\n                techniques aimed to minimize the loss of bark features, provide flexible cropping,and\n                increase the training data for morerobustmodel training.Kim,T. K., Hong, J.,Ryu,D.,\n                Kim, S., Byeon, S. Y., Huh, W., ... & Kim, H. S. (2022). Identifying and extracting\n                                                                                    \n                bark key features of 42 tree species using convolutional neural networks and class\n                activation mapping. Scientific Reports,12(1), 772.4                 \n             2. Researchers utilized threevisualizationmethodsto tacklethechallenge ofvisualizing\n                thecorrelationbetween treebark characteristicsandthe mechanismsofdeep\n                convolutionalneural networks.Firstly,theyemployedIntegrated Gradients,which\n                attributes adeepnetwork\'sprojection toits input byinvokingthe gradientoperator,\n                offering awidelyapplicableapproach withastrongtheoretical foundation.Secondly,\n                Smooth GradCAM++ combinedwithGrad-CAM andSmoothGrad wasutilized,    \n                modelingand visualizingasubsetof featuremaps orneuronsat eachneural network\n                level.This technique producedhierarchicalfeatureseffectivelyincorporating visual\n                appeal,localization,and object-likecaptureelements inthe outputvisualization.\n                Lastly,Deep FeatureDecomposition providedinsightintoclusteringpatterns inthe\n                featurespace,presenting results asheat maps. Itsobjectivewasto explainthe\n                                                                                    \n                predictionsof deepconvolutional neuralnetworksbyhighlightingthe contributing\n                regions or features.These visualizationmethodscollectivelyshed lightonthe\n                correlationbetweenthe biologicalcharacteristicsof varioustreespecies andthe visual\n                mechanismsof deepconvolutional neuralnetworks,offering valuableinsightsinto the\n                intricate relationship betweennatural patterns andmachinelearning processes.Cui,Z.,\n                Li, X., Li, T.,& Li, M.(2023). Improvementand Assessmentof Convolutional Neural\n                Networkfor Tree SpeciesIdentificationBased onBarkCharacteristics.Forests,14(7),\n                1292.                                                               \n             3. Theresearchers solvedthe problemofestimatingtree diameterandcircumference\n                usingcomputervision (CV)technologybydevelopinganon-contact tree     \n                circumferencemonitoring system.Theyutilized asmartphone camera incorporated\n                with CVtechnology asanalternative low-costtool. Thesystemwasdesignedto\n                accelerate andincreasethe effectivenessandefficiencyinmeasuring treediameterand\n                circumferencewithin plantation areas.Thestudy focusedonhomogeneousforests,\n                suchasrubber and Albiziaplantations,and utilizedadvancedtechnologytoachieve\n                proper identification,tracking, andmeasurementof treetargets for further image\n                processing. Theresearchershypothesized thatthe useof CVtechnologycan providean\n                                                                                    \n                effective andefficient solutionfor measuring treediameterandcircumference in\n                plantationareas.Putra, B.T. W.,Ramadhani, N. J.,Soedibyo,D. W.,Marhaenanto,B.,\n                Indarto, I., & Yualianto, Y.(2021). Theuse ofcomputer vision toestimatetree\n                diameterand circumference inhomogeneousandproduction forestsusinga  \n                non-contact method. ForestScience andTechnology,17(1), 32-38.       \n             4. Theresearchers addressedthe issueofclassimbalance intheir datasetbyallowing\n                considerable overlap betweenpatches for classeswith fewerimages.Thisapproach,\n                known asminority classoversampling,has beenshowntobe effectivefor training\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                Convolutional Neural Networks (CNNs)inthe presenceof classimbalance.\n                Additionally,theycreateda datasettotrain andevaluatethe genus-levelclassifierby\n                                                                                    \n                taking asubsetof training andtesting patchesinsuch awaythat thespecies image\n                proportions withina genuswere respected.Thisensuredthat the modelwas trainedand\n                evaluatedwith abalancedrepresentationof specieswithin each genus.Ravindran,P.,\n                Costa, A.,Soares,R., &Wiedenhoeft,A. C. (2018). Classificationof CITES-listed and\n                otherneotropicalMeliaceaewood imagesusing convolutionalneural networks.Plant\n                methods,14,1-10.                                                    \n                                                                                    \n             5. Theresearchers solvedthe problembyadopting animage-capturingprocedure froma\n                previous studyandcapturing 20scenesfrompoints at18º intervalsalong concentric\n                circular pathsaround thetree trunk.Theyensured aminimumof 50%coverage\n                between anysequential pairofimages andusedred flagtapestomarkthe locationsof\n                pictures takenalongthe circularpath.Additionally,they set thedistance betweenthe\n                photo point andthe treetrunk to2mandcalibrated thecamera elevationat each photo\n                point usinga measuringstaff. Theyalsoprinted andinstalled 16-bit digitmarkerson\n                theedgeof thetreetrunk tooptimize thephoto alignmentprogress. Furthermore,they\n                measured individualtreeDBH(diameter atbreast height)using acaliper at18°\n                intervalsalongconcentric circularpaths aroundthe treetrunk tovalidate the3D\n                reconstruction fittingalgorithms.The2D imageswere alignedusing Agisoft\n                Metashape Professional,anda densepoint cloudwas generated.Theextracted3D\n                                                                                    \n                point clouddata were processedusing ahigh-performance computingsystem,andthe\n                processtook around 20minutesfor each treemeasurement.Woo, H.,Kim, I.,&Choi,\n                B.(2021). ComputerVision Techniquesin ForestInventoryAssessment:Improving\n                Accuracy of TreeDiameterMeasurement UsingSmartphoneCameraand        \n                Photogrammetry.Sensors&Materials, 33.                               \n                                                                                    \n             6. Theresearchers solvedthe problemofpest detection throughimageanalysis by\n                conductingexperimentsin paddyfieldsusing anetwork ofwireless camerasandsticky\n                traps tocaptureinsectpests.Theythen processed thecaptured imagesusinga local\n                machine equippedwithan Inteli3processorand4GB RAM.Thearchitecturaldesign\n                of theproposedsystemwas crucialin facilitatingthe imageacquisition and\n                pre-processing.Theresearchersalso utilized imagepre-processingtechniquesto\n                convert RGBimagesinto grayscaleimages,making themethod moreefficient.\n                Additionally,theyemployed adetectionmechanism that comparedthe pixel valuesof\n                successivecaptured imagestodetectdifferences andidentify insectpests.Miranda, J.\n                L., Gerardo,B.D.,& TanguiligIII,B. T.(2014). Pest detectionand extractionusing\n                imageprocessing techniques.Internationaljournal ofcomputer andcommunication\n                engineering,3(3), 189-192.                                          \n                                                                                    \n             7. Theresearchers addressedthe issuebycollectingadditional imagesof palmdiseases\n                usingdifferent cameras andat differenttimesof day,includingnighttimewithflash.\n                                                                                    \n                Theymanually croppedthe regionsof interestintheimages topreserveasmuch\n                information aspossible,andthen appliedimageaugmentation techniquessuch as\n                rotation, flipping, andbrightness adjustment, resultingin alargerdataset for each\n                disease.Theyalsoexperimented withdifferentclassificationalgorithmssuch as\n                LinearSVCfor the SupportVectorMachine (SVM)model, whichachieved a93%\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                accuracy rate.Additionally,they enhancedtheConvolutional NeuralNetwork(CNN)\n                model andconductedexperimentsto testthemodels\'ability todetectleafspots and\n                                                                                    \n                blight spotsdiseasesunder variouscircumstances.Alaa, H., Waleed,K., Samir,M.,\n                Tarek,M., Sobeah, H.,& Salam,M. A.(2020). An intelligentapproachfor detecting\n                palm treesdiseasesusing imageprocessingand machinelearning.Int. J.Adv.Comput.\n                Sci.Appl,11(7), 434-441.                                            \n                                                                                    \n                                                                                    \n           Howdo youintend to solvethe problem?                                     \n           A mobile application aims to revolutionize environmental management by identifying major\n                                                                                    \n           pests and diseases in selected Indigenous Trees. The application uses advanced image\n                                                                                    \n           recognition algorithms to provide insightsinto majorpestsanddiseases inselected indigenous\n           trees.Theapplication alsoserves asaplatform for community engagement,fosteringasenseof\n                                                                                    \n           ownershipand responsibility towardsenvironmentalconservation.            \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           Targetusers /Beneficiaries:(Describe eachBeneficiary)                    \n                                                                                    \n           This Study will bebeneficialfor Researchers, agriculturistandforester making it convenient\n           to major pestsand diseases inselected indigenoustrees providing insightsand moredetails\n           aboutthemajor pestsanddiseasesin selectedindigenoustrees.                \n                                                                                    \n                                                                                    \n           Significance of study:                                                   \n                                                                                    \n           Theproposedmobileapplicationsareanessentialapplication for bothcommon people and\n           environmental enthusiasts.It offers anextensive amountof informationregarding majorpests\n                                                                                    \n           and diseasesin selectedindigenoustrees, accommodatesarangeof learningstyles,and creates\n           afeeling of communityamongthose who sharesimilar interests.Thesoftware helps usersget\n           abetter knowledgeof theirrelationshipwith natureandtheirresponsibility asenvironmental\n           stewards,actingasa catalystfor personal developmentandself-discovery.    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n          SurveyMatrix                                                              \n                                                                                    \n           TitleofStudy        Purpose           Technology          Year           \n           Identifyingandextractingbark Thestudyinvestigatesthe convolutionalneuralnetworks 2022\n           keyfeaturesof42treespecies effectivenessofcomputer classactivationmapping\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           usingconvolutionalneural visionmachinesinidentifying                     \n           networksandclassactivation treebarksusinglarge-scale                     \n           mapping             barkimagedatasets,comparing                          \n                               CNNalgorithms(VGG-16and                              \n                               EfficientNet)andidentifying                          \n                               diagnosticfeatures.                                  \n           ImprovementandAssessmentof Thestudyexploresthe convolutionalneuralnetworks 2023\n           ConvolutionalNeural relationshipbetweentreebark ConvNeXtnetwork          \n           NetworkforTreeSpecies characteristicsanddeep BarkNetV2                   \n           IdentificationBasedon convolutionalneuralnetworks,                       \n           BarkCharacteristics aimingtoimprovetreespecies                           \n                               identificationefficiencyand                          \n                               forestresourcemanagement.                            \n           ClassificationofCITES-listed Thepurposeofthestudywas computervisionclassification 2018\n           andother            todevelopacomputervision model                       \n           neotropicalMeliaceaewood classificationmodelusingdeep deepconvolutionalneural\n           imagesusing         convolutionalneuralnetworks networks                 \n           convolutionalneuralnetworks toidentifyneotropical                        \n                               Meliaceaewoodspecies.This                            \n                               wasaimedatprovidinga                                 \n                               reliable,consistent,and                              \n                               cost-effectivefieldscreening                         \n                               methodforeffectiveglobal                             \n                               scaleenforcementof                                   \n                               internationaltreatiessuchas                          \n                               theConventiononthe                                   \n                               InternationalTradein                                 \n                               EndangeredSpecies(CITES)                             \n                               ornationallawsgoverning                              \n                               timbertradeandimports.The                            \n                               studyfocusedon10                                     \n                               neotropicalspeciesinthe                              \n                               familyMeliaceae,including                            \n                               CITES-listedspecies,withthe                          \n                               goalofachievingspecies-level                         \n                               discrimination,whichis                               \n                               essentialforcombatingillegal                         \n                               loggingandensuringthe                                \n                               protectionofendangeredwood                           \n                               species.                                             \n           PestDetectionandExtraction Thepurposeofthestudyisto ImageProcessing 2014 \n           UsingImageProcessing developaninnovativedecision                         \n           Techniques          supportsystemforearlypest                            \n                               detectioninagriculturalfields.                       \n                               Theresearchersaimtouse                               \n                               imageanalysisandscene                                \n                               interpretationfrom                                   \n                               multi-cameradatatoidentify                           \n                               insectpestsinrealtime.The                            \n                               goalistoreducepesticideuse                           \n                               byenablingearlydetectionof                           \n                               pestsonplantorganssuchas                             \n                               leaves.Thestudyalsofocuses                           \n                               oncreatingasystemthatcan                             \n                               easilyadapttodifferent                               \n                               categoriesofbioaggressors,                           \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                               contributingtomoreefficient                          \n                               andsustainablepest                                   \n                               managementpracticesin                                \n                               agriculture.                                         \n           AnIntelligentApproachfor Thepurposeofthestudyisto Thermalimaging 2020    \n           DetectingPalmTrees  detectRedPalmWeevil ImageProcessing                  \n           DiseasesusingImageProcessing (RPW)infestationinpalm ConvolutionalNeuralNetwork\n           andMachine          treesusingthermalimaging. SupportVectorMachine       \n           Learning            Thestudyaimstouseuncooled MobileApplication          \n                               infraredthermalcamerasand                            \n                               microbolometersensorsto                              \n                               captureimagesofpalmtrees,                            \n                               analyzetheimagesusing                                \n                               softwaretoassesswaterstress                          \n                               andtemperaturerates,and                              \n                               identifyinfectedtreesbasedon                         \n                               theobserveddifferencesin                             \n                               temperatureandwaterstress.                           \n                               Thestudyalsoexplorestheuse                           \n                               ofmachinelearningmodels                              \n                               suchasSupportVector                                  \n                               Machines(SVM)and                                     \n                               ConvolutionalNeural                                  \n                               Networks(CNN)for                                     \n                               classificationanddetectionof                         \n                               RPWinfestationinpalmtrees.                           \n          Gap Analysis                                                              \n               TITLE            DESCRIPTION         SCOPE/TECHNOLOGY  YEAR          \n                                     TECHNOLOGY                                     \n           Identifyingand                          convolutionalneuralnetworks 2022 \n           extractingbarkkey The research delving into bark classactivationmapping  \n           featuresof42tree identification using convolutional neural               \n                         networks (CNNs) alongside class                            \n           speciesusing                                                             \n                         activation mapping (CAM) yieldedseveral                    \n           convolutionalneural                                                      \n                         significant findings. Firstly, CNNs                        \n           networks                                                                 \n                         exhibited remarkable proficiency in                        \n           andclassactivation                                                       \n                         identifying the barks of 42 distinct tree                  \n           mapping                                                                  \n                         species, achieving accuracy rates                          \n                         surpassing 90%. Notably, comparative                       \n                         analysis between the two employed CNN                      \n                         models, namely VGG-16andEfficientNet,                      \n                         revealed onlymarginalvariancesinoverall                    \n                         accuracy. The study identified diagnostic                  \n                         keys for each species, correlating them                    \n                         with distinct bark features such asblisters,               \n                         stripes, lenticels of various shapes, and                  \n                         crevices. Interestingly, the two CNN                       \n                         models demonstrated discrepancies in the                   \n                         quality of diagnostic features, with the                   \n                         older model presenting more general yet                    \n                         well-fitting patterns,whilethenewer,more                   \n                         intricate model indicatedlocalizedpatterns                 \n                         less pertinent to bark identification.                     \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                         Furthermore, CNNs showcased the                            \n                         capability to predict untrained species                    \n                         within the correct genus and family by                     \n                         approximately 41.98% and 48.67%,                           \n                         respectively. Thesefindingsunderscorethe                   \n                         potential of CNNs and CAM in not only                      \n                         accurately identifying and visualizing                     \n                         essential bark traits but also in their                    \n                         broaderapplicabilitytootherplantorgans.                    \n           Improvementand                          convolutionalneuralnetworks 2023 \n           Assessmentof  The study employed three distinct ConvNeXtnetwork          \n           Convolutional visualization methods, namely Integrated BarkNetV2         \n                         Gradients, Smooth Grad CAM++, and                          \n           Neural                                                                   \n                         Deep Feature Decomposition, to elucidate                   \n           NetworkforTree                                                           \n                         the network workflow. Through these                        \n           Species                                                                  \n                         methods, researchers identified specific                   \n           IdentificationBased                                                      \n                         features in tree bark images, including                    \n           on                                                                       \n                         grooves, cracks, and lenticels, which the                  \n           BarkCharacteristics neural networkweightsselectivelyfocused              \n                         on. This selective attention paralleled                    \n                         human recognitionoftreespeciesbasedon                      \n                         bark images, enhancing our understanding                   \n                         of the network\'s decision-making process.                  \n                         Moreover, the visualization results                        \n                         obtained through deep feature                              \n                         decomposition and semantic segmentation                    \n                         exhibited similarities,offeringinsightsinto                \n                         how the network identifies different tree                  \n                         species based on barkimageblocks.These                     \n                         findings underscored the correlation                       \n                         between the biological characteristics of                  \n                         diverse tree species and the visual                        \n                         mechanisms of deep convolutional neural                    \n                         networks, providing valuable insights into                 \n                         both the network\'s functioning and its                     \n                         relationship with natural features. Overall,               \n                         these outcomes shedlightontheprinciples                    \n                         and characteristics of the network                         \n                         workflow and its correlation with the                      \n                         biological features of tree species,                       \n                         advancing our understanding of both                        \n                         machine learning processes and natural                     \n                         phenomena.                                                 \n           Classificationof The study aimed to develop machine computervisionclassification 2018\n           CITES-listedandother learning models for wood identification model       \n           neotropicalMeliaceae based on images of transverse surfaces of deepconvolutionalneural\n           woodimagesusing wood specimens. The researcherscaptured networks         \n           convolutionalneural high-resolution images of wood                       \n           networks      specimens, annotated them for various                      \n                         characteristics, and then created a dataset                \n                         for training and testing the machine                       \n                         learning models. Theyspecificallyfocused                   \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                         on distinguishing between species-level                    \n                         and genus-level accuracy, recognizing the                  \n                         traditionallimitationofwoodidentification                  \n                         at the specieslevel.Thestudyinvolvedthe                    \n                         creation of patch datasets, training of                    \n                         convolutional neural network (CNN)                         \n                         models, and evaluation of the model                        \n                         accuracies. The models were trained using                  \n                         the VGG16 network as feature extractors                    \n                         and the custom top-level layers were                       \n                         trained using stochastic gradient descent                  \n                         and the Adam optimizer. The study also                     \n                         included thecreationofconfusionmatrices                    \n                         and training curves for the models to                      \n                         analyzetheerrorsmadebythemodels.                           \n           PestDetectionand The study presents the development of an ImageProcessing 2014\n           ExtractionUsing automatic detection and extraction system                \n           ImageProcessing for insectpestsinpaddyfieldsusingimage                   \n           Techniques    processingtechniques.Theauthorssetupa                      \n                         network of wireless cameras and sticky                     \n                         traps in the paddy fields to capture insect                \n                         pests. They used CISCO Linksys                             \n                         Wireless-G Internet Home Monitoring                        \n                         Cameras to capture images at 10 frames                     \n                         per second with 8-megapixel resolution.                    \n                         The captured images wereprocessedusing                     \n                         a local machine equipped with an Intel i3                  \n                         processorand4GBRAM.                                        \n                         The study utilized image pre-processing                    \n                         techniques toenhancethecapturedimages,                     \n                         including converting RGB images into                       \n                         grayscale using a specific formula. The                    \n                         authorsalsodevelopedanalgorithmforthe                      \n                         detection of pests in the images, involving                \n                         the extraction of isolated patterns of                     \n                         interestbasedonrobustfeatureextraction.                    \n                         The experimental results of the proposed                   \n                         system showed its efficiency in detecting                  \n                         and extracting insect pests in the paddy                   \n                         fields. The system was tested over five                    \n                         consecutive days, and the results of the                   \n                         detected images of different insect pests                  \n                         wererecordedandpresentedinatable.                          \n                         The study aims tocontributetothefieldof                    \n                         agricultural research byprovidingasimple                   \n                         yet efficient system for automatic pest                    \n                         detection and extraction using image                       \n                         processingtechniques.                                      \n           AnIntelligent Thestudyinvolvedtheuseofadataset Thermalimaging 2020       \n           ApproachforDetecting fromKagglecontaining91,360imagesfor ImageProcessing \n           PalmTrees     leafspotsandblightspotsdiseases.Dueto ConvolutionalNeuralNetwork\n                         thelowvariationintheimages,the SupportVectorMachine        \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           DiseasesusingImage originalimageswereanalyzedbefore MobileApplication    \n           Processingand augmentation,resultingintheselectionof                     \n           Machine       35leafspotsimages,40imagesforblight                        \n           Learning      spots,and50morepalmimagesforeach                           \n                         disease.Theoriginalimageswere                              \n                         manuallycroppedtopreservetheinfected                       \n                         partsandthenresizedto224*224input                          \n                         size.Imageaugmentationtechniquessuch                       \n                         asrotation,flipping,andadjusting                           \n                         brightnesswereapplied,resultingin5250                      \n                         imagesforeachdisease.Thestudyalso                          \n                         involvedtheuseofinfraredthermal                            \n                         camerastocaptureimagesofpalmtreesin                        \n                         ordertodetectwaterstressandtheeffects                      \n                         ofRedPalmWeevil(RPW)infestation.                           \n                         Furthermore,thestudyutilizeda                              \n                         ConvolutionalNeuralNetwork(CNN)                            \n                         modelbuiltonthepre-structuredVGG16                         \n                         Networkforefficientfeatureextraction                       \n                         anddiseaseclassification.                                  \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      A. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Project Title:\\nGreenery Recognition and Observation Optimization Tool (GROOT): A Mobile Application\\nfor Digital Identification of Major Pests and Diseases in Selected Indigenous Trees in Sta.\\nMaria, Laguna\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Topic: Computer Vision, Forestry\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Proponent: DELA CRUZ, ARIANE JOY M.\\n| GONZALODO, PAUL JOSHUA F.\\nVILLADIEGO, TRISH P.\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  B. Technical Description\n6  An\\napplication\\nthat\\nis\\neasier\\nand gives\\ninformation about pests\\nand\\ndiseases\\nin\\nselected\\nindigenous trees (Almon, Mayapis, Narra, Tanguile, and White Lauan). The present manual\\nmethods,\\nsuch physical observation and pen and paper\\nrecording. To improve their current\\nprocess, our\\nanswer\\nis\\na\\nportable gadget\\nor\\nuser-friendly mobile application with a large\\ndatabase\\nand\\ncutting-edge\\npicture\\nrecognition\\ntechnology. By\\nfacilitating\\nrapid\\nspecies\\ndetection and\\noffering comprehensive\\ninformation on\\nillnesses\\nand pests,\\nthis\\napplication\\ncompletely transforms\\nthe identification of major pests and diseases in selected indigenous\\ntrees.\\nBy scanning bark or foliage, users can access vital\\ninformation, enhancing monitoring efforts\\nand fostering a stronger connection with nature. This innovation benefits forestry professionals\\nby improving workflows and enriches forestry education for students. The application offers\\ndetailed profiles of\\ntrees,\\nincluding common and scientific names, habitats, growth patterns,\\nand ecological\\nsignificance.\\nIt also diagnoses pests and diseases, offering management and\\ntreatment recommendations.\\nThrough technology and environmental administration, we empower communities to protect\\nlocal woodlands\\nand\\nsupport conservation efforts,\\nleading the way for a more sustainable\\nfuture.\n7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Statement of the Problem:\\nTo address\\nthe challenges\\nfaced by the Department of Environment and Natural Resources\\n(DENR) in effectively monitoring and preserving tree species, especially in the context of tree\\ncutting activities and ecosystem conservation, we proposed the development of a specialized\\napplication by virtualizing the recording process and integrating technical terms to identify the\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          signs and symptoms of pests, and diseases in selected indigenous trees. This study will address\\nthe following:\\n1. What are the common pests in forest plantation trees in Santa Maria, Laguna?\\n2. What are the common diseases of forest plantation trees in Santa Maria, Laguna?\\n3. What application is used to identify common pests and diseases?\\n4.\\nHow can the application provide assistance on identifying major pests and diseases?\\n5.\\nHow effective GROOT application in identifying the major pests and diseases in\\nselected indigenous trees in Santa Maria, Laguna?\n1                                                                                                    Objectives: General and Specific General Objective:\\nThis study is ambitious and has the potential to be a game-changer for forestry, ecology, and\\neven citizen science. The goal is to develop a user-friendly application to easily identify major\\npests and diseases in selected indigenous trees in Sta. Maria, Laguna.\\nSpecifically, it aims to:\\n1.\\nCollect images showcasing common pests affecting the specified tree species like,\\nAmbrosia Beetle, Ips Calligraphus, Lymantria, and Teak Defoliator Mealybug,\\nshowcasing different stages of infestation and associated damage from ERDB and\\nCFNR.\\n2.\\nCollect images showcasing common diseases affecting the specified tree species like\\nleaf blight, leaf spot, powdery mildew, gall rust, and black ray disease from ERDB and\\nCFNR.\\n3.\\nDevelop an application that utilizes YOLO, a pre-trained Convolutional Neural\\nNetwork, for advanced object detection and recognition.\\n4.\\nDevelop a mobile application that would provide a platform to identify major pests and\\ndiseases in selected indigenous trees through the data gathered.\\n5.\\nDetermine the accuracy of the output of the image processing model.\n2  How did others solve the problem?\\n1.\\nThe researchers addressed the problem of bark identification by utilizing a combination\\nof\\ntechniques. They applied random square cropping with thresholding to the images\\nbefore inputting them into the convolutional neural networks (CNNs). This approach\\ninvolved randomly selecting a pixel\\nlength in the range of 40-60% of the total width\\nfor\\neach\\ncrop,\\nand\\nthen\\nrandomly\\nsampling\\nthe position\\nof\\nthe\\ncropping square.\\nAdditionally,\\nthey used a data augmentation process called \'RandAugment\'\\nto increase\\nthe training data by giving slight modifications. This involved randomly selecting a\\npredefined number\\nof\\naugmentation functions\\nand applying them with a randomly\\nsampled magnitude from a predefined range. These techniques aimed to minimize the\\nloss of bark features, provide flexible cropping, and increase the training data for more\\nrobust model\\ntraining.The researchers addressed the problem of bark identification by\\nutilizing\\na\\ncombination of\\ntechniques. They\\napplied random square cropping with\\nthresholding\\nto\\nthe\\nimages\\nbefore\\ninputting\\nthem into\\nthe\\nconvolutional\\nneural\\nnetworks\\n(CNNs). This approach involved randomly selecting a pixel\\nlength in the\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n0                                                                                                                          accuracy rate. Additionally, they enhanced the Convolutional Neural Network (CNN)\\nmodel and conducted experiments to test the models\' ability to detect leaf spots and\\nblight spots diseases under various circumstances.Alaa, H., Waleed, K., Samir, M.,\\nTarek, M., Sobeah, H., & Salam, M. A. (2020). An intelligent approach for detecting\\npalm trees diseases using image processing and machine learning. Int. J. Adv. Comput.\\nSci. Appl, 11(7), 434-441.\n1                                                                                          How do you intend to solve the problem?\\nA mobile application aims to revolutionize environmental management by identifying major\\npests\\nand\\ndiseases\\nin\\nselected\\nIndigenous Trees. The\\napplication\\nuses\\nadvanced\\nimage\\nrecognition algorithms to provide insights into major pests and diseases in selected indigenous\\ntrees.The application also serves as a platform for community engagement, fostering a sense of\\nownership and responsibility towards environmental conservation.\n2                                                                                                                                                                                                                                                                     Target users / Beneficiaries:(Describe each Beneficiary)\\nThis Study will be beneficial for Researchers, agriculturist and forester making it convenient\\nto major pests and diseases in selected indigenous trees providing insights and more details\\nabout the major pests and diseases in selected indigenous trees.\n3  Significance of study:\\nThe proposed mobile applications are an essential application for both common people and\\nenvironmental enthusiasts. It offers an extensive amount of information regarding major pests\\nand diseases in selected indigenous trees, accommodates a range of learning styles, and creates\\na feeling of community among those who share similar interests. The software helps users get\\na better knowledge of their relationship with nature and their responsibility as environmental\\nstewards, acting as a catalyst for personal development and self-discovery.\n\n                                                                                                                              0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1                                                                           2     3\n0                                                            using convolutional neural\\nnetworks and class activation\\nmapping                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 vision machines in identifying\\ntree barks using large-scale\\nbark image datasets, comparing\\nCNN algorithms (VGG-16 and\\nEfficientNet) and identifying\\ndiagnostic features.                                                                                  \n1  Improvement and Assessment of\\nConvolutional Neural\\nNetwork for Tree Species\\nIdentification Based on\\nBark Characteristics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The study explores the\\nrelationship between tree bark\\ncharacteristics and deep\\nconvolutional neural networks,\\naiming to improve tree species\\nidentification efficiency and\\nforest resource management.                  convolutional neural networks\\nConvNeXt network\\nBarkNetV2  2023\n2            Classification of CITES-listed\\nand other\\nneotropical Meliaceae wood\\nimages using\\nconvolutional neural networks  The purpose of the study was\\nto develop a computer vision\\nclassification model using deep\\nconvolutional neural networks\\nto identify neotropical\\nMeliaceae wood species. This\\nwas aimed at providing a\\nreliable, consistent, and\\ncost-effective field screening\\nmethod for effective global\\nscale enforcement of\\ninternational treaties such as\\nthe Convention on the\\nInternational Trade in\\nEndangered Species (CITES)\\nor national laws governing\\ntimber trade and imports. The\\nstudy focused on 10\\nneotropical species in the\\nfamily Meliaceae, including\\nCITES-listed species, with the\\ngoal of achieving species-level\\ndiscrimination, which is\\nessential for combating illegal\\nlogging and ensuring the\\nprotection of endangered wood\\nspecies.  computer vision classification\\nmodel\\ndeep convolutional neural\\nnetworks  2018\n3                                                             Pest Detection and Extraction\\nUsing Image Processing\\nTechniques                                                                                                                                                                                                                                                                            The purpose of the study is to\\ndevelop an innovative decision\\nsupport system for early pest\\ndetection in agricultural fields.\\nThe researchers aim to use\\nimage analysis and scene\\ninterpretation from\\nmulti-camera data to identify\\ninsect pests in real time. The\\ngoal is to reduce pesticide use\\nby enabling early detection of\\npests on plant organs such as\\nleaves. The study also focuses\\non creating a system that can\\neasily adapt to different\\ncategories of bioaggressors,                                                            Image Processing  2014\n\n                                                                                                           0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1                                                                                                            2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  contributing to more efficient\\nand sustainable pest\\nmanagement practices in\\nagriculture.                                                                                                                   \n1  An Intelligent Approach for\\nDetecting Palm Trees\\nDiseases using Image Processing\\nand Machine\\nLearning  The purpose of the study is to\\ndetect Red Palm Weevil\\n(RPW) infestation in palm\\ntrees using thermal imaging.\\nThe study aims to use uncooled\\ninfrared thermal cameras and\\nmicrobolometer sensors to\\ncapture images of palm trees,\\nanalyze the images using\\nsoftware to assess water stress\\nand temperature rates, and\\nidentify infected trees based on\\nthe observed differences in\\ntemperature and water stress.\\nThe study also explores the use\\nof machine learning models\\nsuch as Support Vector\\nMachines (SVM) and\\nConvolutional Neural\\nNetworks (CNN) for\\nclassification and detection of\\nRPW infestation in palm trees.  Thermal imaging\\nImage Processing\\nConvolutional Neural Network\\nSupport Vector Machine\\nMobile Application  2020\n\n                                                                                                                                         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1                                                        2     3\n0                                                                                               TITLE\\nDESCRIPTION\\nSCOPE/TECHNOLOGY\\nYEAR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n1                                                                                                                               TECHNOLOGY                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n2  Identifying and\\nextracting bark key\\nfeatures of 42 tree\\nspecies using\\nconvolutional neural\\nnetworks\\nand class activation\\nmapping  The\\nresearch\\ndelving\\ninto\\nbark\\nidentification\\nusing\\nconvolutional\\nneural\\nnetworks\\n(CNNs)\\nalongside\\nclass\\nactivation mapping (CAM) yielded several\\nsignificant\\nfindings.\\nFirstly,\\nCNNs\\nexhibited\\nremarkable\\nproficiency\\nin\\nidentifying\\nthe\\nbarks\\nof\\n42\\ndistinct\\ntree\\nspecies,\\nachieving\\naccuracy\\nrates\\nsurpassing\\n90%.\\nNotably,\\ncomparative\\nanalysis between the two employed CNN\\nmodels, namely VGG-16 and EfficientNet,\\nrevealed only marginal variances in overall\\naccuracy. The\\nstudy identified diagnostic\\nkeys\\nfor\\neach\\nspecies,\\ncorrelating\\nthem\\nwith distinct bark features such as blisters,\\nstripes,\\nlenticels\\nof\\nvarious\\nshapes,\\nand\\ncrevices.\\nInterestingly,\\nthe\\ntwo\\nCNN\\nmodels demonstrated discrepancies\\nin the\\nquality\\nof\\ndiagnostic\\nfeatures, with\\nthe\\nolder model presenting more general yet\\nwell-fitting patterns, while the newer, more\\nintricate model\\nindicated localized patterns\\nless\\npertinent\\nto\\nbark\\nidentification.  convolutional neural networks\\nclass activation mapping  2022\n\n                                                                                                                                  0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1                                                                           2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Furthermore,\\nCNNs\\nshowcased\\nthe\\ncapability\\nto\\npredict\\nuntrained\\nspecies\\nwithin\\nthe\\ncorrect\\ngenus\\nand\\nfamily\\nby\\napproximately\\n41.98%\\nand\\n48.67%,\\nrespectively. These findings underscore the\\npotential of CNNs and CAM in not only\\naccurately\\nidentifying\\nand\\nvisualizing\\nessential\\nbark\\ntraits\\nbut\\nalso\\nin\\ntheir\\nbroader applicability to other plant organs.                                                                                  \n1  Improvement and\\nAssessment of\\nConvolutional\\nNeural\\nNetwork for Tree\\nSpecies\\nIdentification Based\\non\\nBark Characteristics  The\\nstudy\\nemployed\\nthree\\ndistinct\\nvisualization methods,\\nnamely\\nIntegrated\\nGradients,\\nSmooth\\nGrad\\nCAM++,\\nand\\nDeep Feature Decomposition,\\nto elucidate\\nthe\\nnetwork\\nworkflow.\\nThrough\\nthese\\nmethods,\\nresearchers\\nidentified\\nspecific\\nfeatures\\nin\\ntree\\nbark\\nimages,\\nincluding\\ngrooves,\\ncracks,\\nand lenticels, which the\\nneural network weights selectively focused\\non.\\nThis\\nselective\\nattention\\nparalleled\\nhuman recognition of tree species based on\\nbark images, enhancing our understanding\\nof\\nthe network\'s decision-making process.\\nMoreover,\\nthe\\nvisualization\\nresults\\nobtained\\nthrough\\ndeep\\nfeature\\ndecomposition and semantic segmentation\\nexhibited similarities, offering insights into\\nhow the\\nnetwork identifies different\\ntree\\nspecies based on bark image blocks. These\\nfindings\\nunderscored\\nthe\\ncorrelation\\nbetween\\nthe\\nbiological\\ncharacteristics\\nof\\ndiverse\\ntree\\nspecies\\nand\\nthe\\nvisual\\nmechanisms of deep convolutional neural\\nnetworks, providing valuable insights into\\nboth\\nthe\\nnetwork\'s\\nfunctioning\\nand\\nits\\nrelationship with natural features. Overall,\\nthese outcomes shed light on the principles\\nand\\ncharacteristics\\nof\\nthe\\nnetwork\\nworkflow\\nand\\nits\\ncorrelation with\\nthe\\nbiological\\nfeatures\\nof\\ntree\\nspecies,\\nadvancing\\nour\\nunderstanding\\nof\\nboth\\nmachine\\nlearning\\nprocesses\\nand\\nnatural\\nphenomena.                  convolutional neural networks\\nConvNeXt network\\nBarkNetV2  2023\n2               Classification of\\nCITES-listed and other\\nneotropical Meliaceae\\nwood images using\\nconvolutional neural\\nnetworks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The\\nstudy\\naimed\\nto\\ndevelop machine\\nlearning models\\nfor wood\\nidentification\\nbased on images of\\ntransverse surfaces of\\nwood specimens. The researchers captured\\nhigh-resolution\\nimages\\nof\\nwood\\nspecimens,\\nannotated\\nthem for\\nvarious\\ncharacteristics,\\nand then created a dataset\\nfor\\ntraining\\nand\\ntesting\\nthe\\nmachine\\nlearning models. They specifically focused  computer vision classification\\nmodel\\ndeep convolutional neural\\nnetworks  2018\n\n                                                                    0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1                                                                                        2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   on\\ndistinguishing\\nbetween\\nspecies-level\\nand genus-level accuracy,\\nrecognizing the\\ntraditional limitation of wood identification\\nat\\nthe species level. The study involved the\\ncreation\\nof\\npatch\\ndatasets,\\ntraining\\nof\\nconvolutional\\nneural\\nnetwork\\n(CNN)\\nmodels,\\nand\\nevaluation\\nof\\nthe model\\naccuracies. The models were trained using\\nthe VGG16 network as\\nfeature extractors\\nand\\nthe\\ncustom top-level\\nlayers\\nwere\\ntrained\\nusing\\nstochastic\\ngradient\\ndescent\\nand\\nthe Adam optimizer. The\\nstudy also\\nincluded the creation of confusion matrices\\nand\\ntraining\\ncurves\\nfor\\nthe models\\nto\\nanalyze the errors made by the models.                                                                                               \n1  Pest Detection and\\nExtraction Using\\nImage Processing\\nTechniques  The study presents\\nthe development of an\\nautomatic detection and extraction system\\nfor insect pests in paddy fields using image\\nprocessing techniques. The authors set up a\\nnetwork\\nof wireless\\ncameras\\nand\\nsticky\\ntraps\\nin the paddy fields\\nto capture insect\\npests.\\nThey\\nused\\nCISCO\\nLinksys\\nWireless-G\\nInternet\\nHome\\nMonitoring\\nCameras\\nto capture\\nimages\\nat 10 frames\\nper\\nsecond with\\n8-megapixel\\nresolution.\\nThe captured images were processed using\\na local machine equipped with an Intel\\ni3\\nprocessor and 4 GB RAM.\\nThe\\nstudy\\nutilized\\nimage\\npre-processing\\ntechniques to enhance the captured images,\\nincluding\\nconverting\\nRGB\\nimages\\ninto\\ngrayscale\\nusing\\na\\nspecific\\nformula. The\\nauthors also developed an algorithm for the\\ndetection of pests in the images,\\ninvolving\\nthe\\nextraction\\nof\\nisolated\\npatterns\\nof\\ninterest based on robust feature extraction.\\nThe\\nexperimental\\nresults of\\nthe proposed\\nsystem showed its efficiency in detecting\\nand\\nextracting\\ninsect\\npests\\nin the paddy\\nfields.\\nThe\\nsystem was\\ntested\\nover\\nfive\\nconsecutive\\ndays,\\nand\\nthe\\nresults\\nof\\nthe\\ndetected\\nimages\\nof\\ndifferent\\ninsect pests\\nwere recorded and presented in a table.\\nThe study aims to contribute to the field of\\nagricultural research by providing a simple\\nyet\\nefficient\\nsystem for\\nautomatic\\npest\\ndetection\\nand\\nextraction\\nusing\\nimage\\nprocessing techniques.                                                                         Image Processing  2014\n2                  An Intelligent\\nApproach for Detecting\\nPalm Trees                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     The study involved the use of a dataset\\nfrom Kaggle containing 91,360 images for\\nleaf spots and blight spots diseases. Due to\\nthe low variation in the images, the  Thermal imaging\\nImage Processing\\nConvolutional Neural Network\\nSupport Vector Machine  2020\n\n                                                         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1                   2 3\n0  Diseases using Image\\nProcessing and\\nMachine\\nLearning  original images were analyzed before\\naugmentation, resulting in the selection of\\n35 leaf spots images, 40 images for blight\\nspots, and 50 more palm images for each\\ndisease. The original images were\\nmanually cropped to preserve the infected\\nparts and then resized to 224*224 input\\nsize. Image augmentation techniques such\\nas rotation, flipping, and adjusting\\nbrightness were applied, resulting in 5250\\nimages for each disease. The study also\\ninvolved the use of infrared thermal\\ncameras to capture images of palm trees in\\norder to detect water stress and the effects\\nof Red Palm Weevil (RPW) infestation.\\nFurthermore, the study utilized a\\nConvolutional Neural Network (CNN)\\nmodel built on the pre-structured VGG16\\nNetwork for efficient feature extraction\\nand disease classification.  Mobile Application  ', '', '', 0);
INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(98, 'mia.villarica@gmail.com', 'PropEase__Concept_Paper.pdf', 'uploads/5fb2e366fb1d400b907597084c9c2886.pdf', '2025-04-23 09:37:01', '                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                                                                                  \n                                       Concept Paper                              \n           A. Basic Information                                                   \n                                                                                  \n           Project Title: PropEase: A Smart Paperless System, Revolutionizing Topic Proposal Matching and\n           Topic Recommendations                                                  \n                                                                                  \n                                                                                  \n           Topic: Document Processing, Topic Matching, Topic Recommendation, Natural Language\n           Processing, Image Recognition, Speech Recognition                      \n                                                                                  \n                                                                                  \n                                                                                  \n           Proponent: Cayadong, Marjelaine M., Verdad, Jane Benneth Dione         \n                                                                                  \n           B. Technical Description                                               \n                                                                                  \n           The traditional methods of research proposals and thesis defense have become increasingly\n           complicated, time-consuming, and expensive. Traditional methods often involve extensive\n           paperwork, this includes printing and organizing physical documents like concept papers,\n           manuscripts, data collections, questionnaires, drafts of the thesis, etc.. This process is complicated,\n           time-consuming, and expensive. Reviewing documents and providing feedback on printed\n           documents are also a traditional method that panelists take time to read before giving comments\n           manually then communicate back to the researchers. This back and forth process can prolong the\n           process of revision and refinement process of research and thesis making.\n                                                                                  \n                                                                                  \n           Researchers and academic institutions are constantly seeking more efficient and innovative ways to\n           modernize the process of proposals and defenses. The emergence of paperless systems has opened\n           up new possibilities for revolutionizing how research proposals and thesis defense are handled in\n           academics. Digitizing research documents enhances efficiency and facilitates easy sharing among\n           researchers and panelists. This approach enables seamless access and sharing research documents\n           anytime and anywhere. Digitized research documents are easily retrievable and searchable that\n           ensures quick access to relevant information during discussion, revisions, and presentations. Going\n           paperless reduces the expenses of having to print for a document. Paperless systems save time spent\n           on reading printed documents that panelists can provide feedback and collaborate remotely. It\n           optimizes time management and resource utilization. Adapting to digital tools and embracing\n           paperless processes, promotes eco-friendly practices. It contributes to environmental sustainability\n           by reducing paper consumption, minimizing waste, and lowering carbon footprint. The process of\n           transitioning to a paperless system in university for research defense and research proposals can be\n           complicated however, by developing and implementing a smart paperless system the process of\n           research proposals and thesis defense can be much easier.              \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n           By making use of the power of advanced technologies such as machine learning, and data analytics,\n           these systems can significantly enhance the efficiency, accuracy, and effectiveness of topic matching\n           and topic recommendations. This system will not only streamline the process of topic proposal\n           matching but also provide targeted recommendations tailored to the unique needs and interests of\n           researchers, students, and academic institutions. By automating tedious tasks and leveraging the\n           power of advanced technologies, this smart paperless system aspires to be a prompt for\n           transformative advancements in academic discovery and knowledge dissemination. This paper\n           explores the potential of a smart paperless system in transforming the landscape of topic proposal\n           matching and topic recommendations.                                    \n                                                                                  \n           Statement of the Problem:                                              \n                                                                                  \n           The traditional methods of topic proposal matching and topic recommendations in academics are\n           often inconvenient, time-consuming, and lack the efficiency needed to cope with the amounts of\n                                                                                  \n           data. Researchers and panelists face challenges in accurately matching proposals with suitable\n           topics, leading to inefficiencies, and poor resource allocation. The absence of advanced analytical\n           capabilities delay the ability to provide personalized and relevant recommendations to a researcher\'s\n           needs.                                                                 \n                                                                                  \n           Thus, this study specifically seeks to address the following problems: \n             1. How can advanced technology be of use to automate topic proposal matching in a\n                modernized way of research proposal?                              \n             2. How  will the integration of advanced technologies generate accurate topic\n                recommendations?                                                  \n             3. How will speech recognition technology be integrated into the system to enhance user\n                interaction?                                                      \n             4. In what way could the researchers incorporate the model that performs the best, as\n                determined by how well it produces accurate responses?            \n             5. How may real testing be used to assess the performance of the developed system?\n                                                                                  \n                                                                                  \n           Objectives: General and Specific General Objective:                    \n                                                                                  \n           The main objective of this study is to design and develop a web-based that helps researchers and\n           panelists in the process of topic proposal and topic recommendation. Specifically, this study aims to:\n                                                                                  \n             1. Develop a user-friendly smart paperless system leveraging the following technologies to\n                automate and streamline the topic proposal matching process:      \n                1.1 Natural Language Processing (NLP)                             \n                1.2 Document Processing                                           \n                1.3 Speech Recognition                                            \n                1.4 Image Recognition technologies                                \n             2. Enhance the system\'s ability to understand, categorize, and analyze textual and visual data\n                within research proposals to generate accurate topic recommendations.\n             3. Improve accessibility and user experience by integrating Speech Recognition capabilities,\n                allowing users to interact with the system using voice recognition and natural language\n                                                                                  \n                queries.                                                          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n             4. Optimize resource allocation and research productivity by providing researchers and students\n                with timely and relevant topic recommendations based on their preferences, areas of interest,\n                and expertise.                                                    \n             5. Evaluate the system\'s performance through user feedback, usability testing, and metrics such\n                as accuracy, efficiency, and user satisfaction to ensure continuous improvement and\n                refinement.                                                       \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n           How did others solve the problem?                                      \n                                                                                  \n             1. Plagiarism is a common problem in the modern age. With the advance of the Internet, it is\n                more and more convenient to access other people’s writings or publications. When someone\n                uses the content of a text in an undesirable way, plagiarism may occur. Plagiarism infringes\n                intellectual property rights, so it is a serious problem nowadays. However, detecting\n                plagiarism effectively is challenging work. Traditional methods, like vector space model or\n                bag-of-words, are short of providing a good solution due to the incapability of handling the\n                semantics of words satisfactorily. In this paper, we propose a new method for plagiarism\n                detection. We use Word2vec to transform the words into word vectors which are able to\n                reveal the semantic relationship among different words. Through word vectors, words are\n                clustered into concepts. Then documents and their paragraphs are represented in terms of\n                concepts, and plagiarism detection can be done more effectively. A number of experiments\n                are conducted to demonstrate the good performance of our proposed method. (Using word\n                semantic concepts for plagiarism detection in text documents. C. W. D., Lee, S., et. al., 2021)\n                                                                                  \n                                                                                  \n             2. In education, students attempt to copy previous works and are relying on prepared solutions\n                available on the Internet in order to meet their requirements. This action leads to plagiarism,\n                which is becoming part of educational institutions’ concern to reduce growing academic\n                dishonesty. The developed system is composed of three main modules; the Document Search\n                which enables users to browse documents, the Document Registration which enables the\n                administrator to add and manage the stored documents, and the document Comparison,\n                which serves as the system plagiarism detection mechanism. (Theses and Capstone Projects\n                Plagiarism Checker using Kolmogorov Complexity Algorithm. Del Rosario, et. al., 2020)\n                                                                                  \n             3. Issues on plagiarism among pre-service teachers (PSTs) have increased in modular and\n                online learning. To confirm this, the study determined the PSTs’ level of awareness on\n                plagiarism; their knowledge on referencing and citation; and the correlation between their\n                level of awareness on plagiarism and knowledge on referencing and citation, with their\n                academic performance. The study employed a descriptive-correlational research design\n                participated by 235 PSTs randomly sampled through strata. (Ctrl C + Ctrl V: Plagiarism and\n                                                                                  \n                Knowledge on Referencing and Citation among Pre-service Teachers. Pentang, J., et. al.,\n                2022)                                                             \n                                                                                  \n             4. Socio-cultural plagiarism provides an understanding of the social values and attitudes among\n                students in academic writing. Based on the rules and regulations of any academic institution,\n                adequate awareness of different forms of plagiarism, citation techniques, paraphrasing, and\n                other instances of copyright infringement should be tailored to any type of violation against\n                conduct and discipline, particularly in cheating. (Sensitivity Towards Sociocultural\n                Plagiarism in the Context of Varied Discipline among College Students. Calicdan, L. C., et.\n                al., 2021)                                                        \n                                                                                  \n             5. Citing sources can solidify claims and make a research paper credible. Failing to credit the\n                ideas of others is a form of plagiarism, which was a common problem among students in the\n                past until today. Citing sources can solidify claims and make a research paper credible.\n                Failing to credit the ideas of others is a form of plagiarism, which was a common problem\n                among students in the past until today. Ideas are considered intellectual property, and there\n                                                                                  \n                can be severe repercussions if one fails to cite where you got an idea from. Plagiarism is\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                common in academic writing because of the lack of knowledge about citing sources.\n                (Students’ Knowledge in Citing Sources at St. Paul University. Mejorada, E., et. al., 2023)\n                                                                                  \n             6. Now a day’s plagiarism became very common in many fields of life such as research and\n                educational fields. Due to the advancement in plagiarism techniques adopted by plagiarists,\n                it is very difficult to detect plagiarism accurately by the existing technique. Different features\n                are observed while checking plagiarism such as syntactic, lexical, semantic, and structural\n                features. (Plagiarism Detection Using Natural Language Processing Techniques. Ilyas, M.,\n                et. al., 2021)                                                    \n                                                                                  \n             7. Paraphrase Identification or Natural Language Sentence Matching (NLSM) is one of the\n                important and challenging tasks in Natural Language Processing where the task is to identify\n                if a sentence is a paraphrase of another sentence in a given pair of sentences. Paraphrase of a\n                sentence conveys the same meaning but its structure and the sequence of words varies. It is a\n                challenging task as it is difficult to infer the proper context about a sentence given its short\n                                                                                  \n                length. Also, coming up with similarity metrics for the inferred context of a pair of sentences\n                is not straightforward as well. (Machine Learning Models for Paraphrase Identification and\n                its Applications on Plagiarism Detection. Ethan, H., etl. al., 2019)\n                                                                                  \n             8. The processing of natural language processing is changed after the evident of deep learning\n                algorithms. The machine learning algorithms use numerical data for processing; therefore,\n                categorical data are converted into equivalent vectors for processing by the machines. Word\n                embeddings are the real vectored representation of words which store semantic information.\n                These embeddings are the significant tool of natural language being used in various tasks\n                like name-entity-recognition and parsing, etc. Authorship attribution is a major problem in\n                natural language processing. (A deep learning approach for plagiarism detection system\n                using BERT. Bohra, A., et. al., 2022)                             \n                                                                                  \n             9. Speech-to-text conversion and summarization for effective understanding and documentation\n                by Vinnarasu A. and Deepa V. Jose presents a method for speech recognition and text\n                summarization to aid in understanding and documenting lengthy speeches. The research\n                                                                                  \n                work describes an easy and effective method for speech recognition, converting speech to\n                text, and producing a summarized text. The proposed hybrid method has various\n                applications, including creating lecture notes and summarizing catalogs for lengthy\n                documents. The combination of speech-to-text conversion and text summarization is\n                implemented, providing a practical strategy for improving the reliability of large language\n                models. The proposed model aims to reduce the time and effort of manual documentation of\n                lengthy speeches in an event, making it easier to archive lecture notes from classes,\n                conferences, or seminars. (Speech-to-text conversion and summarization for effective\n                understanding and documentation, Vinnarasu A., Deepa V. Jose, 2019)\n                                                                                  \n           Other Related Study (data gathering and machine learning methods)      \n                                                                                  \n             10. Based on the article, Python’s speech recognition module and “text blob” for language\n                conversion and analysis were used to develop the system. Natural Language Toolkit (NLTK)\n                is employed for tokenization, lemmatization, POS tagging, and named entity tagging.\n                Emotional states are extracted, and VADER (Valence Aware Dictionary and Sentiment\n                                                                                  \n                Reasoner) sentiment analysis is applied, providing positive, negative, neutral, and compound\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                scores (Lliev & Stanchev, 2020).VADER, an open-source sentiment analysis tool, generates\n                scores based on a lexicon with over 9000 features. The lexicon rates each feature between -4\n                (extremely negative) and +4 (extremely positive) under the MIT License (Akash Apturkar et\n                al., 2020).                                                       \n                                                                                  \n             11. Natural language processing (NLP) has recently gained much attention for representing and\n                analyzing human language computationally. It has spread its applications in various fields\n                such as machine translation, email spam detection, information extraction, summarization,\n                medical, and question answering etc. In this paper, we first distinguish four phases by\n                discussing different levels of NLP and components of Natural Language Generation\n                followed by presenting the history and evolution of NLP. We then discuss in detail the state\n                of the art presenting the various applications of NLP, current trends, and challenges. (Natural\n                language processing: state of the art, current trends and challenges. Khurana, D., et. al.,\n                2022)                                                             \n                                                                                  \n                                                                                  \n             12. Attention is an increasingly popular mechanism used in a wide range of neural architectures.\n                The mechanism itself has been realized in a variety of formats. However, because of the\n                fast-paced advances in this domain, a systematic overview of attention is still missing. They\n                define a unified model for attention architectures in natural language processing, with a\n                focus on those designed to work with vector representations of the textual data. They\n                propose a taxonomy of attention models according to four dimensions: the representation of\n                the input, the compatibility function, the distribution function, and the multiplicity of the\n                input and/or output. They present the examples of how prior information can be exploited in\n                attention models and discuss ongoing research efforts and open challenges in the area,\n                providing the first extensive categorization of the vast body of literature in this exciting\n                domain. (Attention in Natural Language Processing. Andrea, G., et. al., 2021)\n                                                                                  \n             13. Pre-training techniques have been verified successfully in a variety of NLP tasks in recent\n                years. Despite the widespread use of pre-training models for NLP applications, they almost\n                exclusively focus on text-level manipulation, while neglecting layout and style information\n                that is vital for document image understanding. In this paper, we propose the LayoutLM to\n                                                                                  \n                jointly model interactions between text and layout information across scanned document\n                images, which is beneficial for a great number of real-world document image understanding\n                tasks such as information extraction from scanned documents. Furthermore, we also leverage\n                image features to incorporate words\' visual information into LayoutLM. (LayoutLM:\n                Pre-training of Text and Layout for Document Image Understanding. Xu, Y., et. al., 2020)\n                                                                                  \n             14. With the widespread use of mobile phones and scanners to photograph and upload\n                documents, the need for extracting the information trapped in unstructured document images\n                such as retail receipts, insurance claim forms and financial invoices is becoming more acute.\n                A major hurdle to this objective is that these images often contain information in the form of\n                tables and extracting data from tabular sub-images presents a unique set of challenges. This\n                includes accurate detection of the tabular region within an image, and subsequently detecting\n                and extracting information from the rows and columns of the detected table. While some\n                progress has been made in table detection, extracting the table contents is still a challenge\n                since this involves more fine grained table structure (rows & columns) recognition. Prior\n                approaches have attempted to solve the table detection and structure recognition problems\n                                                                                  \n                independently using two separate models. (TableNet: Deep Learning Model for End-to-end\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                Table Detection and Tabular Data Extraction from Scanned Document Images. Shubham,\n                S.P., et. al., 2019)                                              \n                                                                                  \n           Patents                                                                \n                                                                                  \n             15. The Plagiarism is an increasingly widespread and growing problem in the academic field.\n                Several plagiarism techniques are used by fraudsters, ranging from a simple synonym\n                replacement, sentence structure modification, to more complex method involving several\n                types of transformation. Human based plagiarism detection is difficult, not accurate, and\n                time-consuming process. In this paper we propose a plagiarism detection framework based\n                on three deep learning models: Doc2vec, Siamese Long Short-term Memory (SLSTM) and\n                Convolutional Neural Network (CNN). Our system uses three layers: Preprocessing Layer\n                including word embedding, Learning Layers and Detection Layer. To evaluate our system,\n                we carried out a study on plagiarism detection tools from the academic field and make a\n                comparison based on a set of features. Compared to other works, our approach performs a\n                                                                                  \n                good accuracy of 98.33 % and can detect different types of plagiarism, enables to specify\n                another dataset and supports to compare the document from an internet search. (A New\n                Online Plagiarism Detection System based on Deep Learning. Hambi, E.M., et. al., 2020)\n                                                                                  \n             16. Summarizes the research on computational methods to detect academic plagiarism by\n                systematically reviewing 239 research papers published between 2013 and 2018. To structure\n                the presentation of the research contributions, we propose novel technically oriented\n                typologies for plagiarism prevention and detection efforts, the forms of academic plagiarism,\n                and computational plagiarism detection methods. We show that academic plagiarism\n                detection is a highly active research field. Over the period we review, the field has seen\n                major advances regarding the automated detection of strongly obfuscated and thus\n                hard-to-identify forms of academic plagiarism. These improvements mainly originate from\n                better semantic text analysis methods, the investigation of non-textual content features, and\n                the application of machine learning. We identify a research gap in the lack of\n                methodologically thorough performance evaluations of plagiarism detection systems.\n                Concluding from our analysis, we see the integration of heterogeneous analysis methods for\n                                                                                  \n                textual and non-textual content features using machine learning as the most promising area\n                for future research contributions to improve the detection of academic plagiarism further.\n                (Academic Plagiarism Detection. Foltýnek, T., et. al., 2019)      \n                                                                                  \n                                                                                  \n           How do you intend to solve the problem?                                \n                                                                                  \n           The proponents of the study plan to solve the problem by developing a website/ application that will\n           gather the data from the published thesis papers through machine learning using image processing\n           and natural language processing. The said website/ application will be acting as a grading system for\n           plagiarism for a title and concept similar to another and recommend titles that are similar to the topic\n           for a new solution to a problem. The system will be able to give panelists the idea the student is\n           portraying by using the speech to text while the proponent is giving their explanation and insight to\n           their concept papers. It can also scan the soft copy document to see if the concept is already existing\n           or not.                                                                \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                               Figure 1.1 Home page Website GUI                   \n                                                                                  \n           Users are greeted with a brief overview of the website/application\'s capabilities and purpose on the\n                                                                                  \n           main page. Important sections like \"Proposals,\" \"Trash,\" \"Account,\" and \"Sign Up\" are clearly\n           labeled, making it simple to navigate to the functions you need. In order to provide an easy and\n                                                                                  \n           effective user experience, users are advised to register for an account or link their emails in order to\n           gain access to other sections of the website.                          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                              Figure 1.2 Proposals page Website GUI               \n           Users can upload files to the website for plagiarism checks on titles and contents in the proposal\n                                                                                  \n           section. Furthermore, if a file already exists and has been uploaded and reviewed, a square-like form\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n           will show up, enabling users to save and retrieve these suggestions for later use or extra verification.\n           This feature makes it easier for users to retrieve files they have already looked at on the platform,\n                                                                                  \n           which increases efficiency and convenience.                            \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Figure 1.3 Files page Website GUI                 \n                                                                                  \n           When a proposal file is uploaded, our website starts real-time checking right away and gives users\n           feedback right away. The \"Mic\" button above allows users to record the speaker\'s voice, making\n                                                                                  \n           their thoughts easier to hear. By providing a succinct summary of the proposal\'s contents, this\n                                                                                  \n           element improves communication. The uploaded paper appears with its title and contents beneath\n           the voice recording area. Users can view content-related statistics, such as the identification of\n                                                                                  \n           duplicate titles written by other people, right next to the voice recording and paper display.\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                             Figure 1.4 Recommendation Pop-up GUI                 \n           The pop-up window will function as a platform for recommendations, providing ideas for articles\n                                                                                  \n           related to the previous subject. It will suggest titles that cover other project concepts but have a\n           similar idea, giving proponents a title possibility to consider further. This feature presents different\n                                                                                  \n           viewpoints and lines of study within the same topic domain in an effort to improve research\n                                                                                  \n           discovery.                                                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Figure 2 Conceptual Framework                     \n           As shown in the figure above, is the conceptual framework where data gathered will be coming from\n                                                                                  \n           three different sources, such as Concept Paper Proposal, Existing Thesis Books, and Vocabulary\n           Data Set. This framework involves preprocessing steps like cleaning, tokenization, and\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n           stemming/lemmatization before applying machine learning algorithms to analyze the speech\n           being spoken. The goal is to check the accuracy and plagiarism of the proposed conceptual\n                                                                                  \n           framework by using speech-to-text recognition and image or text processing.\n                                                                                  \n           Target users / Beneficiaries:(Describe each Beneficiary)               \n           This study will be beneficial to the institution. Smart paperless systems aim to enhance the\n           efficiency, transparency, and effectiveness of the research proposal matching and topic\n           recommendation process.                                                \n                                                                                  \n                                                                                  \n             1. Administrators or Program Coordinator: The system can be effectively used by\n                administrators or program managers in charge of research programs or funding initiatives to\n                handle proposal submissions and topic selection procedures. Through the automation of\n                repetitive operations like proposal matching and document processing, the system\'s\n                automation capabilities lessen the administrative pressure.       \n                                                                                  \n             2. Panelists or Reviewers: The automation of the system, which assists in matching proposals\n                with relevant topics, will be helpful to panelists considering research proposals or topic\n                submissions. Panelists are able to efficiently comprehend and evaluate proposal material\n                because of the system\'s natural language processing (NLP) capabilities, which guarantees\n                effective decision-making procedures.                             \n                                                                                  \n             3. Future Researchers: The streamlined method of matching topic proposals will help\n                researchers find relevant study ideas more quickly and efficiently, saving them time and\n                effort. They may analyze enormous volumes of text data, extract important information, and\n                                                                                  \n                produce insights for their research by using the system\'s natural language processing (NLP)\n                capabilities. Research papers, journals, and other pertinent documents can be quickly\n                reviewed and categorized by researchers with the use of document processing tools.\n                                                                                  \n           Significance of study:                                                 \n           This study will help researchers perform efficient and well-organized research methods in addition\n           to benefiting panelists for time management and efforts.               \n                                                                                  \n             1. Panelists: The accuracy and speed with which panelists connect research proposals with\n                appropriate concepts will improve during the assessment and selection process. By\n                automating the matching process, biases, and manual effort are minimized, resulting in an\n                equal evaluation of ideas. The ability to process papers more efficiently makes it easier to\n                handle proposal materials, which improves the accessibility and organization of the review\n                process.                                                          \n                                                                                  \n             2. Researchers: Researchers will save time and money thanks to the process of matching\n                                                                                  \n                subject proposals which is now more efficient. By utilizing NLP capabilities, researchers can\n                gain deeper insights by enhancing their comprehension and analysis of study materials.\n                Speech and picture recognition technologies allow users to engage with the system in a\n                natural way, which speeds up the input and retrieval of data.     \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n          Gap Analysis                                                            \n               TITLE           DESCRIPTION         SCOPE/TECHNOLOGY    YEAR       \n                                TECHNOLOGY   (Speech-to-text)                     \n           Automatic Speech In their systematic literature review, Alharbi et al. (2021) 2021\n           Recognition:  Alharbi et al. (2021) explore the conducted a systematic \n           Systematic    advancements in speech-to-text literature review focusing\n           Literature Review recognition  technology, on the advancements in      \n                         highlighting its transformative speech-to-text recognition\n                         impact on data transcription. The technology. Their research\n                         scope encompasses the conversion explores the            \n                         of spoken words into written text transformative impact of\n                         and its applications in analyzing this technology on data\n                         interview recordings efficiently for transcription, particularly\n                                                                                  \n                         further evaluation of applicant in converting spoken     \n                         responses. However, they also words into written text.   \n                         acknowledge the  challenges                              \n                         outlined in their research, including                    \n                         factors such as the number of                            \n                         speakers, speech clarity, vocabulary                     \n                         size, and spectral bandwidth, which                      \n                         influence the performance of                             \n                         automated speech recognition                             \n                         systems. This study was published                        \n                         in 2021.                                                 \n                                                                                  \n           Challenges and In their study by Sneha Basak, The scope of the study 2022\n           Limitations in Himanshi Agrawal, Shreya Jena, conducted by Sneha       \n           Speech        Shilpa Gite, Mrinal Bachute, Basak, Himanshi Agrawal,    \n                                                                                  \n           Recognition   Biswajeet Pradhan, and Mazen Shreya Jena, Shilpa Gite,   \n           Technology: A Assiri (2022), the researchers Mrinal Bachute, Biswajeet \n           Critical Review of acknowledge the significance of Pradhan, and Mazen Assiri\n           Speech Signal speech recognition technology (2022) encompasses a       \n           Processing    while also addressing factors that critical review of speech\n           Algorithm, Tools require attention for further recognition technology, \n           and Systems.  improvement.              focusing on challenges and     \n                                                   limitations within the field.  \n                         They highlight challenges such as The researchers delve into\n                         variation in accents, which pose various aspects of speech\n                         difficulties for machines to signal processing           \n                         understand         different algorithms, tools, and      \n                         pronunciations, intonations, and systems, aiming to identify\n                         accents. The study raises concerns areas that require further\n                         about the lack of speech recognition attention for improvement.\n                         systems designed specifically for                        \n                                                                                  \n                         children, despite the increasing                         \n                         prevalence of e-learning and                             \n                         children spending significant time                       \n                         on screens. The slower pace at                           \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                         which children understand new                            \n                         words further complicates the                            \n                         ability of current speech recognition                    \n                         systems to comprehend child                              \n                         vocabulary effectively. The study                        \n                         discusses the importance of model                        \n                         training to avoid overfitting, which                     \n                         could negatively impact the                              \n                         performance of speech recognition                        \n                         systems by adding unnecessary                            \n                         concepts.                                                \n                                                                                  \n                         Environmental noise is identified as                     \n                         another significant challenge, as it                     \n                         can  severely affect speech                              \n                                                                                  \n                         transcription accuracy. Through                          \n                         these observations, the study                            \n                         provides valuable insights into the                      \n                         limitations and challenges facing                        \n                         speech recognition technology,                           \n                         suggesting areas for further                             \n                         research and development.                                \n                                                                                  \n           Multilingual  Attanasio, Savoldi, Fucci, and Attanasio, Savoldi, Fucci, 2024\n           Speech Models for Hovy (2024) address limitations in and Hovy (2024) address\n           Automatic Speech research related to gender and the limitations in research\n           Recognition   social-cultural factors in voice concerning gender and   \n           Exhibit Gender recognition. The   scope social-cultural factors in     \n           Performance Gaps encompasses the need for a broader voice recognition. Their\n                         dataset considering dialects, sex, study emphasizes the  \n                                                                                  \n                         and other cultural factors to necessity for a broader    \n                         improve the results\' robustness. The dataset encompassing\n                         authors also highlight issues of dialects, sex, and other\n                         generalizability due to the cultural factors to enhance  \n                         categorization of participants as result robustness.     \n                         \"Other\" and the comparison of                            \n                         speakers across different platforms.                     \n                         Additionally, they stress the                            \n                         importance of data quality and the                       \n                         potential biases introduced by the                       \n                         lack of multilingual phonetic tools.                     \n                                                                                  \n           Improving     This research paper addresses the The scope of the research 2023\n           Readability for readability challenges posed by paper encompasses the  \n           Automatic Speech modern Automatic Speech realm of Automatic            \n                                                                                  \n           Recognition   Recognition (ASR) systems, which Speech Recognition (ASR)\n           Transcription may produce accurate transcripts systems and their impact\n                         but can still be difficult to read due on readability in \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                         to grammatical errors, disfluency, transcripts. It delves into\n                         and other spoken communication the challenges faced when \n                         nuances. The paper introduces the ASR systems produce    \n                         ASR post-processing for readability accurate but often   \n                         (APR) task, formulated as a difficult-to-read transcripts\n                         sequence-to-sequence  text due to grammatical errors,    \n                         generation problem, with the goal disfluencies, and other\n                         of transforming noisy ASR outputs spoken communication   \n                         into readable text while preserving nuances.             \n                         semantic meaning. The authors                            \n                         construct a dataset for APR using                        \n                         data from  grammatical error                             \n                         correction tasks and evaluate model                      \n                         performance using adapted metrics.                       \n                         They compare fine-tuned baseline                         \n                                                                                  \n                         models with traditional pipeline                         \n                         methods, demonstrating significant                       \n                         improvements in readability on test                      \n                         sets and confirming their model\'s                        \n                         efficacy through human evaluation                        \n                         and case studies.                                        \n                                                                                  \n           Text-independent This research paper explores The scope of this research 2020\n           speaker recognition text-independent speaker paper is focused on       \n           using LSTM-RNN recognition in the context of advancing                 \n           and speech    degraded speech signals, including text-independent speaker\n           enhancement   noise and  reverberation. It recognition systems in the  \n                         highlights the advantages of presence of degraded        \n                         text-independent   speaker speech signals, including     \n                         recognition compared   to noise and reverberation.       \n                                                                                  \n                         text-dependent  approaches,                              \n                         particularly in allowing clients to                      \n                         speak freely to the system. The                          \n                         paper employs Mel-Frequency                              \n                         Cepstral Coefficients (MFCCs),                           \n                         spectrum, and log-spectrum for                           \n                         feature extraction from speech                           \n                         signals, and utilizes Long-Short                         \n                         Term Memory Recurrent Neural                             \n                         Networks  (LSTM-RNN)  for                                \n                         classification to achieve speaker                        \n                         recognition. The    system                               \n                         demonstrates high recognition rates,                     \n                         reaching 95.33% with MFCCs and                           \n                         98.7%   with  spectrum or                                \n                         log-spectrum, under similar                              \n                                                                                  \n                         recording circumstances. However,                        \n                         challenges arise when recognizing                        \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                         speakers across different recording                      \n                         environments, prompting the use of                       \n                         speech enhancement techniques                            \n                         like spectral subtraction and                            \n                         wavelet denoising to improve                             \n                         recognition performance. The                             \n                         proposed  approach  shows                                \n                         superiority over   previous                              \n                         algorithms, particularly the one by                      \n                         R. Togneri and D. Pullella (2011),                       \n                         showcasing advancements in                               \n                         text-independent   speaker                               \n                         recognition under degraded speech                        \n                         conditions.                                              \n                                                                                  \n                                                                                  \n                                                                                  \n           The papers cover a wide range of difficulties and developments in voice recognition technology.\n           Alharbi et al. (2021) explore how speech-to-text recognition technology can change lives, especially\n           when it comes to data transcription from recorded interviews. They recognize the difficulties\n           presented by variables that affect automated speech recognition systems\' performance, such as\n           speech quality, vocabulary quantity, and ambient noise. Basak et al. (2022) go into further detail\n           about these difficulties, emphasizing problems like accent variance and the absence of kid-friendly\n           systems. They also highlight the shortcomings of the speech recognition technologies available\n           today and offer potential solutions like model training and mitigating background noise.\n                                                                                  \n           Furthermore, Attanasio et al. (2024) fill in the study gaps concerning gender and social-cultural\n           aspects of speech recognition, highlighting the necessity of larger datasets and better data quality to\n           increase the voice recognition systems\' resilience and applicability. Conversely, a study on\n           Automatic Speech Recognition (ASR) post-processing for readability presents the ASR\n           post-processing for readability (APR) challenge, which aims to correct grammatical errors and\n                                                                                  \n           disfluency in ASR outputs in order to make them more readable. The state of speaker recognition\n           technology is further demonstrated by a study on text-independent speaker recognition in degraded\n           speech signals, which uses methods like Mel-Frequency Cepstral Coefficients (MFCCs) and\n           Long-Short Term Memory Recurrent Neural Networks (LSTM-RNN) to achieve high recognition\n           rates even in difficult environments.                                  \n                                                                                  \n                                                                                  \n               TITLE           DESCRIPTION         SCOPE/TECHNOLOGY     YEAR      \n                               TECHNOLOGY   (Image Processing)                    \n           LayoutLM:     The  research paper introduces The scope of this research 2020\n           Pre-training of Text LayoutLM, a novel approach that paper is centered around\n           and Layout for extends pre-training techniques to addressing the limitations\n                                                                                  \n           Document Image encompass layout and style of pre-training techniques   \n           Understanding information  crucial  for in natural language            \n                         understanding document images. processing (NLP) that     \n                         Unlike existing methods that predominantly focus on      \n                         mainly focus on text manipulation, text-level manipulation,\n                         LayoutLM incorporates text and neglecting layout and style\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                         layout interactions, enhancing tasks information crucial for\n                         like information extraction from document image          \n                         scanned documents. It also understanding.                \n                         integrates image features to capture                     \n                         visual information alongside text.                       \n                         This comprehensive framework                             \n                         achieves state-of-the-art results                        \n                         across   various  document                               \n                         understanding tasks such as form                         \n                         understanding,      receipt                              \n                         understanding, and document image                        \n                         classification.                                          \n           Artificial    This research paper introduces a The scope of the research 2020\n                         novel convolutional neural network paper encompasses the \n           Intelligence Image                                                     \n                         (CNN)  algorithm aimed at development and                \n           Recognition                                                            \n                         enhancing convergence speed and evaluation of a novel    \n           Method Based on                                                        \n                         recognition accuracy. The algorithm convolutional neural \n           Convolutional integrates a recurrent neural network (CNN) algorithm    \n           Neural Network network (RNN) into the CNN that integrates recurrent    \n                         architecture, enabling parallel neural networks (RNNs)   \n           Algorithm                                                              \n                         learning of deep image features. and ResNet-inspired     \n                         Additionally, inspired by ResNet\'s residual modules to   \n                         skip connections, a new residual enhance image processing\n                         module called ShortCut3-ResNet is tasks.                 \n                         developed to further optimize                            \n                         feature extraction. A dual                               \n                         optimization model is formulated to                      \n                         integrate convolution and full                           \n                         connection processes effectively.                        \n                         Through simulation experiments,                          \n                         the paper analyzes the impact of                         \n                         various CNN  parameters on                               \n                         network performance, identifying                         \n                         optimal settings.                                        \n           LayoutParser: A This research paper introduces The scope of this research 2021\n           Unified Toolkit for LayoutParser, an open-source paper lies in addressing the\n           Deep Learning library designed to simplify the challenges faced in     \n           Based Document application of deep learning (DL) document image analysis\n           Image Analysis models in document image analysis (DIA) due to the      \n                         (DIA). The paper addresses the complexity of neural      \n                         challenges of code organization and network applications.\n                         model complexity that hinder the                         \n                         easy deployment and reuse of DL                          \n                         innovations in DIA research.                             \n                         LayoutParser offers intuitive                            \n                         interfaces for utilizing DL models                       \n                         in  layout detection, character                          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                         recognition, and     other                               \n                         document-processing tasks. The                           \n                         library also includes a platform for                     \n                         sharing pre-trained models and full                      \n                         document digitization pipelines,                         \n                         enhancing extensibility and                              \n                         collaboration within the DIA                             \n                         community.                                               \n                         This research paper presents a The scope of this research 2020\n           Multimodal Deep novel approach to document paper is to address the     \n           Networks for Text classification by integrating both challenges in fine-grained\n           and Image-Based text and visual information. The document classification by\n           Document      proposed  pipeline utilizes leveraging both text and     \n           Classification off-the-shelf architectures to create visual information. It\n                                                                                  \n                         a  multimodal neural network acknowledges the            \n                         capable of learning from both limitations of visual      \n                         image data and word embeddings analysis alone in achieving\n                         extracted from noisy text obtained accurate document     \n                         through OCR.  The  research classification, especially   \n                         demonstrates     significant when dealing with           \n                         improvements in classification documents lacking clean   \n                         accuracy on   datasets like digital text.                \n                         Tobacco3482 and RVL-CDIP, even                           \n                         in  cases where clean text                               \n                         information is unavailable. The                          \n                         paper also releases a post-OCR text                      \n                         classification dataset to encourage                      \n                         further research in multi-modal                          \n                         text/image classification.                               \n                                                                                  \n                                                                                  \n           SelfDoc:      SelfDoc is a novel pre-training The scope of this research 2021\n           Self-Supervised framework designed for document paper encompasses the  \n           Document      image understanding that addresses development and       \n           Representation the multimodal nature of documents evaluation of a      \n           Learning      and  their intended sequential task-agnostic pre-training\n                         reading. Unlike existing models framework called SelfDoc \n                         that focus on individual words, for document image       \n                         SelfDoc takes a coarse-grained understanding.            \n                         approach to capture the positional,                      \n                         textual, and visual information of                       \n                         semantically     meaningful                              \n                         components in documents while                            \n                         avoiding          excessive                              \n                         contextualization. It incorporates                       \n                         cross-modal learning during                              \n                                                                                  \n                         pre-training to leverage multimodal                      \n                         information from  unlabeled                              \n                         documents and introduces a                               \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n                         modality-adaptive attention                              \n                         mechanism for effective feature                          \n                         fusion.                                                  \n                                                                                  \n           The papers discussed here offer a variety of modern techniques for analyzing and understanding\n           document images. First off, LayoutLM presents a thorough framework that expands on pre-training\n           methods to include style and layout data in addition to text, leading to better results on a range of\n           document comprehension tasks. In tasks like form understanding and transaction comprehension, it\n           achieves state-of-the-art outcomes by skillfully combining text, layout, and image elements.\n           Furthermore, a unique convolutional neural network (CNN) algorithm is put forth to improve\n           recognition accuracy and speed of convergence. It combines residual modules and recurrent neural\n           networks (RNNs) for optimal feature extraction, and simulation experiments are used to illustrate the\n           effects of different CNN factors on network performance.               \n                                                                                  \n                                                                                  \n           Additionally, LayoutParser offers an open-source library with user-friendly interfaces for layout\n           detection, character recognition, and other document processing tasks, addressing the difficulties\n           associated with using deep learning models in document picture analysis. LayoutParser makes deep\n           learning advancements in document image analysis research easier to apply and reuse by\n           streamlining code organization and model complexity. Additionally, a multimodal neural network\n           architecture is used to leverage both text and visual input in a novel way for document classification.\n           This method produces notable gains in classification accuracy even in the absence of clear text data,\n           proving the usefulness of combining several modalities for tasks involving document understanding.\n           Last but not least, SelfDoc offers a pre-training framework created especially for document image\n           understanding. It uses modality-adaptive attention mechanisms and cross-modal learning to capture\n           the visual and textual information of semantically significant document components, improving\n           state-of-the-art document image understanding tasks.                   \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                 Citation of Resources Gathered                   \n           Attention in natural language processing. (2021, October 1). IEEE Journals & Magazine | IEEE\n                                                                                  \n                Xplore. https://ieeexplore.ieee.org/abstract/document/9194070     \n                                                                                  \n           Bohra, A., & Barwar, N. C. (2022). A deep learning approach for plagiarism detection system using\n                                                                                  \n                BERT. In Lecture notes on data engineering and communications technologies (pp.\n                                                                                  \n                163–174). https://doi.org/10.1007/978-981-16-9113-3_13            \n                                                                                  \n           Calicdan, L. C., Bacaro, R. M. R., Ramo, D. C., & Licayan, R. J. (2021). Sensitivity Towards\n                                                                                  \n                                                                                  \n                Sociocultural Plagiarism in the Context of Varied Discipline among College Students.\n                                                                                  \n                International Journal of Asian Education, 2(2), 244–255.          \n                                                                                  \n                https://doi.org/10.46966/ijae.v2i2.121                            \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n           Chang, C. W. D., Lee, S., Wu, C., Liu, C., & Liu, C. (n.d.). Using word semantic concepts for\n                                                                                  \n                plagiarism detection in text documents. Information Retrieval, 24(4–5), 298–321.\n                                                                                  \n                https://doi.org/10.1007/s10791-021-09394-4                        \n                                                                                  \n           Del Rosario, M. J. N., & Sareno, J. (2020). Theses and Capstone Projects Plagiarism Checker using\n                                                                                  \n                Kolmogorov Complexity Algorithm. Walailak Journal of Science and Technology, 17(7),\n                                                                                  \n                726–744. https://doi.org/10.48048/wjst.2020.6498                  \n                                                                                  \n           Foltýnek, T., Meuschke, N., & Gipp, B. (2019). Academic Plagiarism Detection. ACM Computing\n                                                                                  \n                Surveys, 52(6), 1–42. https://doi.org/10.1145/3345317             \n                                                                                  \n                                                                                  \n           Human verification. (n.d.).                                            \n                                                                                  \n                https://www.semanticscholar.org/paper/A-New-Online-Plagiarism-Detection-System-based-\n                                                                                  \n                on-Hambi-Benabbou/1361c6589bcb39cd770013a51bf6ca99062d3992?p2df   \n                                                                                  \n           Khurana, D., Koli, A., Khatter, K., & Singh, S. (2022). Natural language processing: state of the art,\n                                                                                  \n                current trends and challenges. Multimedia Tools and Applications, 82(3), 3713–3744.\n                                                                                  \n                https://doi.org/10.1007/s11042-022-13428-4                        \n                                                                                  \n           Machine Learning Models for Paraphrase Identification and its Applications on Plagiarism\n                                                                                  \n                Detection. (2019, November 1). IEEE Conference Publication | IEEE Xplore.\n                                                                                  \n                                                                                  \n                https://ieeexplore.ieee.org/abstract/document/8944727             \n                                                                                  \n           Mejorada, E., Doong, J. D., Retorta, M. A. P., Curayag, C. M. P., Lonzon, W. A., Ederio, N. T., &\n                                                                                  \n                Calaca, N. I. (2023). Students’ Knowledge in Citing Sources at St. Paul University.\n                                                                                  \n                International Journal of Current Science Research and Review, 06(01), 207–213.\n                                                                                  \n                https://doi.org/10.47191/V6-i1-21                                 \n                                                                                  \n           Pentang, J., & Bautista, R. M. (2022). Ctrl C + Ctrl V: Plagiarism and Knowledge on Referencing\n                                                                                  \n                and Citation among Pre-service Teachers. https://philpapers.org/rec/PENCC\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n           Single view - International Journal of Current Science Research and Review. (n.d.). International\n                                                                                  \n                Journal of Current Science Research and Review.                   \n                                                                                  \n                https://ijcsrr.org/single-view/?id=8564&pid=8479                  \n                                                                                  \n           Single view - International Journal of Current Science Research and Review. (2020, January 6).\n                                                                                  \n                International Journal of Current Science Research and Review.     \n                                                                                  \n                https://ijcsrr.org/single-view/?id=8564&pid=8479                  \n                                                                                  \n           TableNet: Deep Learning Model for End-to-end Table Detection and Tabular Data Extraction from\n                                                                                  \n                Scanned Document Images. (2019, September 1). IEEE Conference Publication | IEEE\n                                                                                  \n                                                                                  \n                Xplore. https://ieeexplore.ieee.org/abstract/document/8978013     \n                                                                                  \n           Xu, Y., Li, M., Cui, L., Huang, S., Wei, F., & Zhou, M. (2020). LayoutLM: Pre-training of Text and\n                                                                                  \n                Layout for Document Image Understanding. ACM Digital Library.     \n                                                                                  \n                https://doi.org/10.1145/3394486.3403172                           \n                                                                                  \n           Liao, J., Eskimez, Ş. E., Lu, L., Shi, Y., Gong, M., Shou, L., Qu, H., & Zeng, M. (2023). Improving\n                                                                                  \n                readability for automatic speech recognition transcription. ACM Transactions on Asian and\n                                                                                  \n                Low-resource Language Information Processing, 22(5), 1–23.        \n                                                                                  \n                https://doi.org/10.1145/3557894                                   \n                                                                                  \n                                                                                  \n           El-Moneim, S. A., Nassar, M. A., Dessouky, M. I., Ismail, N. A., El‐Fishawy, A. S., & El‐Samie, F.\n                                                                                  \n                E. A. (2020). Text-independent speaker recognition using LSTM-RNN and speech\n                                                                                  \n                enhancement. Multimedia Tools and Applications, 79(33–34), 24013–24028.\n                                                                                  \n                https://doi.org/10.1007/s11042-019-08293-7                        \n                                                                                  \n           Xu, Y., Li, M., Cui, L., Huang, S., Wei, F., & Zhou, M. (2020). LayoutLM: Pre-training of Text and\n                                                                                  \n                Layout for Document Image Understanding. ACM: Digital Library.    \n                                                                                  \n                https://doi.org/10.1145/3394486.3403172                           \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                   Republic of the Philippines                    \n                           Laguna State Polytechnic University                    \n                                     Province of Laguna                           \n                                                                                  \n                                                                                  \n           Artificial Intelligence Image recognition method based on convolutional Neural network algorithm.\n                                                                                  \n                (2020). IEEE Journals & Magazine | IEEE Xplore.                   \n                                                                                  \n                https://ieeexplore.ieee.org/abstract/document/9129654             \n                                                                                  \n           Shen, Z., Zhang, R., Dell, M., Lee, B. C. G., Carlson, J., & Li, W. (2021). LayoutParser: a unified\n                                                                                  \n                toolkit for deep learning based document image analysis. In Lecture notes in computer\n                                                                                  \n                science (pp. 131–146). https://doi.org/10.1007/978-3-030-86549-8_9\n                                                                                  \n           Audebert, N., Herold, C., Slimani, K., & Vidal, C. (2020). Multimodal deep networks for text and\n                                                                                  \n                Image-Based document classification. In Communications in computer and information\n                                                                                  \n                                                                                  \n                science (pp. 427–443). https://doi.org/10.1007/978-3-030-43823-4_35\n                                                                                  \n           Li, P., Gu, J., Kuen, J., Morariu, V., I., Zhao, H., Jain, R., Manjunatha, V., & Liu, H. (2021).\n                                                                                  \n                SelfDoC: Self-Supervised Document Representation Learning.        \n                                                                                  \n                https://openaccess.thecvf.com/content/CVPR2021/html/Li_SelfDoc_Self-Supervised_Docu\n                                                                                  \n                ment_Representation_Learning_CVPR_2021_paper.html                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    P\\nroject Title: PropEase: A Smart Paperless System, Revolutionizing Topic Proposal Matching and \\nTopic Recommendations\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    T\\nopic: Document Processing, Topic Matching, Topic Recommendation, Natural Language \\nProcessing, Image Recognition, Speech Recognition\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            P\\nroponent: Cayadong, Marjelaine M., Verdad, Jane Benneth Dione\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    B. Technical Description\n6  T\\n  R\\nhe \\ntraditional  methods  of \\nresearch  proposals  and \\nthesis  defense  have  become \\nincreasingly \\ncomplicated, \\ntime-consuming, \\nand \\nexpensive.  Traditional  methods \\noften \\ninvolve \\nextensive \\npaperwork, \\nthis \\nincludes \\nprinting  and  organizing  physical  documents \\nlike  concept  papers, \\nmanuscripts,  data  collections, questionnaires, drafts of the thesis, etc.. This process is complicated, \\ntime-consuming, \\nand \\nexpensive.  Reviewing \\ndocuments  and  providing \\nfeedback  on  printed \\ndocuments  are  also  a  traditional  method  that  panelists  take  time  to  read  before  giving  comments \\nmanually  then  communicate  back  to  the  researchers.  This  back  and  forth  process  can prolong the \\nprocess of revision and refinement process of research and thesis making. \\nesearchers and academic institutions are constantly seeking more efficient and innovative ways to \\nmodernize  the  process  of  proposals and defenses. The emergence of paperless systems has opened \\nup  new  possibilities  for  revolutionizing  how  research  proposals  and  thesis  defense  are  handled in \\nacademics.  Digitizing  research  documents  enhances  efficiency  and  facilitates  easy  sharing  among \\nresearchers  and  panelists.  This  approach  enables  seamless  access  and  sharing  research documents \\nanytime  and  anywhere.  Digitized  research  documents  are  easily  retrievable  and  searchable  that \\nensures quick access to relevant information during discussion, revisions, and presentations.  Going \\npaperless reduces the expenses of having to print for a document. Paperless systems save time spent \\non  reading  printed  documents  that  panelists  can  provide  feedback  and  collaborate  remotely.  It \\noptimizes \\ntime  management  and  resource  utilization.  Adapting  to  digital  tools  and  embracing \\npaperless  processes,  promotes  eco-friendly  practices.  It  contributes to environmental sustainability \\nby  reducing  paper  consumption,  minimizing  waste,  and  lowering carbon footprint. The process of \\ntransitioning to a paperless system in university for research defense and research proposals can be \\ncomplicated  however,  by  developing  and  implementing  a  smart  paperless  system  the  process  of \\nresearch proposals and thesis defense can be much easier.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0\n0                                                                                                                                                                                                                                                                                                                                                                                                                  By making use of the power of advanced technologies such as machine learning, and data analytics, \\nthese systems can significantly enhance the efficiency, accuracy, and effectiveness of topic matching \\nand  topic  recommendations.  This  system  will  not  only  streamline  the  process  of  topic  proposal \\nmatching  but  also  provide  targeted  recommendations  tailored  to  the  unique  needs and interests of \\nresearchers,  students,  and  academic  institutions.  By  automating  tedious  tasks  and  leveraging  the \\npower  of  advanced \\ntechnologies, \\nthis \\nsmart  paperless \\nsystem  aspires \\nto  be  a  prompt \\nfor \\ntransformative  advancements \\nin  academic  discovery  and  knowledge  dissemination.  This  paper \\nexplores  the  potential  of  a  smart  paperless  system  in transforming the landscape of topic proposal \\nmatching and topic recommendations.\n1  S\\n  T\\n  T\\ntatement of the Problem: \\nhe  traditional  methods  of  topic  proposal  matching  and  topic  recommendations  in  academics  are \\noften  inconvenient,  time-consuming,  and  lack  the  efficiency  needed  to  cope  with  the  amounts  of \\ndata.  Researchers  and  panelists  face  challenges  in  accurately  matching  proposals  with  suitable \\ntopics,  leading  to  inefficiencies,  and  poor  resource  allocation.  The  absence of advanced analytical \\ncapabilities delay the ability to provide personalized and relevant recommendations to a researcher\'s \\nneeds. \\nhus, this study specifically seeks to address the following problems: \\n1.  How  can  advanced \\ntechnology  be  of  use \\nto  automate \\ntopic  proposal  matching \\nin  a \\nmodernized way of research proposal? \\n2.  How \\nwill \\nthe \\nintegration \\nof \\nadvanced \\ntechnologies \\ngenerate \\naccurate \\ntopic \\nrecommendations? \\n3.  How  will  speech  recognition  technology  be  integrated  into  the  system  to  enhance  user \\ninteraction? \\n4. \\nIn  what  way  could \\nthe \\nresearchers \\nincorporate \\nthe  model \\nthat  performs \\nthe  best,  as \\ndetermined by how well it produces accurate responses? \\n5.  How may real testing be used to assess the performance of the developed system?\n2                                                                                                                                                                                                                                                                                                                                                                   O\\n  T\\nbjectives: General and Specific General Objective: \\nhe  main  objective  of  this  study  is  to  design  and  develop  a  web-based that helps researchers and \\npanelists in the process of topic proposal and topic recommendation. Specifically, this study aims to:  \\n \\n1.  Develop a user-friendly smart paperless system leveraging the following technologies to \\nautomate and streamline the topic proposal matching process:  \\n1.1 Natural Language Processing (NLP) \\n1.2 Document Processing \\n1.3 Speech Recognition \\n1.4 Image Recognition technologies  \\n2.  Enhance the system\'s ability to understand, categorize, and analyze textual and visual data \\nwithin research proposals to generate accurate  topic recommendations. \\n3. \\nImprove accessibility and user experience by integrating Speech Recognition capabilities, \\nallowing users to interact with the system using voice recognition and natural language \\nqueries.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0\n0  P\\n   \\nTable  Detection  and  Tabular  Data  Extraction  from  Scanned  Document  Images.  Shubham, \\nS.P., et. al., 2019) \\natents \\n \\n15. The  Plagiarism  is  an  increasingly  widespread  and  growing  problem  in  the  academic  field. \\nSeveral  plagiarism \\ntechniques  are  used  by  fraudsters,  ranging  from  a  simple  synonym \\nreplacement,  sentence  structure  modification,  to  more  complex  method  involving  several \\ntypes  of  transformation.  Human  based  plagiarism  detection  is  difficult,  not  accurate,  and \\ntime-consuming  process.  In  this  paper  we propose a plagiarism detection framework based \\non  three  deep  learning  models: Doc2vec, Siamese Long Short-term Memory (SLSTM) and \\nConvolutional  Neural  Network  (CNN).  Our  system  uses  three  layers:  Preprocessing Layer \\nincluding  word  embedding,  Learning  Layers  and  Detection  Layer. To evaluate our system, \\nwe  carried  out  a  study  on  plagiarism  detection  tools  from  the  academic  field  and  make  a \\ncomparison  based  on  a  set  of  features.  Compared  to other works, our approach performs a \\ngood  accuracy  of  98.33  %  and  can  detect  different  types  of  plagiarism,  enables to specify \\nanother  dataset  and  supports  to  compare  the  document  from  an  internet  search.  (A  New \\nOnline Plagiarism Detection System based on Deep Learning. Hambi, E.M., et. al., 2020) \\n \\n16. Summarizes \\nthe  research  on  computational  methods \\nto  detect  academic  plagiarism  by \\nsystematically reviewing 239 research papers published between 2013 and 2018. To structure \\nthe  presentation  of \\nthe \\nresearch  contributions,  we  propose  novel \\ntechnically  oriented \\ntypologies for plagiarism prevention and detection efforts, the forms of academic plagiarism, \\nand  computational  plagiarism  detection  methods.  We  show \\nthat  academic  plagiarism \\ndetection  is  a  highly  active  research  field.  Over  the  period  we  review,  the  field  has  seen \\nmajor \\nadvances \\nregarding \\nthe  automated  detection  of \\nstrongly  obfuscated  and \\nthus \\nhard-to-identify  forms  of  academic  plagiarism.  These  improvements mainly originate from \\nbetter  semantic  text analysis methods, the investigation of non-textual content features, and \\nthe \\napplication \\nof  machine \\nlearning.  We \\nidentify \\na \\nresearch \\ngap \\nin \\nthe \\nlack \\nof \\nmethodologically \\nthorough \\nperformance \\nevaluations  of  plagiarism  detection \\nsystems. \\nConcluding from our analysis, we see the integration of heterogeneous analysis methods for \\ntextual  and  non-textual  content features using machine learning as the most promising area \\nfor  future  research  contributions  to  improve  the  detection  of  academic  plagiarism  further. \\n(Academic Plagiarism Detection. Foltýnek, T., et. al., 2019)\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               T\\nHow do you intend to solve the problem? \\nhe proponents of the study plan to solve the problem by developing a website/ application that will \\ngather  the  data  from  the  published thesis papers through machine learning using image processing \\nand natural language processing. The said website/ application will be acting as a grading system for \\nplagiarism for a title and concept similar to another and recommend titles that are similar to the topic \\nfor  a  new  solution  to  a  problem.  The  system  will  be  able  to  give  panelists  the idea the student is \\nportraying by using the speech to text while the proponent is giving their explanation and insight to \\ntheir concept papers. It can also scan the soft copy document to see if the concept is already existing \\nor not.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0 1 2 3 4\n0  Figure 1.1 Home page Website GUI \\nUsers are greeted with a brief overview of the website/application\'s capabilities and purpose on the \\nmain  page.  Important  sections  like  \"Proposals,\"  \"Trash,\"  \"Account,\"  and  \"Sign  Up\"  are  clearly \\nlabeled,  making  it  simple  to  navigate  to  the  functions  you  need.  In  order  to  provide  an  easy  and \\neffective user experience, users are advised to register for an account or link their emails in order to \\ngain access to other sections of the website. \\nFigure 1.2 Proposals page Website GUI \\nUsers  can  upload  files  to  the  website  for  plagiarism  checks  on  titles  and  contents  in  the proposal \\nsection. Furthermore, if a file already exists and has been uploaded and reviewed, a square-like form        \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        stemming/lemmatization  before  applying  machine  learning  algorithms  to  analyze  the  speech \\nbeing  spoken.  The  goal  is  to  check  the  accuracy  and  plagiarism  of  the  proposed  conceptual \\nframework by using speech-to-text recognition and image or text processing.\n1  T\\narget users / Beneficiaries:(Describe each Beneficiary) \\nThis  study  will  be  beneficial \\nto \\nthe \\ninstitution.  Smart  paperless  systems  aim  to  enhance  the \\nefficiency, \\ntransparency, \\nand \\neffectiveness \\nof \\nthe \\nresearch \\nproposal  matching \\nand \\ntopic \\nrecommendation process. \\n \\n1.  Administrators  or  Program  Coordinator:  The \\nsystem  can  be  effectively  used  by \\nadministrators or program managers in charge of research programs or funding initiatives to \\nhandle  proposal  submissions  and  topic  selection  procedures.  Through  the  automation  of \\nrepetitive \\noperations \\nlike  proposal  matching  and  document  processing, \\nthe \\nsystem\'s \\nautomation capabilities lessen the administrative pressure. \\n \\n2.  Panelists or Reviewers: The automation of the system, which assists in matching proposals \\nwith  relevant  topics,  will  be  helpful  to  panelists  considering  research  proposals  or  topic \\nsubmissions.  Panelists  are  able  to  efficiently  comprehend  and  evaluate  proposal  material \\nbecause  of  the  system\'s  natural  language  processing  (NLP)  capabilities,  which  guarantees \\neffective decision-making procedures. \\n \\n3.  Future  Researchers:  The  streamlined  method  of  matching \\ntopic  proposals  will  help \\nresearchers  find  relevant  study  ideas  more  quickly  and  efficiently,  saving  them  time  and \\neffort. They may analyze enormous volumes of text data, extract important information, and \\nproduce insights for their research by using the system\'s natural language processing (NLP) \\ncapabilities.  Research  papers, \\njournals,  and  other  pertinent  documents  can  be  quickly \\nreviewed and categorized by researchers with the use of document processing tools.\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              S\\nignificance of study: \\nThis study will help researchers perform efficient and well-organized research methods in addition \\nto benefiting panelists for time management and efforts. \\n \\n1.  Panelists:  The  accuracy  and  speed  with  which  panelists  connect  research  proposals  with \\nappropriate  concepts  will \\nimprove  during \\nthe  assessment  and  selection  process.  By \\nautomating  the  matching  process,  biases,  and  manual  effort  are  minimized,  resulting in an \\nequal  evaluation  of  ideas.  The  ability  to  process  papers  more  efficiently makes it easier to \\nhandle  proposal  materials,  which  improves  the  accessibility and organization of the review \\nprocess. \\n \\n2.  Researchers:  Researchers  will  save  time  and  money  thanks  to  the  process  of  matching \\nsubject proposals which is now more efficient. By utilizing NLP capabilities, researchers can \\ngain  deeper  insights  by  enhancing  their  comprehension  and  analysis  of  study  materials. \\nSpeech  and  picture  recognition  technologies  allow  users  to  engage  with  the  system  in  a \\nnatural way, which speeds up the input and retrieval of data.\n\n                                                                                                                                                            0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2     3\n0                                                                                                               TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n1                                                                                                                                 TECHNOLOGY (Speech-to-text)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n2                                                                                            Automatic Speech \\nRecognition: \\nSystematic \\nLiterature Review                                         In their systematic literature review, \\nAlharbi  et  al.  (2021)  explore \\nthe \\nadvancements \\nin \\nspeech-to-text \\nrecognition \\ntechnology, \\nhighlighting \\nits \\ntransformative \\nimpact  on  data \\ntranscription.  The \\nscope  encompasses  the  conversion \\nof  spoken  words  into  written  text \\nand \\nits  applications \\nin  analyzing \\ninterview  recordings  efficiently  for \\nfurther \\nevaluation \\nof \\napplicant \\nresponses. \\nHowever, \\nthey \\nalso \\nacknowledge \\nthe \\nchallenges \\noutlined in their research, including \\nfactors \\nsuch \\nas \\nthe \\nnumber \\nof \\nspeakers, speech clarity, vocabulary \\nsize, and spectral bandwidth, which \\ninfluence \\nthe \\nperformance \\nof \\nautomated \\nspeech \\nrecognition \\nsystems.  This  study  was  published \\nin 2021.                                                                                                                                          Alharbi \\net \\nal. \\n(2021) \\nconducted \\na \\nsystematic \\nliterature  review  focusing \\non \\nthe \\nadvancements \\nin \\nspeech-to-text \\nrecognition \\ntechnology.  Their  research \\nexplores \\nthe \\ntransformative \\nimpact \\nof \\nthis \\ntechnology \\non \\ndata \\ntranscription, \\nparticularly \\nin \\nconverting \\nspoken \\nwords into written text.  2021\n3  Challenges and \\nLimitations in \\nSpeech \\nRecognition \\nTechnology: A \\nCritical Review of \\nSpeech Signal \\nProcessing \\nAlgorithm, Tools \\nand Systems.  T\\nIn \\ntheir \\nstudy  by  Sneha  Basak, \\nHimanshi  Agrawal,  Shreya \\nJena, \\nShilpa \\nGite, \\nMrinal \\nBachute, \\nBiswajeet \\nPradhan, \\nand  Mazen \\nAssiri \\n(2022), \\nthe \\nresearchers \\nacknowledge \\nthe \\nsignificance \\nof \\nspeech \\nrecognition \\ntechnology \\nwhile  also  addressing  factors  that \\nrequire \\nattention \\nfor \\nfurther \\nimprovement.  \\nhey  highlight  challenges  such  as \\nvariation \\nin  accents,  which  pose \\ndifficulties \\nfor \\nmachines \\nto \\nunderstand \\ndifferent \\npronunciations, \\nintonations, \\nand \\naccents.  The  study  raises  concerns \\nabout the lack of speech recognition \\nsystems  designed \\nspecifically \\nfor \\nchildren, \\ndespite \\nthe \\nincreasing \\nprevalence \\nof \\ne-learning \\nand \\nchildren  spending  significant  time \\non \\nscreens.  The \\nslower  pace  at  The scope of the study \\nconducted by Sneha \\nBasak, Himanshi Agrawal, \\nShreya Jena, Shilpa Gite, \\nMrinal Bachute, Biswajeet \\nPradhan, and Mazen Assiri \\n(2022) encompasses a \\ncritical review of speech \\nrecognition technology, \\nfocusing on challenges and \\nlimitations within the field. \\nThe researchers delve into \\nvarious aspects of speech \\nsignal processing \\nalgorithms, tools, and \\nsystems, aiming to identify \\nareas that require further \\nattention for improvement.  2022\n\n                                                                                                             0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1                                                                                                                                                                                                                                                                                                                                                                 2     3\n0                                                                                                               E\\nwhich \\nchildren \\nunderstand \\nnew \\nwords \\nfurther \\ncomplicates \\nthe \\nability of current speech recognition \\nsystems \\nto \\ncomprehend \\nchild \\nvocabulary  effectively.  The  study \\ndiscusses  the  importance  of  model \\ntraining  to  avoid  overfitting, which \\ncould \\nnegatively \\nimpact \\nthe \\nperformance  of  speech  recognition \\nsystems \\nby \\nadding \\nunnecessary \\nconcepts.  \\nnvironmental noise is identified as \\nanother  significant  challenge,  as  it \\ncan \\nseverely \\naffect \\nspeech \\ntranscription \\naccuracy.  \\nThrough \\nthese \\nobservations, \\nthe \\nstudy \\nprovides  valuable  insights  into  the \\nlimitations  and  challenges \\nfacing \\nspeech \\nrecognition \\ntechnology, \\nsuggesting \\nareas \\nfor \\nfurther \\nresearch and development.                                                                                                                                                                                                                                                                                                                                                                        \n1  Multilingual \\nSpeech  Models  for \\nAutomatic \\nSpeech \\nRecognition \\nExhibit \\nGender \\nPerformance Gaps                                                                       Attanasio, \\nSavoldi, \\nFucci, \\nand \\nHovy  (2024)  address  limitations  in \\nresearch \\nrelated \\nto \\ngender \\nand \\nsocial-cultural \\nfactors \\nin \\nvoice \\nrecognition. \\nThe \\nscope \\nencompasses the need for a broader \\ndataset \\nconsidering  dialects, \\nsex, \\nand \\nother \\ncultural \\nfactors \\nto \\nimprove the results\' robustness. The \\nauthors \\nalso \\nhighlight \\nissues \\nof \\ngeneralizability \\ndue \\nto \\nthe \\ncategorization \\nof \\nparticipants \\nas \\n\"Other\" \\nand \\nthe \\ncomparison \\nof \\nspeakers  across different platforms. \\nAdditionally, \\nthey \\nstress \\nthe \\nimportance  of  data  quality  and  the \\npotential  biases  introduced  by  the \\nlack of multilingual phonetic tools.  Attanasio,  Savoldi,  Fucci, \\nand  Hovy  (2024)  address \\nthe  limitations  in  research \\nconcerning \\ngender \\nand \\nsocial-cultural \\nfactors \\nin \\nvoice \\nrecognition. \\nTheir \\nstudy \\nemphasizes \\nthe \\nnecessity \\nfor \\na \\nbroader \\ndataset \\nencompassing \\ndialects, \\nsex, \\nand \\nother \\ncultural  factors  to enhance \\nresult robustness.  2024\n2                                 Improving \\nReadability for \\nAutomatic Speech \\nRecognition \\nTranscription                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         This  research  paper  addresses  the \\nreadability \\nchallenges \\nposed \\nby \\nmodern \\nAutomatic \\nSpeech \\nRecognition  (ASR)  systems,  which \\nmay  produce  accurate \\ntranscripts \\nbut can still be difficult to read due                                                                                                                                                                                                                  The scope of the research \\npaper encompasses the \\nrealm of Automatic \\nSpeech Recognition (ASR) \\nsystems and their impact \\non readability in  2023\n\n                                                                                    0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1                                                                                                                                                                                                                            2     3\n0                                                                                                                                                                                                                                           to  grammatical  errors,  disfluency, \\nand  other  spoken  communication \\nnuances.  The  paper  introduces  the \\nASR post-processing for readability \\n(APR) \\ntask, \\nformulated \\nas \\na \\nsequence-to-sequence \\ntext \\ngeneration  problem,  with  the  goal \\nof  transforming  noisy  ASR outputs \\ninto  readable  text  while  preserving \\nsemantic  meaning. \\nThe \\nauthors \\nconstruct  a  dataset  for  APR  using \\ndata \\nfrom \\ngrammatical \\nerror \\ncorrection tasks and evaluate model \\nperformance using adapted metrics. \\nThey  compare  fine-tuned  baseline \\nmodels  with \\ntraditional \\npipeline \\nmethods,  demonstrating  significant \\nimprovements  in readability on test \\nsets  and  confirming \\ntheir  model\'s \\nefficacy  through  human  evaluation \\nand case studies.  transcripts. It delves into \\nthe challenges faced when \\nASR systems produce \\naccurate but often \\ndifficult-to-read transcripts \\ndue to grammatical errors, \\ndisfluencies, and other \\nspoken communication \\nnuances.      \n1  Text-independent \\nspeaker recognition \\nusing LSTM-RNN \\nand speech \\nenhancement  This \\nresearch \\npaper \\nexplores \\ntext-independent \\nspeaker \\nrecognition \\nin \\nthe \\ncontext \\nof \\ndegraded  speech  signals,  including \\nnoise \\nand \\nreverberation. \\nIt \\nhighlights \\nthe \\nadvantages \\nof \\ntext-independent \\nspeaker \\nrecognition \\ncompared \\nto \\ntext-dependent \\napproaches, \\nparticularly \\nin  allowing  clients  to \\nspeak \\nfreely \\nto \\nthe  system.  The \\npaper \\nemploys \\nMel-Frequency \\nCepstral \\nCoefficients \\n(MFCCs), \\nspectrum, \\nand \\nlog-spectrum \\nfor \\nfeature \\nextraction \\nfrom \\nspeech \\nsignals, \\nand \\nutilizes  Long-Short \\nTerm  Memory  Recurrent  Neural \\nNetworks \\n(LSTM-RNN) \\nfor \\nclassification \\nto \\nachieve \\nspeaker \\nrecognition. \\nThe \\nsystem \\ndemonstrates high recognition rates, \\nreaching  95.33%  with  MFCCs  and \\n98.7% \\nwith \\nspectrum \\nor \\nlog-spectrum, \\nunder \\nsimilar \\nrecording  circumstances.  However, \\nchallenges  arise  when  recognizing                           The scope of this research \\npaper is focused on \\nadvancing \\ntext-independent speaker \\nrecognition systems in the \\npresence of degraded \\nspeech signals, including \\nnoise and reverberation.  2020\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1 2 3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   speakers  across  different  recording \\nenvironments, prompting the use of \\nspeech \\nenhancement \\ntechniques \\nlike \\nspectral \\nsubtraction \\nand \\nwavelet \\ndenoising \\nto \\nimprove \\nrecognition \\nperformance. \\nThe \\nproposed \\napproach \\nshows \\nsuperiority \\nover \\nprevious \\nalgorithms,  particularly  the  one  by \\nR.  Togneri  and  D.  Pullella  (2011), \\nshowcasing \\nadvancements \\nin \\ntext-independent \\nspeaker \\nrecognition  under  degraded  speech \\nconditions.    \n1  T\\n  F\\nhe  papers  cover  a  wide  range  of  difficulties  and  developments  in  voice  recognition  technology. \\nAlharbi et al. (2021) explore how speech-to-text recognition technology can change lives, especially \\nwhen \\nit  comes \\nto  data \\ntranscription \\nfrom  recorded  interviews.  They  recognize  the  difficulties \\npresented  by  variables  that  affect  automated  speech  recognition  systems\'  performance,  such  as \\nspeech  quality,  vocabulary  quantity,  and  ambient  noise.  Basak  et  al.  (2022)  go into further detail \\nabout  these  difficulties, emphasizing problems like accent variance and the absence of kid-friendly \\nsystems.  They  also  highlight  the  shortcomings  of  the  speech  recognition  technologies  available \\ntoday and offer potential solutions like model training and mitigating background noise.  \\nurthermore,  Attanasio  et  al.  (2024)  fill  in  the  study  gaps  concerning  gender  and  social-cultural \\naspects of speech recognition, highlighting the necessity of larger datasets and better data quality to \\nincrease \\nthe  voice  recognition  systems\'  resilience  and  applicability.  Conversely,  a  study  on \\nAutomatic \\nSpeech \\nRecognition \\n(ASR) \\npost-processing \\nfor \\nreadability \\npresents \\nthe \\nASR \\npost-processing  for  readability  (APR)  challenge,  which  aims  to  correct  grammatical  errors  and \\ndisfluency  in  ASR  outputs  in  order  to  make  them  more  readable.  The state of speaker recognition \\ntechnology is further demonstrated by a study on text-independent speaker recognition in degraded \\nspeech  signals,  which  uses  methods \\nlike  Mel-Frequency  Cepstral  Coefficients  (MFCCs)  and \\nLong-Short  Term  Memory  Recurrent  Neural  Networks  (LSTM-RNN)  to  achieve  high  recognition \\nrates even in difficult environments.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n\n                                                                                    0                                                                                                                                                                                                                                                                                                                                              1                                                                                                                                                                                                                                                2     3\n0                                       TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n1                                                       TECHNOLOGY (Image Processing)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n2  LayoutLM: \\nPre-training of Text \\nand Layout for \\nDocument Image \\nUnderstanding  The \\nresearch \\npaper \\nintroduces \\nLayoutLM,  a  novel  approach  that \\nextends  pre-training \\ntechniques  to \\nencompass \\nlayout \\nand \\nstyle \\ninformation \\ncrucial \\nfor \\nunderstanding \\ndocument \\nimages. \\nUnlike \\nexisting \\nmethods \\nthat \\nmainly  focus  on  text  manipulation, \\nLayoutLM \\nincorporates \\ntext \\nand  The scope of this research \\npaper is centered around \\naddressing the limitations \\nof pre-training techniques \\nin natural language \\nprocessing (NLP) that \\npredominantly focus on \\ntext-level manipulation, \\nneglecting layout and style  2020\n\n                                                                                                              0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1                                                                                                                                                                                                                                                                                  2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              layout interactions, enhancing tasks \\nlike \\ninformation \\nextraction \\nfrom \\nscanned \\ndocuments. \\nIt \\nalso \\nintegrates image features to capture \\nvisual \\ninformation  alongside \\ntext. \\nThis \\ncomprehensive \\nframework \\nachieves \\nstate-of-the-art \\nresults \\nacross \\nvarious \\ndocument \\nunderstanding \\ntasks  such  as  form \\nunderstanding, \\nreceipt \\nunderstanding, and document image \\nclassification.                                                                                                                                                                                                                          information crucial for \\ndocument image \\nunderstanding.      \n1  Artificial \\nIntelligence Image \\nRecognition \\nMethod Based on \\nConvolutional \\nNeural Network \\nAlgorithm  This \\nresearch  paper \\nintroduces  a \\nnovel  convolutional neural network \\n(CNN) \\nalgorithm \\naimed \\nat \\nenhancing  convergence  speed  and \\nrecognition accuracy. The algorithm \\nintegrates \\na \\nrecurrent \\nneural \\nnetwork \\n(RNN) \\ninto \\nthe  CNN \\narchitecture, \\nenabling \\nparallel \\nlearning  of  deep \\nimage \\nfeatures. \\nAdditionally,  inspired  by  ResNet\'s \\nskip  connections,  a  new \\nresidual \\nmodule  called ShortCut3-ResNet is \\ndeveloped \\nto \\nfurther \\noptimize \\nfeature \\nextraction. \\nA \\ndual \\noptimization model is formulated to \\nintegrate \\nconvolution \\nand \\nfull \\nconnection \\nprocesses \\neffectively. \\nThrough \\nsimulation \\nexperiments, \\nthe  paper  analyzes \\nthe \\nimpact  of \\nvarious \\nCNN \\nparameters \\non \\nnetwork \\nperformance, \\nidentifying \\noptimal settings.  The scope of the research \\npaper encompasses the \\ndevelopment and \\nevaluation of a novel \\nconvolutional neural \\nnetwork (CNN) algorithm \\nthat integrates recurrent \\nneural networks (RNNs) \\nand ResNet-inspired \\nresidual modules to \\nenhance image processing \\ntasks.  2020\n2                       LayoutParser: A \\nUnified Toolkit for \\nDeep Learning \\nBased Document \\nImage Analysis                                                                                                                                                                                                                                                                                                                               This \\nresearch \\npaper \\nintroduces \\nLayoutParser, \\nan \\nopen-source \\nlibrary \\ndesigned \\nto \\nsimplify \\nthe \\napplication  of  deep  learning  (DL) \\nmodels in document image analysis \\n(DIA).  The \\npaper \\naddresses \\nthe \\nchallenges of code organization and \\nmodel  complexity \\nthat  hinder  the \\neasy  deployment  and  reuse  of  DL \\ninnovations \\nin \\nDIA \\nresearch. \\nLayoutParser \\noffers \\nintuitive \\ninterfaces  for  utilizing  DL  models \\nin \\nlayout \\ndetection, \\ncharacter                                                                                                        The scope of this research \\npaper lies in addressing the \\nchallenges faced in \\ndocument image analysis \\n(DIA) due to the \\ncomplexity of neural \\nnetwork applications.  2021\n\n                                                                                     0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1                                                                                                                                                                                                                                                                                                                                                           2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  recognition, \\nand \\nother \\ndocument-processing \\ntasks. \\nThe \\nlibrary  also  includes  a  platform for \\nsharing  pre-trained  models  and full \\ndocument \\ndigitization \\npipelines, \\nenhancing \\nextensibility \\nand \\ncollaboration \\nwithin \\nthe \\nDIA \\ncommunity.                                                                                                                                                                                                                                                                                                                                                                  \n1  M\\nultimodal Deep \\nNetworks for Text \\nand Image-Based \\nDocument \\nClassification  This \\nresearch \\npaper \\npresents \\na \\nnovel \\napproach \\nto \\ndocument \\nclassification  by \\nintegrating  both \\ntext  and  visual \\ninformation.  The \\nproposed \\npipeline \\nutilizes \\noff-the-shelf  architectures  to  create \\na \\nmultimodal \\nneural \\nnetwork \\ncapable \\nof \\nlearning \\nfrom \\nboth \\nimage  data  and  word  embeddings \\nextracted  from  noisy  text  obtained \\nthrough \\nOCR. \\nThe \\nresearch \\ndemonstrates \\nsignificant \\nimprovements \\nin \\nclassification \\naccuracy \\non \\ndatasets \\nlike \\nTobacco3482  and  RVL-CDIP,  even \\nin \\ncases \\nwhere \\nclean \\ntext \\ninformation \\nis \\nunavailable. \\nThe \\npaper also releases a post-OCR text \\nclassification  dataset  to  encourage \\nfurther \\nresearch \\nin  multi-modal \\ntext/image classification.  The scope of this research \\npaper is to address the \\nchallenges in fine-grained \\ndocument classification by \\nleveraging both text and \\nvisual information. It \\nacknowledges the \\nlimitations of visual \\nanalysis alone in achieving \\naccurate document \\nclassification, especially \\nwhen dealing with \\ndocuments lacking clean \\ndigital text.  2020\n2                    SelfDoc: \\nSelf-Supervised \\nDocument \\nRepresentation \\nLearning                                                                                                                       SelfDoc \\nis \\na \\nnovel \\npre-training \\nframework  designed  for  document \\nimage  understanding that addresses \\nthe multimodal nature of documents \\nand \\ntheir \\nintended \\nsequential \\nreading.  Unlike \\nexisting  models \\nthat \\nfocus \\non \\nindividual  words, \\nSelfDoc \\ntakes \\na \\ncoarse-grained \\napproach  to  capture  the  positional, \\ntextual,  and  visual  information  of \\nsemantically \\nmeaningful \\ncomponents \\nin \\ndocuments  while \\navoiding \\nexcessive \\ncontextualization. \\nIt \\nincorporates \\ncross-modal \\nlearning \\nduring \\npre-training  to leverage multimodal \\ninformation \\nfrom \\nunlabeled \\ndocuments \\nand \\nintroduces \\na                                                                                                                                                                        The scope of this research \\npaper encompasses the \\ndevelopment and \\nevaluation of a \\ntask-agnostic pre-training \\nframework called SelfDoc \\nfor document image \\nunderstanding.  2021\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               modality-adaptive \\nattention \\nmechanism \\nfor \\neffective \\nfeature \\nfusion.\n1  T\\n  A\\n   \\nhe  papers  discussed  here  offer  a  variety  of  modern  techniques  for  analyzing  and  understanding \\ndocument  images.  First off, LayoutLM presents a thorough framework that expands on pre-training \\nmethods  to  include  style  and  layout  data  in  addition to text, leading to better results on a range of \\ndocument  comprehension  tasks.  In tasks like form understanding and transaction comprehension, it \\nachieves \\nstate-of-the-art  outcomes  by \\nskillfully  combining \\ntext, \\nlayout,  and \\nimage  elements. \\nFurthermore,  a  unique  convolutional  neural  network  (CNN)  algorithm  is  put  forth  to  improve \\nrecognition  accuracy  and speed of convergence. It combines residual modules and recurrent neural \\nnetworks (RNNs) for optimal feature extraction, and simulation experiments are used to illustrate the \\neffects of different CNN factors on network performance. \\ndditionally,  LayoutParser  offers  an  open-source  library  with  user-friendly  interfaces  for  layout \\ndetection,  character  recognition,  and  other  document  processing  tasks,  addressing  the  difficulties \\nassociated with using deep learning models in document picture analysis. LayoutParser makes deep \\nlearning  advancements \\nin  document \\nimage  analysis  research  easier \\nto  apply  and  reuse  by \\nstreamlining  code  organization  and  model  complexity.  Additionally,  a  multimodal  neural  network \\narchitecture is used to leverage both text and visual input in a novel way for document classification. \\nThis method produces notable gains in classification accuracy even in the absence of clear text data, \\nproving the usefulness of combining several modalities for tasks involving document understanding. \\nLast  but  not  least,  SelfDoc  offers  a  pre-training  framework  created  especially for document image \\nunderstanding. It uses modality-adaptive attention mechanisms and cross-modal learning to capture \\nthe  visual  and  textual  information  of  semantically  significant  document  components,  improving \\nstate-of-the-art document image understanding tasks.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Citation of Resources Gathered\n1  Attention in natural language processing. (2021, October 1). IEEE Journals & Magazine | IEEE \\nXplore. https://ieeexplore.ieee.org/abstract/document/9194070 \\nBohra, A., & Barwar, N. C. (2022). A deep learning approach for plagiarism detection system using \\nBERT. In Lecture notes on data engineering and communications technologies (pp. \\n163–174). https://doi.org/10.1007/978-981-16-9113-3_13 \\nCalicdan, L. C., Bacaro, R. M. R., Ramo, D. C., & Licayan, R. J. (2021). Sensitivity Towards \\nSociocultural Plagiarism in the Context of Varied Discipline among College Students. \\nInternational Journal of Asian Education, 2(2), 244–255. \\nhttps://doi.org/10.46966/ijae.v2i2.121', 'our proposal is about topic matching and oh no title proposal entitled recommendation so our system will check if there is an existing thesis title or thesis paper about the proponents proposal so the system will generate a recommended title or topic for a better suggestion for the proponents and then we also have speech to text conversion which at the user or the panelist\nwill the panelist will check if the said speech to text is similar to the proponents proposal and then magde-generate na siya ng mga statistics about doon sa papel atsaka disa speech yung\nmga key discrepancies kung saan meron silang sinabi na wala naman sa papel or kaya wala sa papel pero sinabi nila and then our proposal is also about checking whether uh that title proposal and the speech to text conversion is similar to each other if not there will be the key discrepancies which is in the scoring or the analysis and then\nthe user can also upload multiple files but the system can only accept pdf files so this process is complicated time consuming and expensive so ang idea po namin about this proposal is that we\'re making it paperless which is why topic proposal are title proposal defenses are being converted to online which is our proposal\n\nwhy is my speech to text not working\ni would like to update what i wanted to say in our proposal and that is that or proposal has this updated teacher where the proponent gets to see what needs like to be a family\ni hope this is still working because i\'m not sure what i\'m going to do if it\'s not\nhello hello\nsana nagana pa ito\nhello\n\nhello\n', '{\"similarity_score\": 0, \"missing_in_paper\": [\"our\", \"proposal\", \"about\", \"oh\", \"no\", \"title\", \"proposal\", \"entitled\", \"recommendation\", \"so\", \"our\", \"check\", \"if\", \"there\", \"is\", \"an\", \"existing\", \"thesis\", \"title\", \"or\", \"thesis\", \"paper\", \"about\", \"the\", \"proponents\", \"proposal\", \"so\", \"the\", \"will\", \"generate\", \"recommended\", \"title\", \"or\", \"better\", \"suggestion\", \"for\", \"the\", \"proponents\", \"and\", \"then\", \"we\", \"also\", \"have\", \"speech\", \"to\", \"text\", \"conversion\", \"which\", \"at\", \"the\", \"user\", \"or\", \"the\", \"panelist\", \"will\", \"the\", \"panelist\", \"will\", \"check\", \"if\", \"the\", \"said\", \"speech\", \"to\", \"text\", \"is\", \"similar\", \"to\", \"the\", \"proponents\", \"proposal\", \"and\", \"then\", \"magde-generate\", \"na\", \"siya\", \"ng\", \"mga\", \"statistics\", \"about\", \"doon\", \"sa\", \"papel\", \"atsaka\", \"disa\", \"speech\", \"yung\", \"mga\", \"key\", \"discrepancies\", \"kung\", \"saan\", \"meron\", \"silang\", \"sinabi\", \"na\", \"wala\", \"naman\", \"sa\", \"papel\", \"or\", \"kaya\", \"wala\", \"sa\", \"papel\", \"pero\", \"sinabi\", \"nila\", \"and\", \"then\", \"our\", \"proposal\", \"is\", \"also\", \"about\", \"checking\", \"whether\", \"uh\", \"that\", \"title\", \"proposal\", \"and\", \"the\", \"speech\", \"to\", \"text\", \"conversion\", \"is\", \"similar\", \"to\", \"each\", \"other\", \"if\", \"not\", \"there\", \"the\", \"key\", \"discrepancies\", \"which\", \"is\", \"in\", \"the\", \"scoring\", \"or\", \"the\", \"analysis\", \"and\", \"then\", \"the\", \"user\", \"upload\", \"multiple\", \"files\", \"but\", \"the\", \"system\", \"can\", \"only\", \"accept\", \"pdf\", \"files\", \"so\", \"this\", \"process\", \"complicated\", \"time\", \"consuming\", \"expensive\", \"so\", \"ang\", \"idea\", \"po\", \"namin\", \"about\", \"this\", \"proposal\", \"is\", \"that\", \"we\'re\", \"paperless\", \"which\", \"is\", \"why\", \"topic\", \"proposal\", \"title\", \"proposal\", \"defenses\", \"are\", \"converted\", \"online\", \"which\", \"is\", \"our\", \"proposal\"], \"missing_in_speech\": [\"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"concept\", \"paper\", \"a.\", \"basic\", \"information\", \"project\", \"title:\", \"propease:\", \"a\", \"smart\", \"paperless\", \"system,\", \"revolutionizing\", \"topic\", \"proposal\", \"matching\", \"and\", \"topic\", \"recommendations\", \"topic:\", \"document\", \"processing,\", \"topic\", \"matching,\", \"topic\", \"recommendation,\", \"natural\", \"language\", \"processing,\", \"image\", \"recognition,\", \"speech\", \"recognition\", \"proponent:\", \"cayadong,\", \"marjelaine\", \"m.,\", \"verdad,\", \"jane\", \"benneth\", \"dione\", \"b.\", \"technical\", \"description\", \"the\", \"traditional\", \"methods\", \"of\", \"research\", \"proposals\", \"and\", \"thesis\", \"defense\", \"have\", \"become\", \"increasingly\", \"complicated,\", \"time-consuming,\", \"and\", \"expensive.\", \"traditional\", \"methods\", \"often\", \"involve\", \"extensive\", \"paperwork,\", \"this\", \"includes\", \"printing\", \"and\", \"organizing\", \"physical\", \"documents\", \"like\", \"concept\", \"papers,\", \"manuscripts,\", \"data\", \"collections,\", \"questionnaires,\", \"drafts\", \"of\", \"the\", \"thesis,\", \"etc..\", \"this\", \"process\", \"complicated,\", \"time-consuming,\", \"and\", \"expensive.\", \"reviewing\", \"documents\", \"and\", \"providing\", \"feedback\", \"on\", \"printed\", \"documents\", \"are\", \"also\", \"a\", \"traditional\", \"method\", \"that\", \"panelists\", \"take\", \"time\", \"to\", \"read\", \"before\", \"giving\", \"comments\", \"manually\", \"then\", \"communicate\", \"back\", \"to\", \"the\", \"researchers.\", \"this\", \"back\", \"and\", \"forth\", \"process\", \"can\", \"prolong\", \"the\", \"process\", \"of\", \"revision\", \"and\", \"refinement\", \"process\", \"of\", \"research\", \"and\", \"thesis\", \"making.\", \"researchers\", \"and\", \"academic\", \"institutions\", \"are\", \"constantly\", \"seeking\", \"more\", \"efficient\", \"and\", \"innovative\", \"ways\", \"to\", \"modernize\", \"the\", \"process\", \"of\", \"proposals\", \"and\", \"defenses.\", \"the\", \"emergence\", \"of\", \"paperless\", \"systems\", \"has\", \"opened\", \"up\", \"new\", \"possibilities\", \"for\", \"revolutionizing\", \"how\", \"research\", \"proposals\", \"and\", \"thesis\", \"defense\", \"are\", \"handled\", \"in\", \"academics.\", \"digitizing\", \"research\", \"documents\", \"enhances\", \"efficiency\", \"and\", \"facilitates\", \"easy\", \"sharing\", \"among\", \"researchers\", \"and\", \"panelists.\", \"this\", \"approach\", \"enables\", \"seamless\", \"access\", \"and\", \"sharing\", \"research\", \"documents\", \"anytime\", \"and\", \"anywhere.\", \"digitized\", \"research\", \"documents\", \"are\", \"easily\", \"retrievable\", \"and\", \"searchable\", \"that\", \"ensures\", \"quick\", \"access\", \"to\", \"relevant\", \"information\", \"during\", \"discussion,\", \"revisions,\", \"and\", \"presentations.\", \"going\", \"paperless\", \"reduces\", \"the\", \"expenses\", \"of\", \"having\", \"to\", \"print\", \"for\", \"a\", \"document.\", \"paperless\", \"systems\", \"save\", \"time\", \"spent\", \"on\", \"reading\", \"printed\", \"documents\", \"that\", \"panelists\", \"can\", \"provide\", \"feedback\", \"and\", \"collaborate\", \"remotely.\", \"it\", \"optimizes\", \"time\", \"management\", \"and\", \"resource\", \"utilization.\", \"adapting\", \"to\", \"digital\", \"tools\", \"and\", \"embracing\", \"paperless\", \"processes,\", \"promotes\", \"eco-friendly\", \"practices.\", \"it\", \"contributes\", \"to\", \"environmental\", \"sustainability\", \"by\", \"reducing\", \"paper\", \"consumption,\", \"minimizing\", \"waste,\", \"and\", \"lowering\", \"carbon\", \"footprint.\", \"the\", \"process\", \"of\", \"transitioning\", \"to\", \"a\", \"paperless\", \"system\", \"in\", \"university\", \"for\", \"research\", \"defense\", \"and\", \"research\", \"proposals\", \"can\", \"be\", \"complicated\", \"however,\", \"by\", \"developing\", \"and\", \"implementing\", \"a\", \"smart\", \"paperless\", \"system\", \"the\", \"process\", \"of\", \"research\", \"proposals\", \"and\", \"thesis\", \"defense\", \"can\", \"be\", \"much\", \"easier.\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"by\", \"making\", \"use\", \"of\", \"the\", \"power\", \"of\", \"advanced\", \"technologies\", \"such\", \"as\", \"machine\", \"learning,\", \"and\", \"data\", \"analytics,\", \"these\", \"systems\", \"can\", \"significantly\", \"enhance\", \"the\", \"efficiency,\", \"accuracy,\", \"and\", \"effectiveness\", \"of\", \"topic\", \"recommendations.\", \"this\", \"not\", \"only\", \"streamline\", \"the\", \"process\", \"of\", \"topic\", \"proposal\", \"matching\", \"but\", \"also\", \"provide\", \"targeted\", \"recommendations\", \"tailored\", \"to\", \"the\", \"unique\", \"needs\", \"and\", \"interests\", \"of\", \"researchers,\", \"students,\", \"and\", \"academic\", \"institutions.\", \"by\", \"automating\", \"tedious\", \"tasks\", \"and\", \"leveraging\", \"the\", \"power\", \"of\", \"advanced\", \"technologies,\", \"this\", \"smart\", \"paperless\", \"aspires\", \"to\", \"be\", \"prompt\", \"for\", \"transformative\", \"advancements\", \"in\", \"academic\", \"discovery\", \"and\", \"knowledge\", \"dissemination.\", \"this\", \"paper\", \"explores\", \"the\", \"potential\", \"of\", \"a\", \"smart\", \"paperless\", \"system\", \"in\", \"transforming\", \"the\", \"landscape\", \"of\", \"topic\", \"proposal\", \"matching\", \"and\", \"topic\", \"recommendations.\", \"statement\", \"of\", \"the\", \"problem:\", \"the\", \"traditional\", \"methods\", \"of\", \"topic\", \"proposal\", \"matching\", \"and\", \"topic\", \"recommendations\", \"in\", \"academics\", \"are\", \"often\", \"inconvenient,\", \"time-consuming,\", \"and\", \"lack\", \"the\", \"efficiency\", \"needed\", \"to\", \"cope\", \"with\", \"the\", \"amounts\", \"of\", \"data.\", \"researchers\", \"and\", \"panelists\", \"face\", \"challenges\", \"in\", \"accurately\", \"matching\", \"proposals\", \"with\", \"suitable\", \"topics,\", \"leading\", \"to\", \"inefficiencies,\", \"and\", \"poor\", \"resource\", \"allocation.\", \"the\", \"absence\", \"of\", \"advanced\", \"analytical\", \"capabilities\", \"delay\", \"the\", \"ability\", \"to\", \"provide\", \"personalized\", \"and\", \"relevant\", \"recommendations\", \"to\", \"a\", \"researcher\'s\", \"needs.\", \"thus,\", \"this\", \"study\", \"specifically\", \"seeks\", \"to\", \"address\", \"the\", \"following\", \"problems:\", \"1.\", \"how\", \"can\", \"advanced\", \"technology\", \"be\", \"of\", \"use\", \"to\", \"automate\", \"topic\", \"proposal\", \"matching\", \"in\", \"a\", \"modernized\", \"way\", \"of\", \"research\", \"proposal?\", \"2.\", \"how\", \"will\", \"the\", \"integration\", \"of\", \"advanced\", \"technologies\", \"generate\", \"accurate\", \"topic\", \"recommendations?\", \"3.\", \"how\", \"will\", \"speech\", \"recognition\", \"technology\", \"be\", \"integrated\", \"into\", \"the\", \"system\", \"to\", \"enhance\", \"user\", \"interaction?\", \"4.\", \"in\", \"what\", \"way\", \"could\", \"the\", \"researchers\", \"incorporate\", \"the\", \"model\", \"that\", \"performs\", \"the\", \"best,\", \"as\", \"determined\", \"by\", \"how\", \"well\", \"it\", \"produces\", \"accurate\", \"responses?\", \"5.\", \"how\", \"may\", \"real\", \"testing\", \"be\", \"used\", \"to\", \"assess\", \"the\", \"performance\", \"of\", \"the\", \"developed\", \"system?\", \"objectives:\", \"general\", \"and\", \"specific\", \"general\", \"objective:\", \"the\", \"main\", \"objective\", \"of\", \"this\", \"study\", \"is\", \"to\", \"design\", \"and\", \"develop\", \"a\", \"web-based\", \"that\", \"helps\", \"researchers\", \"and\", \"panelists\", \"in\", \"the\", \"process\", \"of\", \"topic\", \"proposal\", \"and\", \"topic\", \"recommendation.\", \"specifically,\", \"this\", \"study\", \"aims\", \"to:\", \"1.\", \"develop\", \"a\", \"user-friendly\", \"smart\", \"paperless\", \"system\", \"leveraging\", \"the\", \"following\", \"technologies\", \"to\", \"automate\", \"and\", \"streamline\", \"the\", \"topic\", \"proposal\", \"matching\", \"process:\", \"1.1\", \"natural\", \"language\", \"processing\", \"(nlp)\", \"1.2\", \"document\", \"processing\", \"1.3\", \"speech\", \"recognition\", \"1.4\", \"image\", \"recognition\", \"technologies\", \"2.\", \"enhance\", \"the\", \"system\'s\", \"ability\", \"to\", \"understand,\", \"categorize,\", \"and\", \"analyze\", \"textual\", \"and\", \"visual\", \"data\", \"within\", \"research\", \"proposals\", \"to\", \"generate\", \"accurate\", \"topic\", \"recommendations.\", \"3.\", \"improve\", \"accessibility\", \"and\", \"user\", \"experience\", \"by\", \"integrating\", \"speech\", \"recognition\", \"capabilities,\", \"allowing\", \"users\", \"to\", \"interact\", \"with\", \"the\", \"system\", \"using\", \"voice\", \"recognition\", \"and\", \"natural\", \"language\", \"queries.\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"4.\", \"optimize\", \"resource\", \"allocation\", \"and\", \"research\", \"productivity\", \"by\", \"providing\", \"researchers\", \"and\", \"students\", \"with\", \"timely\", \"and\", \"relevant\", \"topic\", \"recommendations\", \"based\", \"on\", \"their\", \"preferences,\", \"areas\", \"of\", \"interest,\", \"and\", \"expertise.\", \"5.\", \"evaluate\", \"the\", \"system\'s\", \"performance\", \"through\", \"user\", \"feedback,\", \"usability\", \"testing,\", \"and\", \"metrics\", \"such\", \"as\", \"accuracy,\", \"efficiency,\", \"and\", \"user\", \"satisfaction\", \"to\", \"ensure\", \"continuous\", \"improvement\", \"and\", \"refinement.\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"how\", \"did\", \"others\", \"solve\", \"the\", \"problem?\", \"1.\", \"plagiarism\", \"is\", \"a\", \"common\", \"problem\", \"in\", \"the\", \"modern\", \"age.\", \"with\", \"the\", \"advance\", \"of\", \"the\", \"internet,\", \"it\", \"is\", \"more\", \"and\", \"more\", \"convenient\", \"to\", \"access\", \"other\", \"people\\u2019s\", \"writings\", \"or\", \"publications.\", \"when\", \"someone\", \"uses\", \"the\", \"content\", \"of\", \"a\", \"text\", \"in\", \"an\", \"undesirable\", \"way,\", \"plagiarism\", \"may\", \"occur.\", \"plagiarism\", \"infringes\", \"intellectual\", \"property\", \"rights,\", \"so\", \"it\", \"is\", \"a\", \"serious\", \"problem\", \"nowadays.\", \"however,\", \"detecting\", \"plagiarism\", \"effectively\", \"is\", \"challenging\", \"work.\", \"traditional\", \"methods,\", \"like\", \"vector\", \"space\", \"model\", \"or\", \"bag-of-words,\", \"are\", \"short\", \"of\", \"providing\", \"a\", \"good\", \"solution\", \"due\", \"to\", \"the\", \"incapability\", \"of\", \"handling\", \"the\", \"semantics\", \"of\", \"words\", \"satisfactorily.\", \"in\", \"this\", \"paper,\", \"we\", \"propose\", \"a\", \"new\", \"method\", \"for\", \"plagiarism\", \"detection.\", \"we\", \"use\", \"word2vec\", \"to\", \"transform\", \"the\", \"words\", \"into\", \"word\", \"vectors\", \"which\", \"are\", \"able\", \"to\", \"reveal\", \"the\", \"semantic\", \"relationship\", \"among\", \"different\", \"words.\", \"through\", \"word\", \"vectors,\", \"words\", \"are\", \"clustered\", \"into\", \"concepts.\", \"then\", \"documents\", \"and\", \"their\", \"paragraphs\", \"are\", \"represented\", \"in\", \"terms\", \"of\", \"concepts,\", \"and\", \"plagiarism\", \"detection\", \"can\", \"be\", \"done\", \"more\", \"effectively.\", \"a\", \"number\", \"of\", \"experiments\", \"are\", \"conducted\", \"to\", \"demonstrate\", \"the\", \"good\", \"performance\", \"of\", \"our\", \"proposed\", \"method.\", \"(using\", \"word\", \"semantic\", \"concepts\", \"for\", \"plagiarism\", \"detection\", \"in\", \"text\", \"documents.\", \"c.\", \"w.\", \"d.,\", \"lee,\", \"s.,\", \"et.\", \"al.,\", \"2021)\", \"2.\", \"in\", \"education,\", \"students\", \"attempt\", \"to\", \"copy\", \"previous\", \"works\", \"and\", \"are\", \"relying\", \"on\", \"prepared\", \"solutions\", \"available\", \"on\", \"the\", \"internet\", \"in\", \"order\", \"to\", \"meet\", \"their\", \"requirements.\", \"this\", \"action\", \"leads\", \"to\", \"plagiarism,\", \"which\", \"is\", \"becoming\", \"part\", \"of\", \"educational\", \"institutions\\u2019\", \"concern\", \"to\", \"reduce\", \"growing\", \"academic\", \"dishonesty.\", \"the\", \"developed\", \"system\", \"is\", \"composed\", \"of\", \"three\", \"main\", \"modules;\", \"the\", \"document\", \"search\", \"which\", \"enables\", \"users\", \"to\", \"browse\", \"documents,\", \"the\", \"document\", \"registration\", \"which\", \"enables\", \"the\", \"administrator\", \"to\", \"add\", \"and\", \"manage\", \"the\", \"stored\", \"documents,\", \"and\", \"the\", \"document\", \"comparison,\", \"which\", \"serves\", \"as\", \"the\", \"system\", \"plagiarism\", \"detection\", \"mechanism.\", \"(theses\", \"and\", \"capstone\", \"projects\", \"plagiarism\", \"checker\", \"using\", \"kolmogorov\", \"complexity\", \"algorithm.\", \"del\", \"rosario,\", \"et.\", \"al.,\", \"2020)\", \"3.\", \"issues\", \"on\", \"plagiarism\", \"among\", \"pre-service\", \"teachers\", \"(psts)\", \"have\", \"increased\", \"in\", \"modular\", \"and\", \"online\", \"learning.\", \"to\", \"confirm\", \"this,\", \"the\", \"study\", \"determined\", \"the\", \"psts\\u2019\", \"level\", \"of\", \"awareness\", \"on\", \"plagiarism;\", \"their\", \"knowledge\", \"on\", \"referencing\", \"and\", \"citation;\", \"and\", \"the\", \"correlation\", \"between\", \"their\", \"level\", \"of\", \"awareness\", \"on\", \"plagiarism\", \"and\", \"knowledge\", \"on\", \"referencing\", \"and\", \"citation,\", \"with\", \"their\", \"academic\", \"performance.\", \"the\", \"study\", \"employed\", \"a\", \"descriptive-correlational\", \"research\", \"design\", \"participated\", \"by\", \"235\", \"psts\", \"randomly\", \"sampled\", \"through\", \"strata.\", \"(ctrl\", \"c\", \"+\", \"ctrl\", \"v:\", \"plagiarism\", \"and\", \"knowledge\", \"on\", \"referencing\", \"and\", \"citation\", \"among\", \"pre-service\", \"teachers.\", \"pentang,\", \"j.,\", \"et.\", \"al.,\", \"2022)\", \"4.\", \"socio-cultural\", \"plagiarism\", \"provides\", \"an\", \"understanding\", \"of\", \"the\", \"social\", \"values\", \"and\", \"attitudes\", \"among\", \"students\", \"in\", \"academic\", \"writing.\", \"based\", \"on\", \"the\", \"rules\", \"and\", \"regulations\", \"of\", \"any\", \"academic\", \"institution,\", \"adequate\", \"awareness\", \"of\", \"different\", \"forms\", \"of\", \"plagiarism,\", \"citation\", \"techniques,\", \"paraphrasing,\", \"and\", \"other\", \"instances\", \"of\", \"copyright\", \"infringement\", \"should\", \"be\", \"tailored\", \"to\", \"any\", \"type\", \"of\", \"violation\", \"against\", \"conduct\", \"and\", \"discipline,\", \"particularly\", \"in\", \"cheating.\", \"(sensitivity\", \"towards\", \"sociocultural\", \"plagiarism\", \"in\", \"the\", \"context\", \"of\", \"varied\", \"discipline\", \"among\", \"college\", \"students.\", \"calicdan,\", \"l.\", \"c.,\", \"et.\", \"al.,\", \"2021)\", \"5.\", \"citing\", \"sources\", \"can\", \"solidify\", \"claims\", \"and\", \"make\", \"a\", \"research\", \"paper\", \"credible.\", \"failing\", \"to\", \"credit\", \"the\", \"ideas\", \"of\", \"others\", \"is\", \"a\", \"form\", \"of\", \"plagiarism,\", \"which\", \"was\", \"a\", \"common\", \"problem\", \"among\", \"students\", \"in\", \"the\", \"past\", \"until\", \"today.\", \"citing\", \"sources\", \"can\", \"solidify\", \"claims\", \"and\", \"make\", \"a\", \"research\", \"paper\", \"credible.\", \"failing\", \"to\", \"credit\", \"the\", \"ideas\", \"of\", \"others\", \"is\", \"a\", \"form\", \"of\", \"plagiarism,\", \"which\", \"was\", \"a\", \"common\", \"problem\", \"among\", \"students\", \"in\", \"the\", \"past\", \"until\", \"today.\", \"ideas\", \"are\", \"considered\", \"intellectual\", \"property,\", \"and\", \"there\", \"can\", \"be\", \"severe\", \"repercussions\", \"if\", \"one\", \"fails\", \"to\", \"cite\", \"where\", \"you\", \"got\", \"an\", \"idea\", \"from.\", \"plagiarism\", \"is\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"common\", \"in\", \"academic\", \"writing\", \"because\", \"of\", \"the\", \"lack\", \"of\", \"knowledge\", \"about\", \"citing\", \"sources.\", \"(students\\u2019\", \"knowledge\", \"in\", \"citing\", \"sources\", \"at\", \"st.\", \"paul\", \"university.\", \"mejorada,\", \"e.,\", \"et.\", \"al.,\", \"2023)\", \"6.\", \"now\", \"a\", \"day\\u2019s\", \"plagiarism\", \"became\", \"very\", \"common\", \"in\", \"many\", \"fields\", \"of\", \"life\", \"such\", \"as\", \"research\", \"and\", \"educational\", \"fields.\", \"due\", \"to\", \"the\", \"advancement\", \"in\", \"plagiarism\", \"techniques\", \"adopted\", \"by\", \"plagiarists,\", \"it\", \"is\", \"very\", \"difficult\", \"to\", \"detect\", \"plagiarism\", \"accurately\", \"by\", \"the\", \"existing\", \"technique.\", \"different\", \"features\", \"are\", \"observed\", \"while\", \"checking\", \"plagiarism\", \"such\", \"as\", \"syntactic,\", \"lexical,\", \"semantic,\", \"and\", \"structural\", \"features.\", \"(plagiarism\", \"detection\", \"using\", \"natural\", \"language\", \"processing\", \"techniques.\", \"ilyas,\", \"m.,\", \"et.\", \"al.,\", \"2021)\", \"7.\", \"paraphrase\", \"identification\", \"or\", \"natural\", \"language\", \"sentence\", \"matching\", \"(nlsm)\", \"is\", \"one\", \"of\", \"the\", \"important\", \"and\", \"challenging\", \"tasks\", \"in\", \"natural\", \"language\", \"processing\", \"where\", \"the\", \"task\", \"is\", \"to\", \"identify\", \"if\", \"a\", \"sentence\", \"is\", \"a\", \"paraphrase\", \"of\", \"another\", \"sentence\", \"in\", \"a\", \"given\", \"pair\", \"of\", \"sentences.\", \"paraphrase\", \"of\", \"a\", \"sentence\", \"conveys\", \"the\", \"same\", \"meaning\", \"but\", \"its\", \"structure\", \"and\", \"the\", \"sequence\", \"of\", \"words\", \"varies.\", \"it\", \"is\", \"a\", \"challenging\", \"task\", \"as\", \"it\", \"is\", \"difficult\", \"to\", \"infer\", \"the\", \"proper\", \"context\", \"about\", \"a\", \"sentence\", \"given\", \"its\", \"short\", \"length.\", \"also,\", \"coming\", \"up\", \"with\", \"similarity\", \"metrics\", \"for\", \"the\", \"inferred\", \"context\", \"of\", \"a\", \"pair\", \"of\", \"sentences\", \"is\", \"not\", \"straightforward\", \"as\", \"well.\", \"(machine\", \"learning\", \"models\", \"for\", \"paraphrase\", \"identification\", \"and\", \"its\", \"applications\", \"on\", \"plagiarism\", \"detection.\", \"ethan,\", \"h.,\", \"etl.\", \"al.,\", \"2019)\", \"8.\", \"the\", \"processing\", \"of\", \"natural\", \"language\", \"processing\", \"is\", \"changed\", \"after\", \"the\", \"evident\", \"of\", \"deep\", \"learning\", \"algorithms.\", \"the\", \"machine\", \"learning\", \"algorithms\", \"use\", \"numerical\", \"data\", \"for\", \"processing;\", \"therefore,\", \"categorical\", \"data\", \"are\", \"converted\", \"into\", \"equivalent\", \"vectors\", \"for\", \"processing\", \"by\", \"the\", \"machines.\", \"word\", \"embeddings\", \"are\", \"the\", \"real\", \"vectored\", \"representation\", \"of\", \"words\", \"which\", \"store\", \"semantic\", \"information.\", \"these\", \"embeddings\", \"are\", \"the\", \"significant\", \"tool\", \"of\", \"natural\", \"language\", \"being\", \"used\", \"in\", \"various\", \"tasks\", \"like\", \"name-entity-recognition\", \"and\", \"parsing,\", \"etc.\", \"authorship\", \"attribution\", \"is\", \"a\", \"major\", \"problem\", \"in\", \"natural\", \"language\", \"processing.\", \"(a\", \"deep\", \"learning\", \"approach\", \"for\", \"plagiarism\", \"detection\", \"system\", \"using\", \"bert.\", \"bohra,\", \"a.,\", \"et.\", \"al.,\", \"2022)\", \"9.\", \"speech-to-text\", \"conversion\", \"and\", \"summarization\", \"for\", \"effective\", \"understanding\", \"and\", \"documentation\", \"by\", \"vinnarasu\", \"a.\", \"and\", \"deepa\", \"v.\", \"jose\", \"presents\", \"a\", \"method\", \"for\", \"speech\", \"recognition\", \"and\", \"text\", \"summarization\", \"to\", \"aid\", \"in\", \"understanding\", \"and\", \"documenting\", \"lengthy\", \"speeches.\", \"the\", \"research\", \"work\", \"describes\", \"an\", \"easy\", \"and\", \"effective\", \"method\", \"for\", \"speech\", \"recognition,\", \"converting\", \"speech\", \"to\", \"text,\", \"and\", \"producing\", \"a\", \"summarized\", \"text.\", \"the\", \"proposed\", \"hybrid\", \"method\", \"has\", \"various\", \"applications,\", \"including\", \"creating\", \"lecture\", \"notes\", \"and\", \"summarizing\", \"catalogs\", \"for\", \"lengthy\", \"documents.\", \"the\", \"combination\", \"of\", \"speech-to-text\", \"conversion\", \"and\", \"text\", \"summarization\", \"is\", \"implemented,\", \"providing\", \"a\", \"practical\", \"strategy\", \"for\", \"improving\", \"the\", \"reliability\", \"of\", \"large\", \"language\", \"models.\", \"the\", \"proposed\", \"model\", \"aims\", \"to\", \"reduce\", \"the\", \"time\", \"and\", \"effort\", \"of\", \"manual\", \"documentation\", \"of\", \"lengthy\", \"speeches\", \"in\", \"an\", \"event,\", \"making\", \"it\", \"easier\", \"to\", \"archive\", \"lecture\", \"notes\", \"from\", \"classes,\", \"conferences,\", \"or\", \"seminars.\", \"(speech-to-text\", \"conversion\", \"and\", \"summarization\", \"for\", \"effective\", \"understanding\", \"and\", \"documentation,\", \"vinnarasu\", \"a.,\", \"deepa\", \"v.\", \"jose,\", \"2019)\", \"other\", \"related\", \"study\", \"(data\", \"gathering\", \"and\", \"machine\", \"learning\", \"methods)\", \"10.\", \"based\", \"on\", \"the\", \"article,\", \"python\\u2019s\", \"speech\", \"recognition\", \"module\", \"and\", \"\\u201ctext\", \"blob\\u201d\", \"for\", \"language\", \"conversion\", \"and\", \"analysis\", \"were\", \"used\", \"to\", \"develop\", \"the\", \"system.\", \"natural\", \"language\", \"toolkit\", \"(nltk)\", \"is\", \"employed\", \"for\", \"tokenization,\", \"lemmatization,\", \"pos\", \"tagging,\", \"and\", \"named\", \"entity\", \"tagging.\", \"emotional\", \"states\", \"are\", \"extracted,\", \"and\", \"vader\", \"(valence\", \"aware\", \"dictionary\", \"and\", \"sentiment\", \"reasoner)\", \"sentiment\", \"analysis\", \"is\", \"applied,\", \"providing\", \"positive,\", \"negative,\", \"neutral,\", \"and\", \"compound\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"scores\", \"(lliev\", \"&\", \"stanchev,\", \"2020).vader,\", \"an\", \"open-source\", \"sentiment\", \"analysis\", \"tool,\", \"generates\", \"scores\", \"based\", \"on\", \"a\", \"lexicon\", \"with\", \"over\", \"9000\", \"features.\", \"the\", \"lexicon\", \"rates\", \"each\", \"feature\", \"between\", \"-4\", \"(extremely\", \"negative)\", \"and\", \"+4\", \"(extremely\", \"positive)\", \"under\", \"the\", \"mit\", \"license\", \"(akash\", \"apturkar\", \"et\", \"al.,\", \"2020).\", \"11.\", \"natural\", \"language\", \"processing\", \"(nlp)\", \"has\", \"recently\", \"gained\", \"much\", \"attention\", \"for\", \"representing\", \"and\", \"analyzing\", \"human\", \"language\", \"computationally.\", \"it\", \"has\", \"spread\", \"its\", \"applications\", \"in\", \"various\", \"fields\", \"such\", \"as\", \"machine\", \"translation,\", \"email\", \"spam\", \"detection,\", \"information\", \"extraction,\", \"summarization,\", \"medical,\", \"and\", \"question\", \"answering\", \"etc.\", \"in\", \"this\", \"paper,\", \"we\", \"first\", \"distinguish\", \"four\", \"phases\", \"by\", \"discussing\", \"different\", \"levels\", \"of\", \"nlp\", \"and\", \"components\", \"of\", \"natural\", \"language\", \"generation\", \"followed\", \"by\", \"presenting\", \"the\", \"history\", \"and\", \"evolution\", \"of\", \"nlp.\", \"we\", \"then\", \"discuss\", \"in\", \"detail\", \"the\", \"state\", \"of\", \"the\", \"art\", \"presenting\", \"the\", \"various\", \"applications\", \"of\", \"nlp,\", \"current\", \"trends,\", \"and\", \"challenges.\", \"(natural\", \"language\", \"processing:\", \"state\", \"of\", \"the\", \"art,\", \"current\", \"trends\", \"and\", \"challenges.\", \"khurana,\", \"d.,\", \"et.\", \"al.,\", \"2022)\", \"12.\", \"attention\", \"is\", \"an\", \"increasingly\", \"popular\", \"mechanism\", \"used\", \"in\", \"a\", \"wide\", \"range\", \"of\", \"neural\", \"architectures.\", \"the\", \"mechanism\", \"itself\", \"has\", \"been\", \"realized\", \"in\", \"a\", \"variety\", \"of\", \"formats.\", \"however,\", \"because\", \"of\", \"the\", \"fast-paced\", \"advances\", \"in\", \"this\", \"domain,\", \"a\", \"systematic\", \"overview\", \"of\", \"attention\", \"is\", \"still\", \"missing.\", \"they\", \"define\", \"a\", \"unified\", \"model\", \"for\", \"attention\", \"architectures\", \"in\", \"natural\", \"language\", \"processing,\", \"with\", \"a\", \"focus\", \"on\", \"those\", \"designed\", \"to\", \"work\", \"with\", \"vector\", \"representations\", \"of\", \"the\", \"textual\", \"data.\", \"they\", \"propose\", \"a\", \"taxonomy\", \"of\", \"attention\", \"models\", \"according\", \"to\", \"four\", \"dimensions:\", \"the\", \"representation\", \"of\", \"the\", \"input,\", \"the\", \"compatibility\", \"function,\", \"the\", \"distribution\", \"function,\", \"and\", \"the\", \"multiplicity\", \"of\", \"the\", \"input\", \"and/or\", \"output.\", \"they\", \"present\", \"the\", \"examples\", \"of\", \"how\", \"prior\", \"information\", \"can\", \"be\", \"exploited\", \"in\", \"attention\", \"models\", \"and\", \"discuss\", \"ongoing\", \"research\", \"efforts\", \"and\", \"open\", \"challenges\", \"in\", \"the\", \"area,\", \"providing\", \"the\", \"first\", \"extensive\", \"categorization\", \"of\", \"the\", \"vast\", \"body\", \"of\", \"literature\", \"in\", \"this\", \"exciting\", \"domain.\", \"(attention\", \"in\", \"natural\", \"language\", \"processing.\", \"andrea,\", \"g.,\", \"et.\", \"al.,\", \"2021)\", \"13.\", \"pre-training\", \"techniques\", \"have\", \"been\", \"verified\", \"successfully\", \"in\", \"a\", \"variety\", \"of\", \"nlp\", \"tasks\", \"in\", \"recent\", \"years.\", \"despite\", \"the\", \"widespread\", \"use\", \"of\", \"pre-training\", \"models\", \"for\", \"nlp\", \"applications,\", \"they\", \"almost\", \"exclusively\", \"focus\", \"on\", \"text-level\", \"manipulation,\", \"while\", \"neglecting\", \"layout\", \"and\", \"style\", \"information\", \"that\", \"is\", \"vital\", \"for\", \"document\", \"image\", \"understanding.\", \"in\", \"this\", \"paper,\", \"we\", \"propose\", \"the\", \"layoutlm\", \"to\", \"jointly\", \"model\", \"interactions\", \"between\", \"text\", \"and\", \"layout\", \"information\", \"across\", \"scanned\", \"document\", \"images,\", \"which\", \"is\", \"beneficial\", \"for\", \"a\", \"great\", \"number\", \"of\", \"real-world\", \"document\", \"image\", \"understanding\", \"tasks\", \"such\", \"as\", \"information\", \"extraction\", \"from\", \"scanned\", \"documents.\", \"furthermore,\", \"we\", \"also\", \"leverage\", \"image\", \"features\", \"to\", \"incorporate\", \"words\'\", \"visual\", \"information\", \"into\", \"layoutlm.\", \"(layoutlm:\", \"pre-training\", \"of\", \"text\", \"and\", \"layout\", \"for\", \"document\", \"image\", \"understanding.\", \"xu,\", \"y.,\", \"et.\", \"al.,\", \"2020)\", \"14.\", \"with\", \"the\", \"widespread\", \"use\", \"of\", \"mobile\", \"phones\", \"and\", \"scanners\", \"to\", \"photograph\", \"and\", \"upload\", \"documents,\", \"the\", \"need\", \"for\", \"extracting\", \"the\", \"information\", \"trapped\", \"in\", \"unstructured\", \"document\", \"images\", \"such\", \"as\", \"retail\", \"receipts,\", \"insurance\", \"claim\", \"forms\", \"and\", \"financial\", \"invoices\", \"is\", \"becoming\", \"more\", \"acute.\", \"a\", \"major\", \"hurdle\", \"to\", \"this\", \"objective\", \"is\", \"that\", \"these\", \"images\", \"often\", \"contain\", \"information\", \"in\", \"the\", \"form\", \"of\", \"tables\", \"and\", \"extracting\", \"data\", \"from\", \"tabular\", \"sub-images\", \"presents\", \"a\", \"unique\", \"set\", \"of\", \"challenges.\", \"this\", \"includes\", \"accurate\", \"detection\", \"of\", \"the\", \"tabular\", \"region\", \"within\", \"an\", \"image,\", \"and\", \"subsequently\", \"detecting\", \"and\", \"extracting\", \"information\", \"from\", \"the\", \"rows\", \"and\", \"columns\", \"of\", \"the\", \"detected\", \"table.\", \"while\", \"some\", \"progress\", \"has\", \"been\", \"made\", \"in\", \"table\", \"detection,\", \"extracting\", \"the\", \"table\", \"contents\", \"is\", \"still\", \"a\", \"challenge\", \"since\", \"this\", \"involves\", \"more\", \"fine\", \"grained\", \"table\", \"structure\", \"(rows\", \"&\", \"columns)\", \"recognition.\", \"prior\", \"approaches\", \"have\", \"attempted\", \"to\", \"solve\", \"the\", \"table\", \"detection\", \"and\", \"structure\", \"recognition\", \"problems\", \"independently\", \"using\", \"two\", \"separate\", \"models.\", \"(tablenet:\", \"deep\", \"learning\", \"model\", \"for\", \"end-to-end\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"table\", \"detection\", \"and\", \"tabular\", \"data\", \"extraction\", \"from\", \"scanned\", \"document\", \"images.\", \"shubham,\", \"s.p.,\", \"et.\", \"al.,\", \"2019)\", \"patents\", \"15.\", \"the\", \"plagiarism\", \"is\", \"an\", \"increasingly\", \"widespread\", \"and\", \"growing\", \"problem\", \"in\", \"the\", \"academic\", \"field.\", \"several\", \"plagiarism\", \"techniques\", \"are\", \"used\", \"by\", \"fraudsters,\", \"ranging\", \"from\", \"a\", \"simple\", \"synonym\", \"replacement,\", \"sentence\", \"structure\", \"modification,\", \"to\", \"more\", \"complex\", \"method\", \"involving\", \"several\", \"types\", \"of\", \"transformation.\", \"human\", \"based\", \"plagiarism\", \"detection\", \"is\", \"difficult,\", \"not\", \"accurate,\", \"and\", \"time-consuming\", \"process.\", \"in\", \"this\", \"paper\", \"we\", \"propose\", \"a\", \"plagiarism\", \"detection\", \"framework\", \"based\", \"on\", \"three\", \"deep\", \"learning\", \"models:\", \"doc2vec,\", \"siamese\", \"long\", \"short-term\", \"memory\", \"(slstm)\", \"and\", \"convolutional\", \"neural\", \"network\", \"(cnn).\", \"our\", \"system\", \"uses\", \"three\", \"layers:\", \"preprocessing\", \"layer\", \"including\", \"word\", \"embedding,\", \"learning\", \"layers\", \"and\", \"detection\", \"layer.\", \"to\", \"evaluate\", \"our\", \"system,\", \"we\", \"carried\", \"out\", \"a\", \"study\", \"on\", \"plagiarism\", \"detection\", \"tools\", \"from\", \"the\", \"academic\", \"field\", \"and\", \"make\", \"a\", \"comparison\", \"based\", \"on\", \"a\", \"set\", \"of\", \"features.\", \"compared\", \"to\", \"other\", \"works,\", \"our\", \"approach\", \"performs\", \"a\", \"good\", \"accuracy\", \"of\", \"98.33\", \"%\", \"and\", \"can\", \"detect\", \"different\", \"types\", \"of\", \"plagiarism,\", \"enables\", \"to\", \"specify\", \"another\", \"dataset\", \"and\", \"supports\", \"to\", \"compare\", \"the\", \"document\", \"from\", \"an\", \"internet\", \"search.\", \"(a\", \"new\", \"online\", \"plagiarism\", \"detection\", \"system\", \"based\", \"on\", \"deep\", \"learning.\", \"hambi,\", \"e.m.,\", \"et.\", \"al.,\", \"2020)\", \"16.\", \"summarizes\", \"the\", \"research\", \"on\", \"computational\", \"methods\", \"to\", \"detect\", \"academic\", \"plagiarism\", \"by\", \"systematically\", \"reviewing\", \"239\", \"research\", \"papers\", \"published\", \"between\", \"2013\", \"and\", \"2018.\", \"to\", \"structure\", \"the\", \"presentation\", \"of\", \"the\", \"research\", \"contributions,\", \"we\", \"propose\", \"novel\", \"technically\", \"oriented\", \"typologies\", \"for\", \"plagiarism\", \"prevention\", \"and\", \"detection\", \"efforts,\", \"the\", \"forms\", \"of\", \"academic\", \"plagiarism,\", \"and\", \"computational\", \"plagiarism\", \"detection\", \"methods.\", \"we\", \"show\", \"that\", \"academic\", \"plagiarism\", \"detection\", \"is\", \"a\", \"highly\", \"active\", \"research\", \"field.\", \"over\", \"the\", \"period\", \"we\", \"review,\", \"the\", \"field\", \"has\", \"seen\", \"major\", \"advances\", \"regarding\", \"the\", \"automated\", \"detection\", \"of\", \"strongly\", \"obfuscated\", \"and\", \"thus\", \"hard-to-identify\", \"forms\", \"of\", \"academic\", \"plagiarism.\", \"these\", \"improvements\", \"mainly\", \"originate\", \"from\", \"better\", \"semantic\", \"text\", \"analysis\", \"methods,\", \"the\", \"investigation\", \"of\", \"non-textual\", \"content\", \"features,\", \"and\", \"the\", \"application\", \"of\", \"machine\", \"learning.\", \"we\", \"identify\", \"a\", \"research\", \"gap\", \"in\", \"the\", \"lack\", \"of\", \"methodologically\", \"thorough\", \"performance\", \"evaluations\", \"of\", \"plagiarism\", \"detection\", \"systems.\", \"concluding\", \"from\", \"our\", \"analysis,\", \"we\", \"see\", \"the\", \"integration\", \"of\", \"heterogeneous\", \"analysis\", \"methods\", \"for\", \"textual\", \"and\", \"non-textual\", \"content\", \"features\", \"using\", \"machine\", \"learning\", \"as\", \"the\", \"most\", \"promising\", \"area\", \"for\", \"future\", \"research\", \"contributions\", \"to\", \"improve\", \"the\", \"detection\", \"of\", \"academic\", \"plagiarism\", \"further.\", \"(academic\", \"plagiarism\", \"detection.\", \"folt\\u00fdnek,\", \"t.,\", \"et.\", \"al.,\", \"2019)\", \"how\", \"do\", \"you\", \"intend\", \"to\", \"solve\", \"the\", \"problem?\", \"the\", \"proponents\", \"of\", \"the\", \"study\", \"plan\", \"to\", \"solve\", \"the\", \"problem\", \"by\", \"developing\", \"a\", \"website/\", \"application\", \"that\", \"will\", \"gather\", \"the\", \"data\", \"from\", \"the\", \"published\", \"thesis\", \"papers\", \"through\", \"machine\", \"learning\", \"using\", \"image\", \"processing\", \"and\", \"natural\", \"language\", \"processing.\", \"the\", \"said\", \"website/\", \"application\", \"will\", \"be\", \"acting\", \"as\", \"a\", \"grading\", \"system\", \"for\", \"plagiarism\", \"for\", \"a\", \"title\", \"and\", \"concept\", \"similar\", \"to\", \"another\", \"and\", \"recommend\", \"titles\", \"that\", \"are\", \"similar\", \"to\", \"the\", \"new\", \"solution\", \"to\", \"a\", \"problem.\", \"the\", \"system\", \"able\", \"to\", \"give\", \"panelists\", \"the\", \"idea\", \"the\", \"student\", \"is\", \"portraying\", \"by\", \"using\", \"the\", \"speech\", \"to\", \"text\", \"while\", \"the\", \"proponent\", \"is\", \"giving\", \"their\", \"explanation\", \"and\", \"insight\", \"to\", \"their\", \"concept\", \"papers.\", \"it\", \"scan\", \"the\", \"soft\", \"copy\", \"document\", \"to\", \"see\", \"if\", \"the\", \"concept\", \"already\", \"existing\", \"or\", \"not.\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"figure\", \"1.1\", \"home\", \"page\", \"website\", \"gui\", \"users\", \"are\", \"greeted\", \"with\", \"a\", \"brief\", \"overview\", \"of\", \"the\", \"website/application\'s\", \"capabilities\", \"purpose\", \"on\", \"the\", \"main\", \"page.\", \"important\", \"sections\", \"like\", \"\\\"proposals,\\\"\", \"\\\"trash,\\\"\", \"\\\"account,\\\"\", \"and\", \"\\\"sign\", \"up\\\"\", \"are\", \"clearly\", \"labeled,\", \"simple\", \"to\", \"navigate\", \"to\", \"the\", \"functions\", \"you\", \"need.\", \"in\", \"order\", \"to\", \"provide\", \"an\", \"easy\", \"and\", \"effective\", \"user\", \"experience,\", \"users\", \"advised\", \"to\", \"register\", \"for\", \"an\", \"account\", \"or\", \"link\", \"their\", \"emails\", \"in\", \"order\", \"to\", \"gain\", \"access\", \"to\", \"other\", \"sections\", \"of\", \"the\", \"website.\", \"figure\", \"1.2\", \"proposals\", \"page\", \"website\", \"gui\", \"users\", \"can\", \"upload\", \"files\", \"to\", \"the\", \"website\", \"for\", \"plagiarism\", \"checks\", \"on\", \"titles\", \"and\", \"contents\", \"in\", \"the\", \"proposal\", \"section.\", \"furthermore,\", \"if\", \"a\", \"file\", \"already\", \"exists\", \"and\", \"has\", \"been\", \"uploaded\", \"and\", \"reviewed,\", \"a\", \"square-like\", \"form\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"will\", \"show\", \"up,\", \"enabling\", \"users\", \"to\", \"save\", \"and\", \"retrieve\", \"these\", \"suggestions\", \"for\", \"later\", \"use\", \"or\", \"extra\", \"verification.\", \"this\", \"feature\", \"makes\", \"it\", \"easier\", \"for\", \"users\", \"to\", \"retrieve\", \"files\", \"they\", \"have\", \"already\", \"looked\", \"at\", \"on\", \"the\", \"platform,\", \"which\", \"increases\", \"efficiency\", \"and\", \"convenience.\", \"figure\", \"1.3\", \"files\", \"page\", \"website\", \"gui\", \"when\", \"a\", \"proposal\", \"file\", \"is\", \"uploaded,\", \"our\", \"website\", \"starts\", \"real-time\", \"checking\", \"right\", \"away\", \"and\", \"gives\", \"users\", \"feedback\", \"right\", \"away.\", \"the\", \"\\\"mic\\\"\", \"button\", \"above\", \"allows\", \"users\", \"to\", \"record\", \"the\", \"speaker\'s\", \"voice,\", \"making\", \"their\", \"thoughts\", \"easier\", \"to\", \"hear.\", \"by\", \"providing\", \"a\", \"succinct\", \"summary\", \"of\", \"the\", \"proposal\'s\", \"contents,\", \"this\", \"element\", \"improves\", \"communication.\", \"the\", \"uploaded\", \"paper\", \"appears\", \"with\", \"its\", \"title\", \"and\", \"contents\", \"beneath\", \"the\", \"voice\", \"recording\", \"area.\", \"users\", \"can\", \"view\", \"content-related\", \"statistics,\", \"such\", \"as\", \"the\", \"identification\", \"of\", \"duplicate\", \"titles\", \"written\", \"by\", \"other\", \"people,\", \"right\", \"next\", \"to\", \"the\", \"voice\", \"recording\", \"and\", \"paper\", \"display.\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"figure\", \"1.4\", \"recommendation\", \"pop-up\", \"gui\", \"the\", \"pop-up\", \"window\", \"will\", \"function\", \"as\", \"a\", \"platform\", \"for\", \"recommendations,\", \"providing\", \"ideas\", \"for\", \"articles\", \"related\", \"to\", \"the\", \"previous\", \"subject.\", \"it\", \"will\", \"suggest\", \"titles\", \"that\", \"cover\", \"other\", \"project\", \"concepts\", \"but\", \"have\", \"a\", \"similar\", \"idea,\", \"giving\", \"proponents\", \"a\", \"title\", \"possibility\", \"to\", \"consider\", \"further.\", \"this\", \"feature\", \"presents\", \"different\", \"viewpoints\", \"and\", \"lines\", \"of\", \"study\", \"within\", \"the\", \"same\", \"topic\", \"domain\", \"in\", \"an\", \"effort\", \"to\", \"improve\", \"research\", \"discovery.\", \"figure\", \"2\", \"conceptual\", \"framework\", \"as\", \"shown\", \"in\", \"the\", \"figure\", \"above,\", \"is\", \"the\", \"conceptual\", \"framework\", \"where\", \"data\", \"gathered\", \"will\", \"be\", \"coming\", \"from\", \"three\", \"different\", \"sources,\", \"such\", \"as\", \"concept\", \"paper\", \"proposal,\", \"existing\", \"thesis\", \"books,\", \"and\", \"vocabulary\", \"data\", \"set.\", \"this\", \"framework\", \"involves\", \"preprocessing\", \"steps\", \"like\", \"cleaning,\", \"tokenization,\", \"and\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"stemming/lemmatization\", \"before\", \"applying\", \"machine\", \"learning\", \"algorithms\", \"to\", \"analyze\", \"the\", \"speech\", \"spoken.\", \"the\", \"goal\", \"is\", \"check\", \"the\", \"accuracy\", \"and\", \"plagiarism\", \"of\", \"the\", \"proposed\", \"conceptual\", \"framework\", \"by\", \"using\", \"speech-to-text\", \"recognition\", \"and\", \"image\", \"or\", \"text\", \"processing.\", \"target\", \"users\", \"/\", \"beneficiaries:(describe\", \"each\", \"beneficiary)\", \"this\", \"study\", \"will\", \"be\", \"beneficial\", \"to\", \"the\", \"institution.\", \"smart\", \"paperless\", \"systems\", \"aim\", \"to\", \"enhance\", \"the\", \"efficiency,\", \"transparency,\", \"and\", \"effectiveness\", \"of\", \"the\", \"research\", \"proposal\", \"matching\", \"and\", \"topic\", \"recommendation\", \"process.\", \"1.\", \"administrators\", \"or\", \"program\", \"coordinator:\", \"the\", \"system\", \"can\", \"be\", \"effectively\", \"used\", \"by\", \"administrators\", \"or\", \"program\", \"managers\", \"in\", \"charge\", \"of\", \"research\", \"programs\", \"or\", \"funding\", \"initiatives\", \"to\", \"handle\", \"proposal\", \"submissions\", \"and\", \"topic\", \"selection\", \"procedures.\", \"through\", \"the\", \"automation\", \"of\", \"repetitive\", \"operations\", \"like\", \"proposal\", \"matching\", \"and\", \"document\", \"processing,\", \"the\", \"system\'s\", \"automation\", \"capabilities\", \"lessen\", \"the\", \"administrative\", \"pressure.\", \"2.\", \"panelists\", \"or\", \"reviewers:\", \"the\", \"automation\", \"of\", \"the\", \"system,\", \"which\", \"assists\", \"in\", \"matching\", \"proposals\", \"with\", \"relevant\", \"topics,\", \"will\", \"be\", \"helpful\", \"to\", \"panelists\", \"considering\", \"research\", \"proposals\", \"or\", \"topic\", \"submissions.\", \"panelists\", \"are\", \"able\", \"to\", \"efficiently\", \"comprehend\", \"and\", \"evaluate\", \"proposal\", \"material\", \"because\", \"of\", \"the\", \"system\'s\", \"natural\", \"language\", \"processing\", \"(nlp)\", \"capabilities,\", \"which\", \"guarantees\", \"effective\", \"decision-making\", \"procedures.\", \"3.\", \"future\", \"researchers:\", \"the\", \"streamlined\", \"method\", \"of\", \"matching\", \"topic\", \"proposals\", \"will\", \"help\", \"researchers\", \"find\", \"relevant\", \"study\", \"ideas\", \"more\", \"quickly\", \"and\", \"efficiently,\", \"saving\", \"them\", \"time\", \"and\", \"effort.\", \"they\", \"may\", \"analyze\", \"enormous\", \"volumes\", \"of\", \"text\", \"data,\", \"extract\", \"important\", \"information,\", \"and\", \"produce\", \"insights\", \"for\", \"their\", \"research\", \"by\", \"using\", \"the\", \"system\'s\", \"natural\", \"language\", \"processing\", \"(nlp)\", \"capabilities.\", \"research\", \"papers,\", \"journals,\", \"and\", \"other\", \"pertinent\", \"documents\", \"can\", \"be\", \"quickly\", \"reviewed\", \"and\", \"categorized\", \"by\", \"researchers\", \"with\", \"the\", \"use\", \"of\", \"document\", \"processing\", \"tools.\", \"significance\", \"of\", \"study:\", \"this\", \"study\", \"will\", \"help\", \"researchers\", \"perform\", \"efficient\", \"and\", \"well-organized\", \"research\", \"methods\", \"in\", \"addition\", \"to\", \"benefiting\", \"panelists\", \"for\", \"time\", \"management\", \"and\", \"efforts.\", \"1.\", \"panelists:\", \"the\", \"accuracy\", \"and\", \"speed\", \"with\", \"which\", \"panelists\", \"connect\", \"research\", \"proposals\", \"with\", \"appropriate\", \"concepts\", \"will\", \"improve\", \"during\", \"the\", \"assessment\", \"and\", \"selection\", \"process.\", \"by\", \"automating\", \"the\", \"matching\", \"process,\", \"biases,\", \"and\", \"manual\", \"effort\", \"are\", \"minimized,\", \"resulting\", \"in\", \"an\", \"equal\", \"evaluation\", \"of\", \"ideas.\", \"the\", \"ability\", \"to\", \"process\", \"papers\", \"more\", \"efficiently\", \"makes\", \"it\", \"easier\", \"to\", \"handle\", \"proposal\", \"materials,\", \"which\", \"improves\", \"the\", \"accessibility\", \"and\", \"organization\", \"of\", \"the\", \"review\", \"process.\", \"2.\", \"researchers:\", \"researchers\", \"will\", \"save\", \"time\", \"and\", \"money\", \"thanks\", \"to\", \"the\", \"process\", \"of\", \"matching\", \"subject\", \"proposals\", \"which\", \"is\", \"now\", \"more\", \"efficient.\", \"by\", \"utilizing\", \"nlp\", \"capabilities,\", \"researchers\", \"can\", \"gain\", \"deeper\", \"insights\", \"by\", \"enhancing\", \"their\", \"comprehension\", \"and\", \"analysis\", \"of\", \"study\", \"materials.\", \"speech\", \"and\", \"picture\", \"recognition\", \"technologies\", \"allow\", \"users\", \"to\", \"engage\", \"with\", \"the\", \"system\", \"in\", \"a\", \"natural\", \"way,\", \"which\", \"speeds\", \"up\", \"the\", \"input\", \"and\", \"retrieval\", \"of\", \"data.\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"gap\", \"analysis\", \"title\", \"description\", \"scope/technology\", \"year\", \"technology\", \"(speech-to-text)\", \"automatic\", \"speech\", \"in\", \"their\", \"systematic\", \"literature\", \"review,\", \"alharbi\", \"et\", \"al.\", \"(2021)\", \"2021\", \"recognition:\", \"alharbi\", \"et\", \"al.\", \"(2021)\", \"explore\", \"the\", \"conducted\", \"a\", \"systematic\", \"systematic\", \"advancements\", \"in\", \"speech-to-text\", \"literature\", \"review\", \"focusing\", \"literature\", \"review\", \"recognition\", \"technology,\", \"on\", \"the\", \"advancements\", \"in\", \"highlighting\", \"its\", \"transformative\", \"speech-to-text\", \"recognition\", \"impact\", \"on\", \"data\", \"transcription.\", \"the\", \"technology.\", \"their\", \"research\", \"scope\", \"encompasses\", \"the\", \"conversion\", \"explores\", \"the\", \"of\", \"spoken\", \"words\", \"into\", \"written\", \"text\", \"transformative\", \"impact\", \"of\", \"and\", \"its\", \"applications\", \"in\", \"analyzing\", \"this\", \"technology\", \"on\", \"data\", \"interview\", \"recordings\", \"efficiently\", \"for\", \"transcription,\", \"particularly\", \"further\", \"evaluation\", \"of\", \"applicant\", \"in\", \"converting\", \"spoken\", \"responses.\", \"however,\", \"they\", \"also\", \"words\", \"into\", \"written\", \"text.\", \"acknowledge\", \"the\", \"challenges\", \"outlined\", \"in\", \"their\", \"research,\", \"including\", \"factors\", \"such\", \"as\", \"the\", \"number\", \"of\", \"speakers,\", \"speech\", \"clarity,\", \"vocabulary\", \"size,\", \"and\", \"spectral\", \"bandwidth,\", \"which\", \"influence\", \"the\", \"performance\", \"of\", \"automated\", \"speech\", \"recognition\", \"systems.\", \"this\", \"study\", \"was\", \"published\", \"in\", \"2021.\", \"challenges\", \"and\", \"in\", \"their\", \"study\", \"by\", \"sneha\", \"basak,\", \"the\", \"scope\", \"of\", \"the\", \"study\", \"2022\", \"limitations\", \"in\", \"himanshi\", \"agrawal,\", \"shreya\", \"jena,\", \"conducted\", \"by\", \"sneha\", \"speech\", \"shilpa\", \"gite,\", \"mrinal\", \"bachute,\", \"basak,\", \"himanshi\", \"agrawal,\", \"recognition\", \"biswajeet\", \"pradhan,\", \"and\", \"mazen\", \"shreya\", \"jena,\", \"shilpa\", \"gite,\", \"technology:\", \"a\", \"assiri\", \"(2022),\", \"the\", \"researchers\", \"mrinal\", \"bachute,\", \"biswajeet\", \"critical\", \"review\", \"of\", \"acknowledge\", \"the\", \"significance\", \"of\", \"pradhan,\", \"and\", \"mazen\", \"assiri\", \"speech\", \"signal\", \"speech\", \"recognition\", \"technology\", \"(2022)\", \"encompasses\", \"a\", \"processing\", \"while\", \"also\", \"addressing\", \"factors\", \"that\", \"critical\", \"review\", \"of\", \"speech\", \"algorithm,\", \"tools\", \"require\", \"attention\", \"for\", \"further\", \"recognition\", \"technology,\", \"and\", \"systems.\", \"improvement.\", \"focusing\", \"on\", \"challenges\", \"and\", \"limitations\", \"within\", \"the\", \"field.\", \"they\", \"highlight\", \"challenges\", \"such\", \"as\", \"the\", \"researchers\", \"delve\", \"into\", \"variation\", \"in\", \"accents,\", \"which\", \"pose\", \"various\", \"aspects\", \"of\", \"speech\", \"difficulties\", \"for\", \"machines\", \"to\", \"signal\", \"processing\", \"understand\", \"different\", \"algorithms,\", \"tools,\", \"and\", \"pronunciations,\", \"intonations,\", \"and\", \"systems,\", \"aiming\", \"to\", \"identify\", \"accents.\", \"the\", \"study\", \"raises\", \"concerns\", \"areas\", \"that\", \"require\", \"further\", \"about\", \"the\", \"lack\", \"of\", \"speech\", \"recognition\", \"attention\", \"for\", \"improvement.\", \"systems\", \"designed\", \"specifically\", \"for\", \"children,\", \"despite\", \"the\", \"increasing\", \"prevalence\", \"of\", \"e-learning\", \"and\", \"children\", \"spending\", \"significant\", \"time\", \"on\", \"screens.\", \"the\", \"slower\", \"pace\", \"at\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"which\", \"children\", \"understand\", \"new\", \"words\", \"further\", \"complicates\", \"the\", \"ability\", \"of\", \"current\", \"speech\", \"recognition\", \"systems\", \"to\", \"comprehend\", \"child\", \"vocabulary\", \"effectively.\", \"the\", \"study\", \"discusses\", \"the\", \"importance\", \"of\", \"model\", \"training\", \"to\", \"avoid\", \"overfitting,\", \"which\", \"could\", \"negatively\", \"impact\", \"the\", \"performance\", \"of\", \"speech\", \"recognition\", \"systems\", \"by\", \"adding\", \"unnecessary\", \"concepts.\", \"environmental\", \"noise\", \"is\", \"identified\", \"as\", \"another\", \"significant\", \"challenge,\", \"as\", \"it\", \"can\", \"severely\", \"affect\", \"speech\", \"transcription\", \"accuracy.\", \"through\", \"these\", \"observations,\", \"the\", \"study\", \"provides\", \"valuable\", \"insights\", \"into\", \"the\", \"limitations\", \"and\", \"challenges\", \"facing\", \"speech\", \"recognition\", \"technology,\", \"suggesting\", \"areas\", \"for\", \"further\", \"research\", \"and\", \"development.\", \"multilingual\", \"attanasio,\", \"savoldi,\", \"fucci,\", \"and\", \"attanasio,\", \"savoldi,\", \"fucci,\", \"2024\", \"speech\", \"models\", \"for\", \"hovy\", \"(2024)\", \"address\", \"limitations\", \"in\", \"and\", \"hovy\", \"(2024)\", \"address\", \"automatic\", \"speech\", \"research\", \"related\", \"to\", \"gender\", \"and\", \"the\", \"limitations\", \"in\", \"research\", \"recognition\", \"social-cultural\", \"factors\", \"in\", \"voice\", \"concerning\", \"gender\", \"and\", \"exhibit\", \"gender\", \"recognition.\", \"the\", \"scope\", \"social-cultural\", \"factors\", \"in\", \"performance\", \"gaps\", \"encompasses\", \"the\", \"need\", \"for\", \"a\", \"broader\", \"voice\", \"recognition.\", \"their\", \"dataset\", \"considering\", \"dialects,\", \"sex,\", \"study\", \"emphasizes\", \"the\", \"and\", \"other\", \"cultural\", \"factors\", \"to\", \"necessity\", \"for\", \"a\", \"broader\", \"improve\", \"the\", \"results\'\", \"robustness.\", \"the\", \"dataset\", \"encompassing\", \"authors\", \"also\", \"highlight\", \"issues\", \"of\", \"dialects,\", \"sex,\", \"and\", \"other\", \"generalizability\", \"due\", \"to\", \"the\", \"cultural\", \"factors\", \"to\", \"enhance\", \"categorization\", \"of\", \"participants\", \"as\", \"result\", \"robustness.\", \"\\\"other\\\"\", \"and\", \"the\", \"comparison\", \"of\", \"speakers\", \"across\", \"different\", \"platforms.\", \"additionally,\", \"they\", \"stress\", \"the\", \"importance\", \"of\", \"data\", \"quality\", \"and\", \"the\", \"potential\", \"biases\", \"introduced\", \"by\", \"the\", \"lack\", \"of\", \"multilingual\", \"phonetic\", \"tools.\", \"improving\", \"this\", \"research\", \"paper\", \"addresses\", \"the\", \"the\", \"scope\", \"of\", \"the\", \"research\", \"2023\", \"readability\", \"for\", \"readability\", \"challenges\", \"posed\", \"by\", \"paper\", \"encompasses\", \"the\", \"automatic\", \"speech\", \"modern\", \"automatic\", \"speech\", \"realm\", \"of\", \"automatic\", \"recognition\", \"recognition\", \"(asr)\", \"systems,\", \"which\", \"speech\", \"recognition\", \"(asr)\", \"transcription\", \"may\", \"produce\", \"accurate\", \"transcripts\", \"systems\", \"and\", \"their\", \"impact\", \"but\", \"can\", \"still\", \"be\", \"difficult\", \"to\", \"read\", \"due\", \"on\", \"readability\", \"in\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"to\", \"grammatical\", \"errors,\", \"disfluency,\", \"transcripts.\", \"it\", \"delves\", \"into\", \"and\", \"other\", \"spoken\", \"communication\", \"the\", \"challenges\", \"faced\", \"when\", \"nuances.\", \"the\", \"paper\", \"introduces\", \"the\", \"asr\", \"systems\", \"produce\", \"asr\", \"post-processing\", \"for\", \"readability\", \"accurate\", \"but\", \"often\", \"(apr)\", \"task,\", \"formulated\", \"as\", \"a\", \"difficult-to-read\", \"transcripts\", \"sequence-to-sequence\", \"text\", \"due\", \"to\", \"grammatical\", \"errors,\", \"generation\", \"problem,\", \"with\", \"the\", \"goal\", \"disfluencies,\", \"and\", \"other\", \"of\", \"transforming\", \"noisy\", \"asr\", \"outputs\", \"spoken\", \"communication\", \"into\", \"readable\", \"text\", \"while\", \"preserving\", \"nuances.\", \"semantic\", \"meaning.\", \"the\", \"authors\", \"construct\", \"a\", \"dataset\", \"for\", \"apr\", \"using\", \"data\", \"from\", \"grammatical\", \"error\", \"correction\", \"tasks\", \"and\", \"evaluate\", \"model\", \"performance\", \"using\", \"adapted\", \"metrics.\", \"they\", \"compare\", \"fine-tuned\", \"baseline\", \"models\", \"with\", \"traditional\", \"pipeline\", \"methods,\", \"demonstrating\", \"significant\", \"improvements\", \"in\", \"readability\", \"on\", \"test\", \"sets\", \"and\", \"confirming\", \"their\", \"model\'s\", \"efficacy\", \"through\", \"human\", \"evaluation\", \"and\", \"case\", \"studies.\", \"text-independent\", \"this\", \"research\", \"paper\", \"explores\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"2020\", \"speaker\", \"recognition\", \"text-independent\", \"speaker\", \"paper\", \"is\", \"focused\", \"on\", \"using\", \"lstm-rnn\", \"recognition\", \"in\", \"the\", \"context\", \"of\", \"advancing\", \"and\", \"speech\", \"degraded\", \"speech\", \"signals,\", \"including\", \"text-independent\", \"speaker\", \"enhancement\", \"noise\", \"and\", \"reverberation.\", \"it\", \"recognition\", \"systems\", \"in\", \"the\", \"highlights\", \"the\", \"advantages\", \"of\", \"presence\", \"of\", \"degraded\", \"text-independent\", \"speaker\", \"speech\", \"signals,\", \"including\", \"recognition\", \"compared\", \"to\", \"noise\", \"and\", \"reverberation.\", \"text-dependent\", \"approaches,\", \"particularly\", \"in\", \"allowing\", \"clients\", \"to\", \"speak\", \"freely\", \"to\", \"the\", \"system.\", \"the\", \"paper\", \"employs\", \"mel-frequency\", \"cepstral\", \"coefficients\", \"(mfccs),\", \"spectrum,\", \"and\", \"log-spectrum\", \"for\", \"feature\", \"extraction\", \"from\", \"speech\", \"signals,\", \"and\", \"utilizes\", \"long-short\", \"term\", \"memory\", \"recurrent\", \"neural\", \"networks\", \"(lstm-rnn)\", \"for\", \"classification\", \"to\", \"achieve\", \"speaker\", \"recognition.\", \"the\", \"system\", \"demonstrates\", \"high\", \"recognition\", \"rates,\", \"reaching\", \"95.33%\", \"with\", \"mfccs\", \"and\", \"98.7%\", \"with\", \"spectrum\", \"or\", \"log-spectrum,\", \"under\", \"similar\", \"recording\", \"circumstances.\", \"however,\", \"challenges\", \"arise\", \"when\", \"recognizing\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"speakers\", \"across\", \"different\", \"recording\", \"environments,\", \"prompting\", \"the\", \"use\", \"of\", \"speech\", \"enhancement\", \"techniques\", \"like\", \"spectral\", \"subtraction\", \"and\", \"wavelet\", \"denoising\", \"to\", \"improve\", \"recognition\", \"performance.\", \"the\", \"proposed\", \"approach\", \"shows\", \"superiority\", \"over\", \"previous\", \"algorithms,\", \"particularly\", \"the\", \"one\", \"by\", \"r.\", \"togneri\", \"and\", \"d.\", \"pullella\", \"(2011),\", \"showcasing\", \"advancements\", \"in\", \"text-independent\", \"speaker\", \"recognition\", \"under\", \"degraded\", \"speech\", \"conditions.\", \"the\", \"papers\", \"cover\", \"a\", \"wide\", \"range\", \"of\", \"difficulties\", \"and\", \"developments\", \"in\", \"voice\", \"recognition\", \"technology.\", \"alharbi\", \"et\", \"al.\", \"(2021)\", \"explore\", \"how\", \"speech-to-text\", \"recognition\", \"technology\", \"can\", \"change\", \"lives,\", \"especially\", \"when\", \"it\", \"comes\", \"to\", \"data\", \"transcription\", \"from\", \"recorded\", \"interviews.\", \"they\", \"recognize\", \"the\", \"difficulties\", \"presented\", \"by\", \"variables\", \"that\", \"affect\", \"automated\", \"speech\", \"recognition\", \"systems\'\", \"performance,\", \"such\", \"as\", \"speech\", \"quality,\", \"vocabulary\", \"quantity,\", \"and\", \"ambient\", \"noise.\", \"basak\", \"et\", \"al.\", \"(2022)\", \"go\", \"into\", \"further\", \"detail\", \"about\", \"these\", \"difficulties,\", \"emphasizing\", \"problems\", \"like\", \"accent\", \"variance\", \"and\", \"the\", \"absence\", \"of\", \"kid-friendly\", \"systems.\", \"they\", \"also\", \"highlight\", \"the\", \"shortcomings\", \"of\", \"the\", \"speech\", \"recognition\", \"technologies\", \"available\", \"today\", \"and\", \"offer\", \"potential\", \"solutions\", \"like\", \"model\", \"training\", \"and\", \"mitigating\", \"background\", \"noise.\", \"furthermore,\", \"attanasio\", \"et\", \"al.\", \"(2024)\", \"fill\", \"in\", \"the\", \"study\", \"gaps\", \"concerning\", \"gender\", \"and\", \"social-cultural\", \"aspects\", \"of\", \"speech\", \"recognition,\", \"highlighting\", \"the\", \"necessity\", \"of\", \"larger\", \"datasets\", \"and\", \"better\", \"data\", \"quality\", \"to\", \"increase\", \"the\", \"voice\", \"recognition\", \"systems\'\", \"resilience\", \"and\", \"applicability.\", \"conversely,\", \"a\", \"study\", \"on\", \"automatic\", \"speech\", \"recognition\", \"(asr)\", \"post-processing\", \"for\", \"readability\", \"presents\", \"the\", \"asr\", \"post-processing\", \"for\", \"readability\", \"(apr)\", \"challenge,\", \"which\", \"aims\", \"to\", \"correct\", \"grammatical\", \"errors\", \"and\", \"disfluency\", \"in\", \"asr\", \"outputs\", \"in\", \"order\", \"to\", \"make\", \"them\", \"more\", \"readable.\", \"the\", \"state\", \"of\", \"speaker\", \"recognition\", \"technology\", \"is\", \"further\", \"demonstrated\", \"by\", \"a\", \"study\", \"on\", \"text-independent\", \"speaker\", \"recognition\", \"in\", \"degraded\", \"speech\", \"signals,\", \"which\", \"uses\", \"methods\", \"like\", \"mel-frequency\", \"cepstral\", \"coefficients\", \"(mfccs)\", \"and\", \"long-short\", \"term\", \"memory\", \"recurrent\", \"neural\", \"networks\", \"(lstm-rnn)\", \"to\", \"achieve\", \"high\", \"recognition\", \"rates\", \"even\", \"in\", \"difficult\", \"environments.\", \"title\", \"description\", \"scope/technology\", \"year\", \"technology\", \"(image\", \"processing)\", \"layoutlm:\", \"the\", \"research\", \"paper\", \"introduces\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"2020\", \"pre-training\", \"of\", \"text\", \"layoutlm,\", \"a\", \"novel\", \"approach\", \"that\", \"paper\", \"is\", \"centered\", \"around\", \"and\", \"layout\", \"for\", \"extends\", \"pre-training\", \"techniques\", \"to\", \"addressing\", \"the\", \"limitations\", \"document\", \"image\", \"encompass\", \"layout\", \"and\", \"style\", \"of\", \"pre-training\", \"techniques\", \"understanding\", \"information\", \"crucial\", \"for\", \"in\", \"natural\", \"language\", \"understanding\", \"document\", \"images.\", \"processing\", \"(nlp)\", \"that\", \"unlike\", \"existing\", \"methods\", \"that\", \"predominantly\", \"focus\", \"on\", \"mainly\", \"focus\", \"on\", \"text\", \"manipulation,\", \"text-level\", \"manipulation,\", \"layoutlm\", \"incorporates\", \"text\", \"and\", \"neglecting\", \"layout\", \"and\", \"style\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"layout\", \"interactions,\", \"enhancing\", \"tasks\", \"information\", \"crucial\", \"for\", \"like\", \"information\", \"extraction\", \"from\", \"document\", \"image\", \"scanned\", \"documents.\", \"it\", \"also\", \"understanding.\", \"integrates\", \"image\", \"features\", \"to\", \"capture\", \"visual\", \"information\", \"alongside\", \"text.\", \"this\", \"comprehensive\", \"framework\", \"achieves\", \"state-of-the-art\", \"results\", \"across\", \"various\", \"document\", \"understanding\", \"tasks\", \"such\", \"as\", \"form\", \"understanding,\", \"receipt\", \"understanding,\", \"and\", \"document\", \"image\", \"classification.\", \"artificial\", \"this\", \"research\", \"paper\", \"introduces\", \"a\", \"the\", \"scope\", \"of\", \"the\", \"research\", \"2020\", \"novel\", \"convolutional\", \"neural\", \"network\", \"paper\", \"encompasses\", \"the\", \"intelligence\", \"image\", \"(cnn)\", \"algorithm\", \"aimed\", \"at\", \"development\", \"and\", \"recognition\", \"enhancing\", \"convergence\", \"speed\", \"and\", \"evaluation\", \"of\", \"a\", \"novel\", \"method\", \"based\", \"on\", \"recognition\", \"accuracy.\", \"the\", \"algorithm\", \"convolutional\", \"neural\", \"convolutional\", \"integrates\", \"a\", \"recurrent\", \"neural\", \"network\", \"(cnn)\", \"algorithm\", \"neural\", \"network\", \"network\", \"(rnn)\", \"into\", \"the\", \"cnn\", \"that\", \"integrates\", \"recurrent\", \"architecture,\", \"enabling\", \"parallel\", \"neural\", \"networks\", \"(rnns)\", \"algorithm\", \"learning\", \"of\", \"deep\", \"image\", \"features.\", \"and\", \"resnet-inspired\", \"additionally,\", \"inspired\", \"by\", \"resnet\'s\", \"residual\", \"modules\", \"to\", \"skip\", \"connections,\", \"a\", \"new\", \"residual\", \"enhance\", \"image\", \"processing\", \"module\", \"called\", \"shortcut3-resnet\", \"is\", \"tasks.\", \"developed\", \"to\", \"further\", \"optimize\", \"feature\", \"extraction.\", \"a\", \"dual\", \"optimization\", \"model\", \"is\", \"formulated\", \"to\", \"integrate\", \"convolution\", \"and\", \"full\", \"connection\", \"processes\", \"effectively.\", \"through\", \"simulation\", \"experiments,\", \"the\", \"paper\", \"analyzes\", \"the\", \"impact\", \"of\", \"various\", \"cnn\", \"parameters\", \"on\", \"network\", \"performance,\", \"identifying\", \"optimal\", \"settings.\", \"layoutparser:\", \"a\", \"this\", \"research\", \"paper\", \"introduces\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"2021\", \"unified\", \"toolkit\", \"for\", \"layoutparser,\", \"an\", \"open-source\", \"paper\", \"lies\", \"in\", \"addressing\", \"the\", \"deep\", \"learning\", \"library\", \"designed\", \"to\", \"simplify\", \"the\", \"challenges\", \"faced\", \"in\", \"based\", \"document\", \"application\", \"of\", \"deep\", \"learning\", \"(dl)\", \"document\", \"image\", \"analysis\", \"image\", \"analysis\", \"models\", \"in\", \"document\", \"image\", \"analysis\", \"(dia)\", \"due\", \"to\", \"the\", \"(dia).\", \"the\", \"paper\", \"addresses\", \"the\", \"complexity\", \"of\", \"neural\", \"challenges\", \"of\", \"code\", \"organization\", \"and\", \"network\", \"applications.\", \"model\", \"complexity\", \"that\", \"hinder\", \"the\", \"easy\", \"deployment\", \"and\", \"reuse\", \"of\", \"dl\", \"innovations\", \"in\", \"dia\", \"research.\", \"layoutparser\", \"offers\", \"intuitive\", \"interfaces\", \"for\", \"utilizing\", \"dl\", \"models\", \"in\", \"layout\", \"detection,\", \"character\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"recognition,\", \"and\", \"other\", \"document-processing\", \"tasks.\", \"the\", \"library\", \"also\", \"includes\", \"a\", \"platform\", \"for\", \"sharing\", \"pre-trained\", \"models\", \"and\", \"full\", \"document\", \"digitization\", \"pipelines,\", \"enhancing\", \"extensibility\", \"and\", \"collaboration\", \"within\", \"the\", \"dia\", \"community.\", \"this\", \"research\", \"paper\", \"presents\", \"a\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"2020\", \"multimodal\", \"deep\", \"novel\", \"approach\", \"to\", \"document\", \"paper\", \"is\", \"to\", \"address\", \"the\", \"networks\", \"for\", \"text\", \"classification\", \"by\", \"integrating\", \"both\", \"challenges\", \"in\", \"fine-grained\", \"and\", \"image-based\", \"text\", \"and\", \"visual\", \"information.\", \"the\", \"document\", \"classification\", \"by\", \"document\", \"proposed\", \"pipeline\", \"utilizes\", \"leveraging\", \"both\", \"text\", \"and\", \"classification\", \"off-the-shelf\", \"architectures\", \"to\", \"create\", \"visual\", \"information.\", \"it\", \"a\", \"multimodal\", \"neural\", \"network\", \"acknowledges\", \"the\", \"capable\", \"of\", \"learning\", \"from\", \"both\", \"limitations\", \"of\", \"visual\", \"image\", \"data\", \"and\", \"word\", \"embeddings\", \"analysis\", \"alone\", \"in\", \"achieving\", \"extracted\", \"from\", \"noisy\", \"text\", \"obtained\", \"accurate\", \"document\", \"through\", \"ocr.\", \"the\", \"research\", \"classification,\", \"especially\", \"demonstrates\", \"significant\", \"when\", \"dealing\", \"with\", \"improvements\", \"in\", \"classification\", \"documents\", \"lacking\", \"clean\", \"accuracy\", \"on\", \"datasets\", \"like\", \"digital\", \"text.\", \"tobacco3482\", \"and\", \"rvl-cdip,\", \"even\", \"in\", \"cases\", \"where\", \"clean\", \"text\", \"information\", \"is\", \"unavailable.\", \"the\", \"paper\", \"also\", \"releases\", \"a\", \"post-ocr\", \"text\", \"classification\", \"dataset\", \"to\", \"encourage\", \"further\", \"research\", \"in\", \"multi-modal\", \"text/image\", \"classification.\", \"selfdoc:\", \"selfdoc\", \"is\", \"a\", \"novel\", \"pre-training\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"2021\", \"self-supervised\", \"framework\", \"designed\", \"for\", \"document\", \"paper\", \"encompasses\", \"the\", \"document\", \"image\", \"understanding\", \"that\", \"addresses\", \"development\", \"and\", \"representation\", \"the\", \"multimodal\", \"nature\", \"of\", \"documents\", \"evaluation\", \"of\", \"a\", \"learning\", \"and\", \"their\", \"intended\", \"sequential\", \"task-agnostic\", \"pre-training\", \"reading.\", \"unlike\", \"existing\", \"models\", \"framework\", \"called\", \"selfdoc\", \"that\", \"focus\", \"on\", \"individual\", \"words,\", \"for\", \"document\", \"image\", \"selfdoc\", \"takes\", \"a\", \"coarse-grained\", \"understanding.\", \"approach\", \"to\", \"capture\", \"the\", \"positional,\", \"textual,\", \"and\", \"visual\", \"information\", \"of\", \"semantically\", \"meaningful\", \"components\", \"in\", \"documents\", \"while\", \"avoiding\", \"excessive\", \"contextualization.\", \"it\", \"incorporates\", \"cross-modal\", \"learning\", \"during\", \"pre-training\", \"to\", \"leverage\", \"multimodal\", \"information\", \"from\", \"unlabeled\", \"documents\", \"and\", \"introduces\", \"a\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"modality-adaptive\", \"attention\", \"mechanism\", \"for\", \"effective\", \"feature\", \"fusion.\", \"the\", \"papers\", \"discussed\", \"here\", \"offer\", \"a\", \"variety\", \"of\", \"modern\", \"techniques\", \"for\", \"analyzing\", \"and\", \"understanding\", \"document\", \"images.\", \"first\", \"off,\", \"layoutlm\", \"presents\", \"a\", \"thorough\", \"framework\", \"that\", \"expands\", \"on\", \"pre-training\", \"methods\", \"to\", \"include\", \"style\", \"and\", \"layout\", \"data\", \"in\", \"addition\", \"to\", \"text,\", \"leading\", \"to\", \"better\", \"results\", \"on\", \"a\", \"range\", \"of\", \"document\", \"comprehension\", \"tasks.\", \"in\", \"tasks\", \"like\", \"form\", \"understanding\", \"and\", \"transaction\", \"comprehension,\", \"it\", \"achieves\", \"state-of-the-art\", \"outcomes\", \"by\", \"skillfully\", \"combining\", \"text,\", \"layout,\", \"and\", \"image\", \"elements.\", \"furthermore,\", \"a\", \"unique\", \"convolutional\", \"neural\", \"network\", \"(cnn)\", \"algorithm\", \"is\", \"put\", \"forth\", \"to\", \"improve\", \"recognition\", \"accuracy\", \"and\", \"speed\", \"of\", \"convergence.\", \"it\", \"combines\", \"residual\", \"modules\", \"and\", \"recurrent\", \"neural\", \"networks\", \"(rnns)\", \"for\", \"optimal\", \"feature\", \"extraction,\", \"and\", \"simulation\", \"experiments\", \"are\", \"used\", \"to\", \"illustrate\", \"the\", \"effects\", \"of\", \"different\", \"cnn\", \"factors\", \"on\", \"network\", \"performance.\", \"additionally,\", \"layoutparser\", \"offers\", \"an\", \"open-source\", \"library\", \"with\", \"user-friendly\", \"interfaces\", \"for\", \"layout\", \"detection,\", \"character\", \"recognition,\", \"and\", \"other\", \"document\", \"processing\", \"tasks,\", \"addressing\", \"the\", \"difficulties\", \"associated\", \"with\", \"using\", \"deep\", \"learning\", \"models\", \"in\", \"document\", \"picture\", \"analysis.\", \"layoutparser\", \"makes\", \"deep\", \"learning\", \"advancements\", \"in\", \"document\", \"image\", \"analysis\", \"research\", \"easier\", \"to\", \"apply\", \"and\", \"reuse\", \"by\", \"streamlining\", \"code\", \"organization\", \"and\", \"model\", \"complexity.\", \"additionally,\", \"a\", \"multimodal\", \"neural\", \"network\", \"architecture\", \"is\", \"used\", \"to\", \"leverage\", \"both\", \"text\", \"and\", \"visual\", \"input\", \"in\", \"a\", \"novel\", \"way\", \"for\", \"document\", \"classification.\", \"this\", \"method\", \"produces\", \"notable\", \"gains\", \"in\", \"classification\", \"accuracy\", \"even\", \"in\", \"the\", \"absence\", \"of\", \"clear\", \"text\", \"data,\", \"proving\", \"the\", \"usefulness\", \"of\", \"combining\", \"several\", \"modalities\", \"for\", \"tasks\", \"involving\", \"document\", \"understanding.\", \"last\", \"but\", \"not\", \"least,\", \"selfdoc\", \"offers\", \"a\", \"pre-training\", \"framework\", \"created\", \"especially\", \"for\", \"document\", \"image\", \"understanding.\", \"it\", \"uses\", \"modality-adaptive\", \"attention\", \"mechanisms\", \"and\", \"cross-modal\", \"learning\", \"to\", \"capture\", \"the\", \"visual\", \"and\", \"textual\", \"information\", \"of\", \"semantically\", \"significant\", \"document\", \"components,\", \"improving\", \"state-of-the-art\", \"document\", \"image\", \"understanding\", \"tasks.\", \"citation\", \"of\", \"resources\", \"gathered\", \"attention\", \"in\", \"natural\", \"language\", \"processing.\", \"(2021,\", \"october\", \"1).\", \"ieee\", \"journals\", \"&\", \"magazine\", \"|\", \"ieee\", \"xplore.\", \"https://ieeexplore.ieee.org/abstract/document/9194070\", \"bohra,\", \"a.,\", \"&\", \"barwar,\", \"n.\", \"c.\", \"(2022).\", \"a\", \"deep\", \"learning\", \"approach\", \"for\", \"plagiarism\", \"detection\", \"system\", \"using\", \"bert.\", \"in\", \"lecture\", \"notes\", \"on\", \"data\", \"engineering\", \"and\", \"communications\", \"technologies\", \"(pp.\", \"163\\u2013174).\", \"https://doi.org/10.1007/978-981-16-9113-3_13\", \"calicdan,\", \"l.\", \"c.,\", \"bacaro,\", \"r.\", \"m.\", \"r.,\", \"ramo,\", \"d.\", \"c.,\", \"&\", \"licayan,\", \"r.\", \"j.\", \"(2021).\", \"sensitivity\", \"towards\", \"sociocultural\", \"plagiarism\", \"in\", \"the\", \"context\", \"of\", \"varied\", \"discipline\", \"among\", \"college\", \"students.\", \"international\", \"journal\", \"of\", \"asian\", \"education,\", \"2(2),\", \"244\\u2013255.\", \"https://doi.org/10.46966/ijae.v2i2.121\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"chang,\", \"c.\", \"w.\", \"d.,\", \"lee,\", \"s.,\", \"wu,\", \"c.,\", \"liu,\", \"c.,\", \"&\", \"liu,\", \"c.\", \"(n.d.).\", \"using\", \"word\", \"semantic\", \"concepts\", \"for\", \"plagiarism\", \"detection\", \"in\", \"text\", \"documents.\", \"information\", \"retrieval,\", \"24(4\\u20135),\", \"298\\u2013321.\", \"https://doi.org/10.1007/s10791-021-09394-4\", \"del\", \"rosario,\", \"m.\", \"j.\", \"n.,\", \"&\", \"sareno,\", \"j.\", \"(2020).\", \"theses\", \"and\", \"capstone\", \"projects\", \"plagiarism\", \"checker\", \"using\", \"kolmogorov\", \"complexity\", \"algorithm.\", \"walailak\", \"journal\", \"of\", \"science\", \"and\", \"technology,\", \"17(7),\", \"726\\u2013744.\", \"https://doi.org/10.48048/wjst.2020.6498\", \"folt\\u00fdnek,\", \"t.,\", \"meuschke,\", \"n.,\", \"&\", \"gipp,\", \"b.\", \"(2019).\", \"academic\", \"plagiarism\", \"detection.\", \"acm\", \"computing\", \"surveys,\", \"52(6),\", \"1\\u201342.\", \"https://doi.org/10.1145/3345317\", \"human\", \"verification.\", \"(n.d.).\", \"https://www.semanticscholar.org/paper/a-new-online-plagiarism-detection-system-based-\", \"on-hambi-benabbou/1361c6589bcb39cd770013a51bf6ca99062d3992?p2df\", \"khurana,\", \"d.,\", \"koli,\", \"a.,\", \"khatter,\", \"k.,\", \"&\", \"singh,\", \"s.\", \"(2022).\", \"natural\", \"language\", \"processing:\", \"state\", \"of\", \"the\", \"art,\", \"current\", \"trends\", \"and\", \"challenges.\", \"multimedia\", \"tools\", \"and\", \"applications,\", \"82(3),\", \"3713\\u20133744.\", \"https://doi.org/10.1007/s11042-022-13428-4\", \"machine\", \"learning\", \"models\", \"for\", \"paraphrase\", \"identification\", \"and\", \"its\", \"applications\", \"on\", \"plagiarism\", \"detection.\", \"(2019,\", \"november\", \"1).\", \"ieee\", \"conference\", \"publication\", \"|\", \"ieee\", \"xplore.\", \"https://ieeexplore.ieee.org/abstract/document/8944727\", \"mejorada,\", \"e.,\", \"doong,\", \"j.\", \"d.,\", \"retorta,\", \"m.\", \"a.\", \"p.,\", \"curayag,\", \"c.\", \"m.\", \"p.,\", \"lonzon,\", \"w.\", \"a.,\", \"ederio,\", \"n.\", \"t.,\", \"&\", \"calaca,\", \"n.\", \"i.\", \"(2023).\", \"students\\u2019\", \"knowledge\", \"in\", \"citing\", \"sources\", \"at\", \"st.\", \"paul\", \"university.\", \"international\", \"journal\", \"of\", \"current\", \"science\", \"research\", \"and\", \"review,\", \"06(01),\", \"207\\u2013213.\", \"https://doi.org/10.47191/v6-i1-21\", \"pentang,\", \"j.,\", \"&\", \"bautista,\", \"r.\", \"m.\", \"(2022).\", \"ctrl\", \"c\", \"+\", \"ctrl\", \"v:\", \"plagiarism\", \"and\", \"knowledge\", \"on\", \"referencing\", \"and\", \"citation\", \"among\", \"pre-service\", \"teachers.\", \"https://philpapers.org/rec/pencc\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"single\", \"view\", \"-\", \"international\", \"journal\", \"of\", \"current\", \"science\", \"research\", \"and\", \"review.\", \"(n.d.).\", \"international\", \"journal\", \"of\", \"current\", \"science\", \"research\", \"and\", \"review.\", \"https://ijcsrr.org/single-view/?id=8564&pid=8479\", \"single\", \"view\", \"-\", \"international\", \"journal\", \"of\", \"current\", \"science\", \"research\", \"and\", \"review.\", \"(2020,\", \"january\", \"6).\", \"international\", \"journal\", \"of\", \"current\", \"science\", \"research\", \"and\", \"review.\", \"https://ijcsrr.org/single-view/?id=8564&pid=8479\", \"tablenet:\", \"deep\", \"learning\", \"model\", \"for\", \"end-to-end\", \"table\", \"detection\", \"and\", \"tabular\", \"data\", \"extraction\", \"from\", \"scanned\", \"document\", \"images.\", \"(2019,\", \"september\", \"1).\", \"ieee\", \"conference\", \"publication\", \"|\", \"ieee\", \"xplore.\", \"https://ieeexplore.ieee.org/abstract/document/8978013\", \"xu,\", \"y.,\", \"li,\", \"m.,\", \"cui,\", \"l.,\", \"huang,\", \"s.,\", \"wei,\", \"f.,\", \"&\", \"zhou,\", \"m.\", \"(2020).\", \"layoutlm:\", \"pre-training\", \"of\", \"text\", \"and\", \"layout\", \"for\", \"document\", \"image\", \"understanding.\", \"acm\", \"digital\", \"library.\", \"https://doi.org/10.1145/3394486.3403172\", \"liao,\", \"j.,\", \"eskimez,\", \"\\u015f.\", \"e.,\", \"lu,\", \"l.,\", \"shi,\", \"y.,\", \"gong,\", \"m.,\", \"shou,\", \"l.,\", \"qu,\", \"h.,\", \"&\", \"zeng,\", \"m.\", \"(2023).\", \"improving\", \"readability\", \"for\", \"automatic\", \"speech\", \"recognition\", \"transcription.\", \"acm\", \"transactions\", \"on\", \"asian\", \"and\", \"low-resource\", \"language\", \"information\", \"processing,\", \"22(5),\", \"1\\u201323.\", \"https://doi.org/10.1145/3557894\", \"el-moneim,\", \"s.\", \"a.,\", \"nassar,\", \"m.\", \"a.,\", \"dessouky,\", \"m.\", \"i.,\", \"ismail,\", \"n.\", \"a.,\", \"el\\u2010fishawy,\", \"a.\", \"s.,\", \"&\", \"el\\u2010samie,\", \"f.\", \"e.\", \"a.\", \"(2020).\", \"text-independent\", \"speaker\", \"recognition\", \"using\", \"lstm-rnn\", \"and\", \"speech\", \"enhancement.\", \"multimedia\", \"tools\", \"and\", \"applications,\", \"79(33\\u201334),\", \"24013\\u201324028.\", \"https://doi.org/10.1007/s11042-019-08293-7\", \"xu,\", \"y.,\", \"li,\", \"m.,\", \"cui,\", \"l.,\", \"huang,\", \"s.,\", \"wei,\", \"f.,\", \"&\", \"zhou,\", \"m.\", \"(2020).\", \"layoutlm:\", \"pre-training\", \"of\", \"text\", \"and\", \"layout\", \"for\", \"document\", \"image\", \"understanding.\", \"acm:\", \"digital\", \"library.\", \"https://doi.org/10.1145/3394486.3403172\", \"republic\", \"of\", \"the\", \"philippines\", \"laguna\", \"state\", \"polytechnic\", \"university\", \"province\", \"of\", \"laguna\", \"artificial\", \"intelligence\", \"image\", \"recognition\", \"method\", \"based\", \"on\", \"convolutional\", \"neural\", \"network\", \"algorithm.\", \"(2020).\", \"ieee\", \"journals\", \"&\", \"magazine\", \"|\", \"ieee\", \"xplore.\", \"https://ieeexplore.ieee.org/abstract/document/9129654\", \"shen,\", \"z.,\", \"zhang,\", \"r.,\", \"dell,\", \"m.,\", \"lee,\", \"b.\", \"c.\", \"g.,\", \"carlson,\", \"j.,\", \"&\", \"li,\", \"w.\", \"(2021).\", \"layoutparser:\", \"a\", \"unified\", \"toolkit\", \"for\", \"deep\", \"learning\", \"based\", \"document\", \"image\", \"analysis.\", \"in\", \"lecture\", \"notes\", \"in\", \"computer\", \"science\", \"(pp.\", \"131\\u2013146).\", \"https://doi.org/10.1007/978-3-030-86549-8_9\", \"audebert,\", \"n.,\", \"herold,\", \"c.,\", \"slimani,\", \"k.,\", \"&\", \"vidal,\", \"c.\", \"(2020).\", \"multimodal\", \"deep\", \"networks\", \"for\", \"text\", \"and\", \"image-based\", \"document\", \"classification.\", \"in\", \"communications\", \"in\", \"computer\", \"and\", \"information\", \"science\", \"(pp.\", \"427\\u2013443).\", \"https://doi.org/10.1007/978-3-030-43823-4_35\", \"li,\", \"p.,\", \"gu,\", \"j.,\", \"kuen,\", \"j.,\", \"morariu,\", \"v.,\", \"i.,\", \"zhao,\", \"h.,\", \"jain,\", \"r.,\", \"manjunatha,\", \"v.,\", \"&\", \"liu,\", \"h.\", \"(2021).\", \"selfdoc:\", \"self-supervised\", \"document\", \"representation\", \"learning.\", \"https://openaccess.thecvf.com/content/cvpr2021/html/li_selfdoc_self-supervised_docu\", \"ment_representation_learning_cvpr_2021_paper.html\", \"tables:\", \"0\", \"0\", \"concept\", \"paper\", \"1\", \"a.\", \"basic\", \"information\", \"2\", \"p\\\\nroject\", \"title:\", \"propease:\", \"a\", \"smart\", \"paperless\", \"system,\", \"revolutionizing\", \"topic\", \"proposal\", \"matching\", \"and\", \"\\\\ntopic\", \"recommendations\", \"3\", \"t\\\\nopic:\", \"document\", \"processing,\", \"topic\", \"matching,\", \"topic\", \"recommendation,\", \"natural\", \"language\", \"\\\\nprocessing,\", \"image\", \"recognition,\", \"speech\", \"recognition\", \"4\", \"p\\\\nroponent:\", \"cayadong,\", \"marjelaine\", \"m.,\", \"verdad,\", \"jane\", \"benneth\", \"dione\", \"5\", \"b.\", \"technical\", \"description\", \"6\", \"t\\\\n\", \"r\\\\nhe\", \"\\\\ntraditional\", \"methods\", \"of\", \"\\\\nresearch\", \"proposals\", \"and\", \"\\\\nthesis\", \"defense\", \"have\", \"become\", \"\\\\nincreasingly\", \"\\\\ncomplicated,\", \"\\\\ntime-consuming,\", \"\\\\nand\", \"\\\\nexpensive.\", \"traditional\", \"methods\", \"\\\\noften\", \"\\\\ninvolve\", \"\\\\nextensive\", \"\\\\npaperwork,\", \"\\\\nthis\", \"\\\\nincludes\", \"\\\\nprinting\", \"and\", \"organizing\", \"physical\", \"documents\", \"\\\\nlike\", \"concept\", \"papers,\", \"\\\\nmanuscripts,\", \"data\", \"collections,\", \"questionnaires,\", \"drafts\", \"of\", \"the\", \"thesis,\", \"etc..\", \"this\", \"process\", \"is\", \"complicated,\", \"\\\\ntime-consuming,\", \"\\\\nand\", \"\\\\nexpensive.\", \"reviewing\", \"\\\\ndocuments\", \"and\", \"providing\", \"\\\\nfeedback\", \"on\", \"printed\", \"\\\\ndocuments\", \"are\", \"also\", \"a\", \"traditional\", \"method\", \"that\", \"panelists\", \"take\", \"time\", \"to\", \"read\", \"before\", \"giving\", \"comments\", \"\\\\nmanually\", \"then\", \"communicate\", \"back\", \"to\", \"the\", \"researchers.\", \"this\", \"back\", \"and\", \"forth\", \"process\", \"can\", \"prolong\", \"the\", \"\\\\nprocess\", \"of\", \"revision\", \"and\", \"refinement\", \"process\", \"of\", \"research\", \"and\", \"thesis\", \"making.\", \"\\\\nesearchers\", \"and\", \"academic\", \"institutions\", \"are\", \"constantly\", \"seeking\", \"more\", \"efficient\", \"and\", \"innovative\", \"ways\", \"to\", \"\\\\nmodernize\", \"the\", \"process\", \"of\", \"proposals\", \"and\", \"defenses.\", \"the\", \"emergence\", \"of\", \"paperless\", \"systems\", \"has\", \"opened\", \"\\\\nup\", \"new\", \"possibilities\", \"for\", \"revolutionizing\", \"how\", \"research\", \"proposals\", \"and\", \"thesis\", \"defense\", \"are\", \"handled\", \"in\", \"\\\\nacademics.\", \"digitizing\", \"research\", \"documents\", \"enhances\", \"efficiency\", \"and\", \"facilitates\", \"easy\", \"sharing\", \"among\", \"\\\\nresearchers\", \"and\", \"panelists.\", \"this\", \"approach\", \"enables\", \"seamless\", \"access\", \"and\", \"sharing\", \"research\", \"documents\", \"\\\\nanytime\", \"and\", \"anywhere.\", \"digitized\", \"research\", \"documents\", \"are\", \"easily\", \"retrievable\", \"and\", \"searchable\", \"that\", \"\\\\nensures\", \"quick\", \"access\", \"to\", \"relevant\", \"information\", \"during\", \"discussion,\", \"revisions,\", \"and\", \"presentations.\", \"going\", \"\\\\npaperless\", \"reduces\", \"the\", \"expenses\", \"of\", \"having\", \"to\", \"print\", \"for\", \"a\", \"document.\", \"paperless\", \"systems\", \"save\", \"time\", \"spent\", \"\\\\non\", \"reading\", \"printed\", \"documents\", \"that\", \"panelists\", \"can\", \"provide\", \"feedback\", \"and\", \"collaborate\", \"remotely.\", \"it\", \"\\\\noptimizes\", \"\\\\ntime\", \"management\", \"and\", \"resource\", \"utilization.\", \"adapting\", \"to\", \"digital\", \"tools\", \"and\", \"embracing\", \"\\\\npaperless\", \"processes,\", \"promotes\", \"eco-friendly\", \"practices.\", \"it\", \"contributes\", \"to\", \"environmental\", \"sustainability\", \"\\\\nby\", \"reducing\", \"paper\", \"consumption,\", \"minimizing\", \"waste,\", \"and\", \"lowering\", \"carbon\", \"footprint.\", \"the\", \"process\", \"of\", \"\\\\ntransitioning\", \"to\", \"a\", \"paperless\", \"system\", \"in\", \"university\", \"for\", \"research\", \"defense\", \"and\", \"research\", \"proposals\", \"can\", \"be\", \"\\\\ncomplicated\", \"however,\", \"by\", \"developing\", \"and\", \"implementing\", \"a\", \"smart\", \"paperless\", \"system\", \"the\", \"process\", \"of\", \"\\\\nresearch\", \"proposals\", \"and\", \"thesis\", \"defense\", \"can\", \"be\", \"much\", \"easier.\", \"0\", \"0\", \"by\", \"making\", \"use\", \"of\", \"the\", \"power\", \"of\", \"advanced\", \"technologies\", \"such\", \"as\", \"machine\", \"learning,\", \"and\", \"data\", \"analytics,\", \"\\\\nthese\", \"systems\", \"can\", \"significantly\", \"enhance\", \"the\", \"efficiency,\", \"accuracy,\", \"and\", \"effectiveness\", \"of\", \"topic\", \"matching\", \"\\\\nand\", \"topic\", \"recommendations.\", \"this\", \"system\", \"will\", \"not\", \"only\", \"streamline\", \"the\", \"process\", \"of\", \"topic\", \"proposal\", \"\\\\nmatching\", \"but\", \"also\", \"provide\", \"targeted\", \"recommendations\", \"tailored\", \"to\", \"the\", \"unique\", \"needs\", \"and\", \"interests\", \"of\", \"\\\\nresearchers,\", \"students,\", \"and\", \"academic\", \"institutions.\", \"by\", \"automating\", \"tedious\", \"tasks\", \"and\", \"leveraging\", \"the\", \"\\\\npower\", \"of\", \"advanced\", \"\\\\ntechnologies,\", \"\\\\nthis\", \"\\\\nsmart\", \"paperless\", \"\\\\nsystem\", \"aspires\", \"\\\\nto\", \"be\", \"a\", \"prompt\", \"\\\\nfor\", \"\\\\ntransformative\", \"advancements\", \"\\\\nin\", \"academic\", \"discovery\", \"and\", \"knowledge\", \"dissemination.\", \"this\", \"paper\", \"\\\\nexplores\", \"the\", \"potential\", \"of\", \"a\", \"smart\", \"paperless\", \"system\", \"in\", \"transforming\", \"the\", \"landscape\", \"of\", \"topic\", \"proposal\", \"\\\\nmatching\", \"and\", \"topic\", \"recommendations.\", \"1\", \"s\\\\n\", \"t\\\\n\", \"t\\\\ntatement\", \"of\", \"the\", \"problem:\", \"\\\\nhe\", \"traditional\", \"methods\", \"of\", \"topic\", \"proposal\", \"matching\", \"and\", \"topic\", \"recommendations\", \"in\", \"academics\", \"are\", \"\\\\noften\", \"inconvenient,\", \"time-consuming,\", \"and\", \"lack\", \"the\", \"efficiency\", \"needed\", \"to\", \"cope\", \"with\", \"the\", \"amounts\", \"of\", \"\\\\ndata.\", \"researchers\", \"and\", \"panelists\", \"face\", \"challenges\", \"in\", \"accurately\", \"matching\", \"proposals\", \"with\", \"suitable\", \"\\\\ntopics,\", \"leading\", \"to\", \"inefficiencies,\", \"and\", \"poor\", \"resource\", \"allocation.\", \"the\", \"absence\", \"of\", \"advanced\", \"analytical\", \"\\\\ncapabilities\", \"delay\", \"the\", \"ability\", \"to\", \"provide\", \"personalized\", \"and\", \"relevant\", \"recommendations\", \"to\", \"a\", \"researcher\'s\", \"\\\\nneeds.\", \"\\\\nhus,\", \"this\", \"study\", \"specifically\", \"seeks\", \"to\", \"address\", \"the\", \"following\", \"problems:\", \"\\\\n1.\", \"how\", \"can\", \"advanced\", \"\\\\ntechnology\", \"be\", \"of\", \"use\", \"\\\\nto\", \"automate\", \"\\\\ntopic\", \"proposal\", \"matching\", \"\\\\nin\", \"a\", \"\\\\nmodernized\", \"way\", \"of\", \"research\", \"proposal?\", \"\\\\n2.\", \"how\", \"\\\\nwill\", \"\\\\nthe\", \"\\\\nintegration\", \"\\\\nof\", \"\\\\nadvanced\", \"\\\\ntechnologies\", \"\\\\ngenerate\", \"\\\\naccurate\", \"\\\\ntopic\", \"\\\\nrecommendations?\", \"\\\\n3.\", \"how\", \"will\", \"speech\", \"recognition\", \"technology\", \"be\", \"integrated\", \"into\", \"the\", \"system\", \"to\", \"enhance\", \"user\", \"\\\\ninteraction?\", \"\\\\n4.\", \"\\\\nin\", \"what\", \"way\", \"could\", \"\\\\nthe\", \"\\\\nresearchers\", \"\\\\nincorporate\", \"\\\\nthe\", \"model\", \"\\\\nthat\", \"performs\", \"\\\\nthe\", \"best,\", \"as\", \"\\\\ndetermined\", \"by\", \"how\", \"well\", \"it\", \"produces\", \"accurate\", \"responses?\", \"\\\\n5.\", \"how\", \"may\", \"real\", \"testing\", \"be\", \"used\", \"to\", \"assess\", \"the\", \"performance\", \"of\", \"the\", \"developed\", \"system?\", \"2\", \"o\\\\n\", \"t\\\\nbjectives:\", \"general\", \"and\", \"specific\", \"general\", \"objective:\", \"\\\\nhe\", \"main\", \"objective\", \"of\", \"this\", \"study\", \"is\", \"to\", \"design\", \"and\", \"develop\", \"a\", \"web-based\", \"that\", \"helps\", \"researchers\", \"and\", \"\\\\npanelists\", \"in\", \"the\", \"process\", \"of\", \"topic\", \"proposal\", \"and\", \"topic\", \"recommendation.\", \"specifically,\", \"this\", \"study\", \"aims\", \"to:\", \"\\\\n\", \"\\\\n1.\", \"develop\", \"a\", \"user-friendly\", \"smart\", \"paperless\", \"system\", \"leveraging\", \"the\", \"following\", \"technologies\", \"to\", \"\\\\nautomate\", \"and\", \"streamline\", \"the\", \"topic\", \"proposal\", \"matching\", \"process:\", \"\\\\n1.1\", \"natural\", \"language\", \"processing\", \"(nlp)\", \"\\\\n1.2\", \"document\", \"processing\", \"\\\\n1.3\", \"speech\", \"recognition\", \"\\\\n1.4\", \"image\", \"recognition\", \"technologies\", \"\\\\n2.\", \"enhance\", \"the\", \"system\'s\", \"ability\", \"to\", \"understand,\", \"categorize,\", \"and\", \"analyze\", \"textual\", \"and\", \"visual\", \"data\", \"\\\\nwithin\", \"research\", \"proposals\", \"to\", \"generate\", \"accurate\", \"topic\", \"recommendations.\", \"\\\\n3.\", \"\\\\nimprove\", \"accessibility\", \"and\", \"user\", \"experience\", \"by\", \"integrating\", \"speech\", \"recognition\", \"capabilities,\", \"\\\\nallowing\", \"users\", \"to\", \"interact\", \"with\", \"the\", \"system\", \"using\", \"voice\", \"recognition\", \"and\", \"natural\", \"language\", \"\\\\nqueries.\", \"0\", \"0\", \"p\\\\n\", \"\\\\ntable\", \"detection\", \"and\", \"tabular\", \"data\", \"extraction\", \"from\", \"scanned\", \"document\", \"images.\", \"shubham,\", \"\\\\ns.p.,\", \"et.\", \"al.,\", \"2019)\", \"\\\\natents\", \"\\\\n\", \"\\\\n15.\", \"the\", \"plagiarism\", \"is\", \"an\", \"increasingly\", \"widespread\", \"and\", \"growing\", \"problem\", \"in\", \"the\", \"academic\", \"field.\", \"\\\\nseveral\", \"plagiarism\", \"\\\\ntechniques\", \"are\", \"used\", \"by\", \"fraudsters,\", \"ranging\", \"from\", \"a\", \"simple\", \"synonym\", \"\\\\nreplacement,\", \"sentence\", \"structure\", \"modification,\", \"to\", \"more\", \"complex\", \"method\", \"involving\", \"several\", \"\\\\ntypes\", \"of\", \"transformation.\", \"human\", \"based\", \"plagiarism\", \"detection\", \"is\", \"difficult,\", \"not\", \"accurate,\", \"and\", \"\\\\ntime-consuming\", \"process.\", \"in\", \"this\", \"paper\", \"we\", \"propose\", \"a\", \"plagiarism\", \"detection\", \"framework\", \"based\", \"\\\\non\", \"three\", \"deep\", \"learning\", \"models:\", \"doc2vec,\", \"siamese\", \"long\", \"short-term\", \"memory\", \"(slstm)\", \"and\", \"\\\\nconvolutional\", \"neural\", \"network\", \"(cnn).\", \"our\", \"system\", \"uses\", \"three\", \"layers:\", \"preprocessing\", \"layer\", \"\\\\nincluding\", \"word\", \"embedding,\", \"learning\", \"layers\", \"and\", \"detection\", \"layer.\", \"to\", \"evaluate\", \"our\", \"system,\", \"\\\\nwe\", \"carried\", \"out\", \"a\", \"study\", \"on\", \"plagiarism\", \"detection\", \"tools\", \"from\", \"the\", \"academic\", \"field\", \"and\", \"make\", \"a\", \"\\\\ncomparison\", \"based\", \"on\", \"a\", \"set\", \"of\", \"features.\", \"compared\", \"to\", \"other\", \"works,\", \"our\", \"approach\", \"performs\", \"a\", \"\\\\ngood\", \"accuracy\", \"of\", \"98.33\", \"%\", \"and\", \"can\", \"detect\", \"different\", \"types\", \"of\", \"plagiarism,\", \"enables\", \"to\", \"specify\", \"\\\\nanother\", \"dataset\", \"and\", \"supports\", \"to\", \"compare\", \"the\", \"document\", \"from\", \"an\", \"internet\", \"search.\", \"(a\", \"new\", \"\\\\nonline\", \"plagiarism\", \"detection\", \"system\", \"based\", \"on\", \"deep\", \"learning.\", \"hambi,\", \"e.m.,\", \"et.\", \"al.,\", \"2020)\", \"\\\\n\", \"\\\\n16.\", \"summarizes\", \"\\\\nthe\", \"research\", \"on\", \"computational\", \"methods\", \"\\\\nto\", \"detect\", \"academic\", \"plagiarism\", \"by\", \"\\\\nsystematically\", \"reviewing\", \"239\", \"research\", \"papers\", \"published\", \"between\", \"2013\", \"and\", \"2018.\", \"to\", \"structure\", \"\\\\nthe\", \"presentation\", \"of\", \"\\\\nthe\", \"\\\\nresearch\", \"contributions,\", \"we\", \"propose\", \"novel\", \"\\\\ntechnically\", \"oriented\", \"\\\\ntypologies\", \"for\", \"plagiarism\", \"prevention\", \"and\", \"detection\", \"efforts,\", \"the\", \"forms\", \"of\", \"academic\", \"plagiarism,\", \"\\\\nand\", \"computational\", \"plagiarism\", \"detection\", \"methods.\", \"we\", \"show\", \"\\\\nthat\", \"academic\", \"plagiarism\", \"\\\\ndetection\", \"is\", \"a\", \"highly\", \"active\", \"research\", \"field.\", \"over\", \"the\", \"period\", \"we\", \"review,\", \"the\", \"field\", \"has\", \"seen\", \"\\\\nmajor\", \"\\\\nadvances\", \"\\\\nregarding\", \"\\\\nthe\", \"automated\", \"detection\", \"of\", \"\\\\nstrongly\", \"obfuscated\", \"and\", \"\\\\nthus\", \"\\\\nhard-to-identify\", \"forms\", \"of\", \"academic\", \"plagiarism.\", \"these\", \"improvements\", \"mainly\", \"originate\", \"from\", \"\\\\nbetter\", \"semantic\", \"text\", \"analysis\", \"methods,\", \"the\", \"investigation\", \"of\", \"non-textual\", \"content\", \"features,\", \"and\", \"\\\\nthe\", \"\\\\napplication\", \"\\\\nof\", \"machine\", \"\\\\nlearning.\", \"we\", \"\\\\nidentify\", \"\\\\na\", \"\\\\nresearch\", \"\\\\ngap\", \"\\\\nin\", \"\\\\nthe\", \"\\\\nlack\", \"\\\\nof\", \"\\\\nmethodologically\", \"\\\\nthorough\", \"\\\\nperformance\", \"\\\\nevaluations\", \"of\", \"plagiarism\", \"detection\", \"\\\\nsystems.\", \"\\\\nconcluding\", \"from\", \"our\", \"analysis,\", \"we\", \"see\", \"the\", \"integration\", \"of\", \"heterogeneous\", \"analysis\", \"methods\", \"for\", \"\\\\ntextual\", \"and\", \"non-textual\", \"content\", \"features\", \"using\", \"machine\", \"learning\", \"as\", \"the\", \"most\", \"promising\", \"area\", \"\\\\nfor\", \"future\", \"research\", \"contributions\", \"to\", \"improve\", \"the\", \"detection\", \"of\", \"academic\", \"plagiarism\", \"further.\", \"\\\\n(academic\", \"plagiarism\", \"detection.\", \"folt\\u00fdnek,\", \"t.,\", \"et.\", \"al.,\", \"2019)\", \"1\", \"t\\\\nhow\", \"do\", \"you\", \"intend\", \"to\", \"solve\", \"the\", \"problem?\", \"\\\\nhe\", \"proponents\", \"of\", \"the\", \"study\", \"plan\", \"to\", \"solve\", \"the\", \"problem\", \"by\", \"developing\", \"a\", \"website/\", \"application\", \"that\", \"will\", \"\\\\ngather\", \"the\", \"data\", \"from\", \"the\", \"published\", \"thesis\", \"papers\", \"through\", \"machine\", \"learning\", \"using\", \"image\", \"processing\", \"\\\\nand\", \"natural\", \"language\", \"processing.\", \"the\", \"said\", \"website/\", \"application\", \"will\", \"be\", \"acting\", \"as\", \"a\", \"grading\", \"system\", \"for\", \"\\\\nplagiarism\", \"for\", \"a\", \"title\", \"and\", \"concept\", \"similar\", \"to\", \"another\", \"and\", \"recommend\", \"titles\", \"that\", \"are\", \"similar\", \"to\", \"the\", \"topic\", \"\\\\nfor\", \"a\", \"new\", \"solution\", \"to\", \"a\", \"problem.\", \"the\", \"system\", \"will\", \"be\", \"able\", \"to\", \"give\", \"panelists\", \"the\", \"idea\", \"the\", \"student\", \"is\", \"\\\\nportraying\", \"by\", \"using\", \"the\", \"speech\", \"to\", \"text\", \"while\", \"the\", \"proponent\", \"is\", \"giving\", \"their\", \"explanation\", \"and\", \"insight\", \"to\", \"\\\\ntheir\", \"concept\", \"papers.\", \"it\", \"can\", \"also\", \"scan\", \"the\", \"soft\", \"copy\", \"document\", \"to\", \"see\", \"if\", \"the\", \"concept\", \"is\", \"already\", \"existing\", \"\\\\nor\", \"not.\", \"0\", \"1\", \"2\", \"3\", \"4\", \"0\", \"figure\", \"1.1\", \"home\", \"page\", \"website\", \"gui\", \"\\\\nusers\", \"are\", \"greeted\", \"with\", \"a\", \"brief\", \"overview\", \"of\", \"the\", \"website/application\'s\", \"capabilities\", \"and\", \"purpose\", \"on\", \"the\", \"\\\\nmain\", \"page.\", \"important\", \"sections\", \"like\", \"\\\"proposals,\\\"\", \"\\\"trash,\\\"\", \"\\\"account,\\\"\", \"and\", \"\\\"sign\", \"up\\\"\", \"are\", \"clearly\", \"\\\\nlabeled,\", \"making\", \"it\", \"simple\", \"to\", \"navigate\", \"to\", \"the\", \"functions\", \"you\", \"need.\", \"in\", \"order\", \"to\", \"provide\", \"an\", \"easy\", \"and\", \"\\\\neffective\", \"user\", \"experience,\", \"users\", \"are\", \"advised\", \"to\", \"register\", \"for\", \"an\", \"account\", \"or\", \"link\", \"their\", \"emails\", \"in\", \"order\", \"to\", \"\\\\ngain\", \"access\", \"to\", \"other\", \"sections\", \"of\", \"the\", \"website.\", \"\\\\nfigure\", \"1.2\", \"proposals\", \"page\", \"website\", \"gui\", \"\\\\nusers\", \"can\", \"upload\", \"files\", \"to\", \"the\", \"website\", \"for\", \"plagiarism\", \"checks\", \"on\", \"titles\", \"and\", \"contents\", \"in\", \"the\", \"proposal\", \"\\\\nsection.\", \"furthermore,\", \"if\", \"a\", \"file\", \"already\", \"exists\", \"and\", \"has\", \"been\", \"uploaded\", \"and\", \"reviewed,\", \"a\", \"square-like\", \"form\", \"1\", \"2\", \"3\", \"4\", \"5\", \"0\", \"0\", \"stemming/lemmatization\", \"before\", \"applying\", \"machine\", \"learning\", \"algorithms\", \"to\", \"analyze\", \"the\", \"speech\", \"\\\\nbeing\", \"spoken.\", \"the\", \"goal\", \"is\", \"to\", \"check\", \"the\", \"accuracy\", \"and\", \"plagiarism\", \"of\", \"the\", \"proposed\", \"conceptual\", \"\\\\nframework\", \"by\", \"using\", \"speech-to-text\", \"recognition\", \"and\", \"image\", \"or\", \"text\", \"processing.\", \"1\", \"t\\\\narget\", \"users\", \"/\", \"beneficiaries:(describe\", \"each\", \"beneficiary)\", \"\\\\nthis\", \"study\", \"will\", \"be\", \"beneficial\", \"\\\\nto\", \"\\\\nthe\", \"\\\\ninstitution.\", \"smart\", \"paperless\", \"systems\", \"aim\", \"to\", \"enhance\", \"the\", \"\\\\nefficiency,\", \"\\\\ntransparency,\", \"\\\\nand\", \"\\\\neffectiveness\", \"\\\\nof\", \"\\\\nthe\", \"\\\\nresearch\", \"\\\\nproposal\", \"matching\", \"\\\\nand\", \"\\\\ntopic\", \"\\\\nrecommendation\", \"process.\", \"\\\\n\", \"\\\\n1.\", \"administrators\", \"or\", \"program\", \"coordinator:\", \"the\", \"\\\\nsystem\", \"can\", \"be\", \"effectively\", \"used\", \"by\", \"\\\\nadministrators\", \"or\", \"program\", \"managers\", \"in\", \"charge\", \"of\", \"research\", \"programs\", \"or\", \"funding\", \"initiatives\", \"to\", \"\\\\nhandle\", \"proposal\", \"submissions\", \"and\", \"topic\", \"selection\", \"procedures.\", \"through\", \"the\", \"automation\", \"of\", \"\\\\nrepetitive\", \"\\\\noperations\", \"\\\\nlike\", \"proposal\", \"matching\", \"and\", \"document\", \"processing,\", \"\\\\nthe\", \"\\\\nsystem\'s\", \"\\\\nautomation\", \"capabilities\", \"lessen\", \"the\", \"administrative\", \"pressure.\", \"\\\\n\", \"\\\\n2.\", \"panelists\", \"or\", \"reviewers:\", \"the\", \"automation\", \"of\", \"the\", \"system,\", \"which\", \"assists\", \"in\", \"matching\", \"proposals\", \"\\\\nwith\", \"relevant\", \"topics,\", \"will\", \"be\", \"helpful\", \"to\", \"panelists\", \"considering\", \"research\", \"proposals\", \"or\", \"topic\", \"\\\\nsubmissions.\", \"panelists\", \"are\", \"able\", \"to\", \"efficiently\", \"comprehend\", \"and\", \"evaluate\", \"proposal\", \"material\", \"\\\\nbecause\", \"of\", \"the\", \"system\'s\", \"natural\", \"language\", \"processing\", \"(nlp)\", \"capabilities,\", \"which\", \"guarantees\", \"\\\\neffective\", \"decision-making\", \"procedures.\", \"\\\\n\", \"\\\\n3.\", \"future\", \"researchers:\", \"the\", \"streamlined\", \"method\", \"of\", \"matching\", \"\\\\ntopic\", \"proposals\", \"will\", \"help\", \"\\\\nresearchers\", \"find\", \"relevant\", \"study\", \"ideas\", \"more\", \"quickly\", \"and\", \"efficiently,\", \"saving\", \"them\", \"time\", \"and\", \"\\\\neffort.\", \"they\", \"may\", \"analyze\", \"enormous\", \"volumes\", \"of\", \"text\", \"data,\", \"extract\", \"important\", \"information,\", \"and\", \"\\\\nproduce\", \"insights\", \"for\", \"their\", \"research\", \"by\", \"using\", \"the\", \"system\'s\", \"natural\", \"language\", \"processing\", \"(nlp)\", \"\\\\ncapabilities.\", \"research\", \"papers,\", \"\\\\njournals,\", \"and\", \"other\", \"pertinent\", \"documents\", \"can\", \"be\", \"quickly\", \"\\\\nreviewed\", \"and\", \"categorized\", \"by\", \"researchers\", \"with\", \"the\", \"use\", \"of\", \"document\", \"processing\", \"tools.\", \"2\", \"s\\\\nignificance\", \"of\", \"study:\", \"\\\\nthis\", \"study\", \"will\", \"help\", \"researchers\", \"perform\", \"efficient\", \"and\", \"well-organized\", \"research\", \"methods\", \"in\", \"addition\", \"\\\\nto\", \"benefiting\", \"panelists\", \"for\", \"time\", \"management\", \"and\", \"efforts.\", \"\\\\n\", \"\\\\n1.\", \"panelists:\", \"the\", \"accuracy\", \"and\", \"speed\", \"with\", \"which\", \"panelists\", \"connect\", \"research\", \"proposals\", \"with\", \"\\\\nappropriate\", \"concepts\", \"will\", \"\\\\nimprove\", \"during\", \"\\\\nthe\", \"assessment\", \"and\", \"selection\", \"process.\", \"by\", \"\\\\nautomating\", \"the\", \"matching\", \"process,\", \"biases,\", \"and\", \"manual\", \"effort\", \"are\", \"minimized,\", \"resulting\", \"in\", \"an\", \"\\\\nequal\", \"evaluation\", \"of\", \"ideas.\", \"the\", \"ability\", \"to\", \"process\", \"papers\", \"more\", \"efficiently\", \"makes\", \"it\", \"easier\", \"to\", \"\\\\nhandle\", \"proposal\", \"materials,\", \"which\", \"improves\", \"the\", \"accessibility\", \"and\", \"organization\", \"of\", \"the\", \"review\", \"\\\\nprocess.\", \"\\\\n\", \"\\\\n2.\", \"researchers:\", \"researchers\", \"will\", \"save\", \"time\", \"and\", \"money\", \"thanks\", \"to\", \"the\", \"process\", \"of\", \"matching\", \"\\\\nsubject\", \"proposals\", \"which\", \"is\", \"now\", \"more\", \"efficient.\", \"by\", \"utilizing\", \"nlp\", \"capabilities,\", \"researchers\", \"can\", \"\\\\ngain\", \"deeper\", \"insights\", \"by\", \"enhancing\", \"their\", \"comprehension\", \"and\", \"analysis\", \"of\", \"study\", \"materials.\", \"\\\\nspeech\", \"and\", \"picture\", \"recognition\", \"technologies\", \"allow\", \"users\", \"to\", \"engage\", \"with\", \"the\", \"system\", \"in\", \"a\", \"\\\\nnatural\", \"way,\", \"which\", \"speeds\", \"up\", \"the\", \"input\", \"and\", \"retrieval\", \"of\", \"data.\", \"0\", \"1\", \"2\", \"3\", \"0\", \"title\", \"\\\\ndescription\", \"\\\\nscope/technology\", \"\\\\nyear\", \"1\", \"technology\", \"(speech-to-text)\", \"2\", \"automatic\", \"speech\", \"\\\\nrecognition:\", \"\\\\nsystematic\", \"\\\\nliterature\", \"review\", \"in\", \"their\", \"systematic\", \"literature\", \"review,\", \"\\\\nalharbi\", \"et\", \"al.\", \"(2021)\", \"explore\", \"\\\\nthe\", \"\\\\nadvancements\", \"\\\\nin\", \"\\\\nspeech-to-text\", \"\\\\nrecognition\", \"\\\\ntechnology,\", \"\\\\nhighlighting\", \"\\\\nits\", \"\\\\ntransformative\", \"\\\\nimpact\", \"on\", \"data\", \"\\\\ntranscription.\", \"the\", \"\\\\nscope\", \"encompasses\", \"the\", \"conversion\", \"\\\\nof\", \"spoken\", \"words\", \"into\", \"written\", \"text\", \"\\\\nand\", \"\\\\nits\", \"applications\", \"\\\\nin\", \"analyzing\", \"\\\\ninterview\", \"recordings\", \"efficiently\", \"for\", \"\\\\nfurther\", \"\\\\nevaluation\", \"\\\\nof\", \"\\\\napplicant\", \"\\\\nresponses.\", \"\\\\nhowever,\", \"\\\\nthey\", \"\\\\nalso\", \"\\\\nacknowledge\", \"\\\\nthe\", \"\\\\nchallenges\", \"\\\\noutlined\", \"in\", \"their\", \"research,\", \"including\", \"\\\\nfactors\", \"\\\\nsuch\", \"\\\\nas\", \"\\\\nthe\", \"\\\\nnumber\", \"\\\\nof\", \"\\\\nspeakers,\", \"speech\", \"clarity,\", \"vocabulary\", \"\\\\nsize,\", \"and\", \"spectral\", \"bandwidth,\", \"which\", \"\\\\ninfluence\", \"\\\\nthe\", \"\\\\nperformance\", \"\\\\nof\", \"\\\\nautomated\", \"\\\\nspeech\", \"\\\\nrecognition\", \"\\\\nsystems.\", \"this\", \"study\", \"was\", \"published\", \"\\\\nin\", \"2021.\", \"alharbi\", \"\\\\net\", \"\\\\nal.\", \"\\\\n(2021)\", \"\\\\nconducted\", \"\\\\na\", \"\\\\nsystematic\", \"\\\\nliterature\", \"review\", \"focusing\", \"\\\\non\", \"\\\\nthe\", \"\\\\nadvancements\", \"\\\\nin\", \"\\\\nspeech-to-text\", \"\\\\nrecognition\", \"\\\\ntechnology.\", \"their\", \"research\", \"\\\\nexplores\", \"\\\\nthe\", \"\\\\ntransformative\", \"\\\\nimpact\", \"\\\\nof\", \"\\\\nthis\", \"\\\\ntechnology\", \"\\\\non\", \"\\\\ndata\", \"\\\\ntranscription,\", \"\\\\nparticularly\", \"\\\\nin\", \"\\\\nconverting\", \"\\\\nspoken\", \"\\\\nwords\", \"into\", \"written\", \"text.\", \"2021\", \"3\", \"challenges\", \"and\", \"\\\\nlimitations\", \"in\", \"\\\\nspeech\", \"\\\\nrecognition\", \"\\\\ntechnology:\", \"a\", \"\\\\ncritical\", \"review\", \"of\", \"\\\\nspeech\", \"signal\", \"\\\\nprocessing\", \"\\\\nalgorithm,\", \"tools\", \"\\\\nand\", \"systems.\", \"t\\\\nin\", \"\\\\ntheir\", \"\\\\nstudy\", \"by\", \"sneha\", \"basak,\", \"\\\\nhimanshi\", \"agrawal,\", \"shreya\", \"\\\\njena,\", \"\\\\nshilpa\", \"\\\\ngite,\", \"\\\\nmrinal\", \"\\\\nbachute,\", \"\\\\nbiswajeet\", \"\\\\npradhan,\", \"\\\\nand\", \"mazen\", \"\\\\nassiri\", \"\\\\n(2022),\", \"\\\\nthe\", \"\\\\nresearchers\", \"\\\\nacknowledge\", \"\\\\nthe\", \"\\\\nsignificance\", \"\\\\nof\", \"\\\\nspeech\", \"\\\\nrecognition\", \"\\\\ntechnology\", \"\\\\nwhile\", \"also\", \"addressing\", \"factors\", \"that\", \"\\\\nrequire\", \"\\\\nattention\", \"\\\\nfor\", \"\\\\nfurther\", \"\\\\nimprovement.\", \"\\\\nhey\", \"highlight\", \"challenges\", \"such\", \"as\", \"\\\\nvariation\", \"\\\\nin\", \"accents,\", \"which\", \"pose\", \"\\\\ndifficulties\", \"\\\\nfor\", \"\\\\nmachines\", \"\\\\nto\", \"\\\\nunderstand\", \"\\\\ndifferent\", \"\\\\npronunciations,\", \"\\\\nintonations,\", \"\\\\nand\", \"\\\\naccents.\", \"the\", \"study\", \"raises\", \"concerns\", \"\\\\nabout\", \"the\", \"lack\", \"of\", \"speech\", \"recognition\", \"\\\\nsystems\", \"designed\", \"\\\\nspecifically\", \"\\\\nfor\", \"\\\\nchildren,\", \"\\\\ndespite\", \"\\\\nthe\", \"\\\\nincreasing\", \"\\\\nprevalence\", \"\\\\nof\", \"\\\\ne-learning\", \"\\\\nand\", \"\\\\nchildren\", \"spending\", \"significant\", \"time\", \"\\\\non\", \"\\\\nscreens.\", \"the\", \"\\\\nslower\", \"pace\", \"at\", \"the\", \"scope\", \"of\", \"the\", \"study\", \"\\\\nconducted\", \"by\", \"sneha\", \"\\\\nbasak,\", \"himanshi\", \"agrawal,\", \"\\\\nshreya\", \"jena,\", \"shilpa\", \"gite,\", \"\\\\nmrinal\", \"bachute,\", \"biswajeet\", \"\\\\npradhan,\", \"and\", \"mazen\", \"assiri\", \"\\\\n(2022)\", \"encompasses\", \"a\", \"\\\\ncritical\", \"review\", \"of\", \"speech\", \"\\\\nrecognition\", \"technology,\", \"\\\\nfocusing\", \"on\", \"challenges\", \"and\", \"\\\\nlimitations\", \"within\", \"the\", \"field.\", \"\\\\nthe\", \"researchers\", \"delve\", \"into\", \"\\\\nvarious\", \"aspects\", \"of\", \"speech\", \"\\\\nsignal\", \"processing\", \"\\\\nalgorithms,\", \"tools,\", \"and\", \"\\\\nsystems,\", \"aiming\", \"to\", \"identify\", \"\\\\nareas\", \"that\", \"require\", \"further\", \"\\\\nattention\", \"for\", \"improvement.\", \"2022\", \"0\", \"1\", \"2\", \"3\", \"0\", \"e\\\\nwhich\", \"\\\\nchildren\", \"\\\\nunderstand\", \"\\\\nnew\", \"\\\\nwords\", \"\\\\nfurther\", \"\\\\ncomplicates\", \"\\\\nthe\", \"\\\\nability\", \"of\", \"current\", \"speech\", \"recognition\", \"\\\\nsystems\", \"\\\\nto\", \"\\\\ncomprehend\", \"\\\\nchild\", \"\\\\nvocabulary\", \"effectively.\", \"the\", \"study\", \"\\\\ndiscusses\", \"the\", \"importance\", \"of\", \"model\", \"\\\\ntraining\", \"to\", \"avoid\", \"overfitting,\", \"which\", \"\\\\ncould\", \"\\\\nnegatively\", \"\\\\nimpact\", \"\\\\nthe\", \"\\\\nperformance\", \"of\", \"speech\", \"recognition\", \"\\\\nsystems\", \"\\\\nby\", \"\\\\nadding\", \"\\\\nunnecessary\", \"\\\\nconcepts.\", \"\\\\nnvironmental\", \"noise\", \"is\", \"identified\", \"as\", \"\\\\nanother\", \"significant\", \"challenge,\", \"as\", \"it\", \"\\\\ncan\", \"\\\\nseverely\", \"\\\\naffect\", \"\\\\nspeech\", \"\\\\ntranscription\", \"\\\\naccuracy.\", \"\\\\nthrough\", \"\\\\nthese\", \"\\\\nobservations,\", \"\\\\nthe\", \"\\\\nstudy\", \"\\\\nprovides\", \"valuable\", \"insights\", \"into\", \"the\", \"\\\\nlimitations\", \"and\", \"challenges\", \"\\\\nfacing\", \"\\\\nspeech\", \"\\\\nrecognition\", \"\\\\ntechnology,\", \"\\\\nsuggesting\", \"\\\\nareas\", \"\\\\nfor\", \"\\\\nfurther\", \"\\\\nresearch\", \"and\", \"development.\", \"1\", \"multilingual\", \"\\\\nspeech\", \"models\", \"for\", \"\\\\nautomatic\", \"\\\\nspeech\", \"\\\\nrecognition\", \"\\\\nexhibit\", \"\\\\ngender\", \"\\\\nperformance\", \"gaps\", \"attanasio,\", \"\\\\nsavoldi,\", \"\\\\nfucci,\", \"\\\\nand\", \"\\\\nhovy\", \"(2024)\", \"address\", \"limitations\", \"in\", \"\\\\nresearch\", \"\\\\nrelated\", \"\\\\nto\", \"\\\\ngender\", \"\\\\nand\", \"\\\\nsocial-cultural\", \"\\\\nfactors\", \"\\\\nin\", \"\\\\nvoice\", \"\\\\nrecognition.\", \"\\\\nthe\", \"\\\\nscope\", \"\\\\nencompasses\", \"the\", \"need\", \"for\", \"a\", \"broader\", \"\\\\ndataset\", \"\\\\nconsidering\", \"dialects,\", \"\\\\nsex,\", \"\\\\nand\", \"\\\\nother\", \"\\\\ncultural\", \"\\\\nfactors\", \"\\\\nto\", \"\\\\nimprove\", \"the\", \"results\'\", \"robustness.\", \"the\", \"\\\\nauthors\", \"\\\\nalso\", \"\\\\nhighlight\", \"\\\\nissues\", \"\\\\nof\", \"\\\\ngeneralizability\", \"\\\\ndue\", \"\\\\nto\", \"\\\\nthe\", \"\\\\ncategorization\", \"\\\\nof\", \"\\\\nparticipants\", \"\\\\nas\", \"\\\\n\\\"other\\\"\", \"\\\\nand\", \"\\\\nthe\", \"\\\\ncomparison\", \"\\\\nof\", \"\\\\nspeakers\", \"across\", \"different\", \"platforms.\", \"\\\\nadditionally,\", \"\\\\nthey\", \"\\\\nstress\", \"\\\\nthe\", \"\\\\nimportance\", \"of\", \"data\", \"quality\", \"and\", \"the\", \"\\\\npotential\", \"biases\", \"introduced\", \"by\", \"the\", \"\\\\nlack\", \"of\", \"multilingual\", \"phonetic\", \"tools.\", \"attanasio,\", \"savoldi,\", \"fucci,\", \"\\\\nand\", \"hovy\", \"(2024)\", \"address\", \"\\\\nthe\", \"limitations\", \"in\", \"research\", \"\\\\nconcerning\", \"\\\\ngender\", \"\\\\nand\", \"\\\\nsocial-cultural\", \"\\\\nfactors\", \"\\\\nin\", \"\\\\nvoice\", \"\\\\nrecognition.\", \"\\\\ntheir\", \"\\\\nstudy\", \"\\\\nemphasizes\", \"\\\\nthe\", \"\\\\nnecessity\", \"\\\\nfor\", \"\\\\na\", \"\\\\nbroader\", \"\\\\ndataset\", \"\\\\nencompassing\", \"\\\\ndialects,\", \"\\\\nsex,\", \"\\\\nand\", \"\\\\nother\", \"\\\\ncultural\", \"factors\", \"to\", \"enhance\", \"\\\\nresult\", \"robustness.\", \"2024\", \"2\", \"improving\", \"\\\\nreadability\", \"for\", \"\\\\nautomatic\", \"speech\", \"\\\\nrecognition\", \"\\\\ntranscription\", \"this\", \"research\", \"paper\", \"addresses\", \"the\", \"\\\\nreadability\", \"\\\\nchallenges\", \"\\\\nposed\", \"\\\\nby\", \"\\\\nmodern\", \"\\\\nautomatic\", \"\\\\nspeech\", \"\\\\nrecognition\", \"(asr)\", \"systems,\", \"which\", \"\\\\nmay\", \"produce\", \"accurate\", \"\\\\ntranscripts\", \"\\\\nbut\", \"can\", \"still\", \"be\", \"difficult\", \"to\", \"read\", \"due\", \"the\", \"scope\", \"of\", \"the\", \"research\", \"\\\\npaper\", \"encompasses\", \"the\", \"\\\\nrealm\", \"of\", \"automatic\", \"\\\\nspeech\", \"recognition\", \"(asr)\", \"\\\\nsystems\", \"and\", \"their\", \"impact\", \"\\\\non\", \"readability\", \"in\", \"2023\", \"0\", \"1\", \"2\", \"3\", \"0\", \"to\", \"grammatical\", \"errors,\", \"disfluency,\", \"\\\\nand\", \"other\", \"spoken\", \"communication\", \"\\\\nnuances.\", \"the\", \"paper\", \"introduces\", \"the\", \"\\\\nasr\", \"post-processing\", \"for\", \"readability\", \"\\\\n(apr)\", \"\\\\ntask,\", \"\\\\nformulated\", \"\\\\nas\", \"\\\\na\", \"\\\\nsequence-to-sequence\", \"\\\\ntext\", \"\\\\ngeneration\", \"problem,\", \"with\", \"the\", \"goal\", \"\\\\nof\", \"transforming\", \"noisy\", \"asr\", \"outputs\", \"\\\\ninto\", \"readable\", \"text\", \"while\", \"preserving\", \"\\\\nsemantic\", \"meaning.\", \"\\\\nthe\", \"\\\\nauthors\", \"\\\\nconstruct\", \"a\", \"dataset\", \"for\", \"apr\", \"using\", \"\\\\ndata\", \"\\\\nfrom\", \"\\\\ngrammatical\", \"\\\\nerror\", \"\\\\ncorrection\", \"tasks\", \"and\", \"evaluate\", \"model\", \"\\\\nperformance\", \"using\", \"adapted\", \"metrics.\", \"\\\\nthey\", \"compare\", \"fine-tuned\", \"baseline\", \"\\\\nmodels\", \"with\", \"\\\\ntraditional\", \"\\\\npipeline\", \"\\\\nmethods,\", \"demonstrating\", \"significant\", \"\\\\nimprovements\", \"in\", \"readability\", \"on\", \"test\", \"\\\\nsets\", \"and\", \"confirming\", \"\\\\ntheir\", \"model\'s\", \"\\\\nefficacy\", \"through\", \"human\", \"evaluation\", \"\\\\nand\", \"case\", \"studies.\", \"transcripts.\", \"it\", \"delves\", \"into\", \"\\\\nthe\", \"challenges\", \"faced\", \"when\", \"\\\\nasr\", \"systems\", \"produce\", \"\\\\naccurate\", \"but\", \"often\", \"\\\\ndifficult-to-read\", \"transcripts\", \"\\\\ndue\", \"to\", \"grammatical\", \"errors,\", \"\\\\ndisfluencies,\", \"and\", \"other\", \"\\\\nspoken\", \"communication\", \"\\\\nnuances.\", \"1\", \"text-independent\", \"\\\\nspeaker\", \"recognition\", \"\\\\nusing\", \"lstm-rnn\", \"\\\\nand\", \"speech\", \"\\\\nenhancement\", \"this\", \"\\\\nresearch\", \"\\\\npaper\", \"\\\\nexplores\", \"\\\\ntext-independent\", \"\\\\nspeaker\", \"\\\\nrecognition\", \"\\\\nin\", \"\\\\nthe\", \"\\\\ncontext\", \"\\\\nof\", \"\\\\ndegraded\", \"speech\", \"signals,\", \"including\", \"\\\\nnoise\", \"\\\\nand\", \"\\\\nreverberation.\", \"\\\\nit\", \"\\\\nhighlights\", \"\\\\nthe\", \"\\\\nadvantages\", \"\\\\nof\", \"\\\\ntext-independent\", \"\\\\nspeaker\", \"\\\\nrecognition\", \"\\\\ncompared\", \"\\\\nto\", \"\\\\ntext-dependent\", \"\\\\napproaches,\", \"\\\\nparticularly\", \"\\\\nin\", \"allowing\", \"clients\", \"to\", \"\\\\nspeak\", \"\\\\nfreely\", \"\\\\nto\", \"\\\\nthe\", \"system.\", \"the\", \"\\\\npaper\", \"\\\\nemploys\", \"\\\\nmel-frequency\", \"\\\\ncepstral\", \"\\\\ncoefficients\", \"\\\\n(mfccs),\", \"\\\\nspectrum,\", \"\\\\nand\", \"\\\\nlog-spectrum\", \"\\\\nfor\", \"\\\\nfeature\", \"\\\\nextraction\", \"\\\\nfrom\", \"\\\\nspeech\", \"\\\\nsignals,\", \"\\\\nand\", \"\\\\nutilizes\", \"long-short\", \"\\\\nterm\", \"memory\", \"recurrent\", \"neural\", \"\\\\nnetworks\", \"\\\\n(lstm-rnn)\", \"\\\\nfor\", \"\\\\nclassification\", \"\\\\nto\", \"\\\\nachieve\", \"\\\\nspeaker\", \"\\\\nrecognition.\", \"\\\\nthe\", \"\\\\nsystem\", \"\\\\ndemonstrates\", \"high\", \"recognition\", \"rates,\", \"\\\\nreaching\", \"95.33%\", \"with\", \"mfccs\", \"and\", \"\\\\n98.7%\", \"\\\\nwith\", \"\\\\nspectrum\", \"\\\\nor\", \"\\\\nlog-spectrum,\", \"\\\\nunder\", \"\\\\nsimilar\", \"\\\\nrecording\", \"circumstances.\", \"however,\", \"\\\\nchallenges\", \"arise\", \"when\", \"recognizing\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"\\\\npaper\", \"is\", \"focused\", \"on\", \"\\\\nadvancing\", \"\\\\ntext-independent\", \"speaker\", \"\\\\nrecognition\", \"systems\", \"in\", \"the\", \"\\\\npresence\", \"of\", \"degraded\", \"\\\\nspeech\", \"signals,\", \"including\", \"\\\\nnoise\", \"and\", \"reverberation.\", \"2020\", \"0\", \"1\", \"2\", \"3\", \"0\", \"speakers\", \"across\", \"different\", \"recording\", \"\\\\nenvironments,\", \"prompting\", \"the\", \"use\", \"of\", \"\\\\nspeech\", \"\\\\nenhancement\", \"\\\\ntechniques\", \"\\\\nlike\", \"\\\\nspectral\", \"\\\\nsubtraction\", \"\\\\nand\", \"\\\\nwavelet\", \"\\\\ndenoising\", \"\\\\nto\", \"\\\\nimprove\", \"\\\\nrecognition\", \"\\\\nperformance.\", \"\\\\nthe\", \"\\\\nproposed\", \"\\\\napproach\", \"\\\\nshows\", \"\\\\nsuperiority\", \"\\\\nover\", \"\\\\nprevious\", \"\\\\nalgorithms,\", \"particularly\", \"the\", \"one\", \"by\", \"\\\\nr.\", \"togneri\", \"and\", \"d.\", \"pullella\", \"(2011),\", \"\\\\nshowcasing\", \"\\\\nadvancements\", \"\\\\nin\", \"\\\\ntext-independent\", \"\\\\nspeaker\", \"\\\\nrecognition\", \"under\", \"degraded\", \"speech\", \"\\\\nconditions.\", \"1\", \"t\\\\n\", \"f\\\\nhe\", \"papers\", \"cover\", \"a\", \"wide\", \"range\", \"of\", \"difficulties\", \"and\", \"developments\", \"in\", \"voice\", \"recognition\", \"technology.\", \"\\\\nalharbi\", \"et\", \"al.\", \"(2021)\", \"explore\", \"how\", \"speech-to-text\", \"recognition\", \"technology\", \"can\", \"change\", \"lives,\", \"especially\", \"\\\\nwhen\", \"\\\\nit\", \"comes\", \"\\\\nto\", \"data\", \"\\\\ntranscription\", \"\\\\nfrom\", \"recorded\", \"interviews.\", \"they\", \"recognize\", \"the\", \"difficulties\", \"\\\\npresented\", \"by\", \"variables\", \"that\", \"affect\", \"automated\", \"speech\", \"recognition\", \"systems\'\", \"performance,\", \"such\", \"as\", \"\\\\nspeech\", \"quality,\", \"vocabulary\", \"quantity,\", \"and\", \"ambient\", \"noise.\", \"basak\", \"et\", \"al.\", \"(2022)\", \"go\", \"into\", \"further\", \"detail\", \"\\\\nabout\", \"these\", \"difficulties,\", \"emphasizing\", \"problems\", \"like\", \"accent\", \"variance\", \"and\", \"the\", \"absence\", \"of\", \"kid-friendly\", \"\\\\nsystems.\", \"they\", \"also\", \"highlight\", \"the\", \"shortcomings\", \"of\", \"the\", \"speech\", \"recognition\", \"technologies\", \"available\", \"\\\\ntoday\", \"and\", \"offer\", \"potential\", \"solutions\", \"like\", \"model\", \"training\", \"and\", \"mitigating\", \"background\", \"noise.\", \"\\\\nurthermore,\", \"attanasio\", \"et\", \"al.\", \"(2024)\", \"fill\", \"in\", \"the\", \"study\", \"gaps\", \"concerning\", \"gender\", \"and\", \"social-cultural\", \"\\\\naspects\", \"of\", \"speech\", \"recognition,\", \"highlighting\", \"the\", \"necessity\", \"of\", \"larger\", \"datasets\", \"and\", \"better\", \"data\", \"quality\", \"to\", \"\\\\nincrease\", \"\\\\nthe\", \"voice\", \"recognition\", \"systems\'\", \"resilience\", \"and\", \"applicability.\", \"conversely,\", \"a\", \"study\", \"on\", \"\\\\nautomatic\", \"\\\\nspeech\", \"\\\\nrecognition\", \"\\\\n(asr)\", \"\\\\npost-processing\", \"\\\\nfor\", \"\\\\nreadability\", \"\\\\npresents\", \"\\\\nthe\", \"\\\\nasr\", \"\\\\npost-processing\", \"for\", \"readability\", \"(apr)\", \"challenge,\", \"which\", \"aims\", \"to\", \"correct\", \"grammatical\", \"errors\", \"and\", \"\\\\ndisfluency\", \"in\", \"asr\", \"outputs\", \"in\", \"order\", \"to\", \"make\", \"them\", \"more\", \"readable.\", \"the\", \"state\", \"of\", \"speaker\", \"recognition\", \"\\\\ntechnology\", \"is\", \"further\", \"demonstrated\", \"by\", \"a\", \"study\", \"on\", \"text-independent\", \"speaker\", \"recognition\", \"in\", \"degraded\", \"\\\\nspeech\", \"signals,\", \"which\", \"uses\", \"methods\", \"\\\\nlike\", \"mel-frequency\", \"cepstral\", \"coefficients\", \"(mfccs)\", \"and\", \"\\\\nlong-short\", \"term\", \"memory\", \"recurrent\", \"neural\", \"networks\", \"(lstm-rnn)\", \"to\", \"achieve\", \"high\", \"recognition\", \"\\\\nrates\", \"even\", \"in\", \"difficult\", \"environments.\", \"0\", \"1\", \"2\", \"3\", \"0\", \"title\", \"\\\\ndescription\", \"\\\\nscope/technology\", \"\\\\nyear\", \"1\", \"technology\", \"(image\", \"processing)\", \"2\", \"layoutlm:\", \"\\\\npre-training\", \"of\", \"text\", \"\\\\nand\", \"layout\", \"for\", \"\\\\ndocument\", \"image\", \"\\\\nunderstanding\", \"the\", \"\\\\nresearch\", \"\\\\npaper\", \"\\\\nintroduces\", \"\\\\nlayoutlm,\", \"a\", \"novel\", \"approach\", \"that\", \"\\\\nextends\", \"pre-training\", \"\\\\ntechniques\", \"to\", \"\\\\nencompass\", \"\\\\nlayout\", \"\\\\nand\", \"\\\\nstyle\", \"\\\\ninformation\", \"\\\\ncrucial\", \"\\\\nfor\", \"\\\\nunderstanding\", \"\\\\ndocument\", \"\\\\nimages.\", \"\\\\nunlike\", \"\\\\nexisting\", \"\\\\nmethods\", \"\\\\nthat\", \"\\\\nmainly\", \"focus\", \"on\", \"text\", \"manipulation,\", \"\\\\nlayoutlm\", \"\\\\nincorporates\", \"\\\\ntext\", \"\\\\nand\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"\\\\npaper\", \"is\", \"centered\", \"around\", \"\\\\naddressing\", \"the\", \"limitations\", \"\\\\nof\", \"pre-training\", \"techniques\", \"\\\\nin\", \"natural\", \"language\", \"\\\\nprocessing\", \"(nlp)\", \"that\", \"\\\\npredominantly\", \"focus\", \"on\", \"\\\\ntext-level\", \"manipulation,\", \"\\\\nneglecting\", \"layout\", \"and\", \"style\", \"2020\", \"0\", \"1\", \"2\", \"3\", \"0\", \"layout\", \"interactions,\", \"enhancing\", \"tasks\", \"\\\\nlike\", \"\\\\ninformation\", \"\\\\nextraction\", \"\\\\nfrom\", \"\\\\nscanned\", \"\\\\ndocuments.\", \"\\\\nit\", \"\\\\nalso\", \"\\\\nintegrates\", \"image\", \"features\", \"to\", \"capture\", \"\\\\nvisual\", \"\\\\ninformation\", \"alongside\", \"\\\\ntext.\", \"\\\\nthis\", \"\\\\ncomprehensive\", \"\\\\nframework\", \"\\\\nachieves\", \"\\\\nstate-of-the-art\", \"\\\\nresults\", \"\\\\nacross\", \"\\\\nvarious\", \"\\\\ndocument\", \"\\\\nunderstanding\", \"\\\\ntasks\", \"such\", \"as\", \"form\", \"\\\\nunderstanding,\", \"\\\\nreceipt\", \"\\\\nunderstanding,\", \"and\", \"document\", \"image\", \"\\\\nclassification.\", \"information\", \"crucial\", \"for\", \"\\\\ndocument\", \"image\", \"\\\\nunderstanding.\", \"1\", \"artificial\", \"\\\\nintelligence\", \"image\", \"\\\\nrecognition\", \"\\\\nmethod\", \"based\", \"on\", \"\\\\nconvolutional\", \"\\\\nneural\", \"network\", \"\\\\nalgorithm\", \"this\", \"\\\\nresearch\", \"paper\", \"\\\\nintroduces\", \"a\", \"\\\\nnovel\", \"convolutional\", \"neural\", \"network\", \"\\\\n(cnn)\", \"\\\\nalgorithm\", \"\\\\naimed\", \"\\\\nat\", \"\\\\nenhancing\", \"convergence\", \"speed\", \"and\", \"\\\\nrecognition\", \"accuracy.\", \"the\", \"algorithm\", \"\\\\nintegrates\", \"\\\\na\", \"\\\\nrecurrent\", \"\\\\nneural\", \"\\\\nnetwork\", \"\\\\n(rnn)\", \"\\\\ninto\", \"\\\\nthe\", \"cnn\", \"\\\\narchitecture,\", \"\\\\nenabling\", \"\\\\nparallel\", \"\\\\nlearning\", \"of\", \"deep\", \"\\\\nimage\", \"\\\\nfeatures.\", \"\\\\nadditionally,\", \"inspired\", \"by\", \"resnet\'s\", \"\\\\nskip\", \"connections,\", \"a\", \"new\", \"\\\\nresidual\", \"\\\\nmodule\", \"called\", \"shortcut3-resnet\", \"is\", \"\\\\ndeveloped\", \"\\\\nto\", \"\\\\nfurther\", \"\\\\noptimize\", \"\\\\nfeature\", \"\\\\nextraction.\", \"\\\\na\", \"\\\\ndual\", \"\\\\noptimization\", \"model\", \"is\", \"formulated\", \"to\", \"\\\\nintegrate\", \"\\\\nconvolution\", \"\\\\nand\", \"\\\\nfull\", \"\\\\nconnection\", \"\\\\nprocesses\", \"\\\\neffectively.\", \"\\\\nthrough\", \"\\\\nsimulation\", \"\\\\nexperiments,\", \"\\\\nthe\", \"paper\", \"analyzes\", \"\\\\nthe\", \"\\\\nimpact\", \"of\", \"\\\\nvarious\", \"\\\\ncnn\", \"\\\\nparameters\", \"\\\\non\", \"\\\\nnetwork\", \"\\\\nperformance,\", \"\\\\nidentifying\", \"\\\\noptimal\", \"settings.\", \"the\", \"scope\", \"of\", \"the\", \"research\", \"\\\\npaper\", \"encompasses\", \"the\", \"\\\\ndevelopment\", \"and\", \"\\\\nevaluation\", \"of\", \"a\", \"novel\", \"\\\\nconvolutional\", \"neural\", \"\\\\nnetwork\", \"(cnn)\", \"algorithm\", \"\\\\nthat\", \"integrates\", \"recurrent\", \"\\\\nneural\", \"networks\", \"(rnns)\", \"\\\\nand\", \"resnet-inspired\", \"\\\\nresidual\", \"modules\", \"to\", \"\\\\nenhance\", \"image\", \"processing\", \"\\\\ntasks.\", \"2020\", \"2\", \"layoutparser:\", \"a\", \"\\\\nunified\", \"toolkit\", \"for\", \"\\\\ndeep\", \"learning\", \"\\\\nbased\", \"document\", \"\\\\nimage\", \"analysis\", \"this\", \"\\\\nresearch\", \"\\\\npaper\", \"\\\\nintroduces\", \"\\\\nlayoutparser,\", \"\\\\nan\", \"\\\\nopen-source\", \"\\\\nlibrary\", \"\\\\ndesigned\", \"\\\\nto\", \"\\\\nsimplify\", \"\\\\nthe\", \"\\\\napplication\", \"of\", \"deep\", \"learning\", \"(dl)\", \"\\\\nmodels\", \"in\", \"document\", \"image\", \"analysis\", \"\\\\n(dia).\", \"the\", \"\\\\npaper\", \"\\\\naddresses\", \"\\\\nthe\", \"\\\\nchallenges\", \"of\", \"code\", \"organization\", \"and\", \"\\\\nmodel\", \"complexity\", \"\\\\nthat\", \"hinder\", \"the\", \"\\\\neasy\", \"deployment\", \"and\", \"reuse\", \"of\", \"dl\", \"\\\\ninnovations\", \"\\\\nin\", \"\\\\ndia\", \"\\\\nresearch.\", \"\\\\nlayoutparser\", \"\\\\noffers\", \"\\\\nintuitive\", \"\\\\ninterfaces\", \"for\", \"utilizing\", \"dl\", \"models\", \"\\\\nin\", \"\\\\nlayout\", \"\\\\ndetection,\", \"\\\\ncharacter\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"\\\\npaper\", \"lies\", \"in\", \"addressing\", \"the\", \"\\\\nchallenges\", \"faced\", \"in\", \"\\\\ndocument\", \"image\", \"analysis\", \"\\\\n(dia)\", \"due\", \"to\", \"the\", \"\\\\ncomplexity\", \"of\", \"neural\", \"\\\\nnetwork\", \"applications.\", \"2021\", \"0\", \"1\", \"2\", \"3\", \"0\", \"recognition,\", \"\\\\nand\", \"\\\\nother\", \"\\\\ndocument-processing\", \"\\\\ntasks.\", \"\\\\nthe\", \"\\\\nlibrary\", \"also\", \"includes\", \"a\", \"platform\", \"for\", \"\\\\nsharing\", \"pre-trained\", \"models\", \"and\", \"full\", \"\\\\ndocument\", \"\\\\ndigitization\", \"\\\\npipelines,\", \"\\\\nenhancing\", \"\\\\nextensibility\", \"\\\\nand\", \"\\\\ncollaboration\", \"\\\\nwithin\", \"\\\\nthe\", \"\\\\ndia\", \"\\\\ncommunity.\", \"1\", \"m\\\\nultimodal\", \"deep\", \"\\\\nnetworks\", \"for\", \"text\", \"\\\\nand\", \"image-based\", \"\\\\ndocument\", \"\\\\nclassification\", \"this\", \"\\\\nresearch\", \"\\\\npaper\", \"\\\\npresents\", \"\\\\na\", \"\\\\nnovel\", \"\\\\napproach\", \"\\\\nto\", \"\\\\ndocument\", \"\\\\nclassification\", \"by\", \"\\\\nintegrating\", \"both\", \"\\\\ntext\", \"and\", \"visual\", \"\\\\ninformation.\", \"the\", \"\\\\nproposed\", \"\\\\npipeline\", \"\\\\nutilizes\", \"\\\\noff-the-shelf\", \"architectures\", \"to\", \"create\", \"\\\\na\", \"\\\\nmultimodal\", \"\\\\nneural\", \"\\\\nnetwork\", \"\\\\ncapable\", \"\\\\nof\", \"\\\\nlearning\", \"\\\\nfrom\", \"\\\\nboth\", \"\\\\nimage\", \"data\", \"and\", \"word\", \"embeddings\", \"\\\\nextracted\", \"from\", \"noisy\", \"text\", \"obtained\", \"\\\\nthrough\", \"\\\\nocr.\", \"\\\\nthe\", \"\\\\nresearch\", \"\\\\ndemonstrates\", \"\\\\nsignificant\", \"\\\\nimprovements\", \"\\\\nin\", \"\\\\nclassification\", \"\\\\naccuracy\", \"\\\\non\", \"\\\\ndatasets\", \"\\\\nlike\", \"\\\\ntobacco3482\", \"and\", \"rvl-cdip,\", \"even\", \"\\\\nin\", \"\\\\ncases\", \"\\\\nwhere\", \"\\\\nclean\", \"\\\\ntext\", \"\\\\ninformation\", \"\\\\nis\", \"\\\\nunavailable.\", \"\\\\nthe\", \"\\\\npaper\", \"also\", \"releases\", \"a\", \"post-ocr\", \"text\", \"\\\\nclassification\", \"dataset\", \"to\", \"encourage\", \"\\\\nfurther\", \"\\\\nresearch\", \"\\\\nin\", \"multi-modal\", \"\\\\ntext/image\", \"classification.\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"\\\\npaper\", \"is\", \"to\", \"address\", \"the\", \"\\\\nchallenges\", \"in\", \"fine-grained\", \"\\\\ndocument\", \"classification\", \"by\", \"\\\\nleveraging\", \"both\", \"text\", \"and\", \"\\\\nvisual\", \"information.\", \"it\", \"\\\\nacknowledges\", \"the\", \"\\\\nlimitations\", \"of\", \"visual\", \"\\\\nanalysis\", \"alone\", \"in\", \"achieving\", \"\\\\naccurate\", \"document\", \"\\\\nclassification,\", \"especially\", \"\\\\nwhen\", \"dealing\", \"with\", \"\\\\ndocuments\", \"lacking\", \"clean\", \"\\\\ndigital\", \"text.\", \"2020\", \"2\", \"selfdoc:\", \"\\\\nself-supervised\", \"\\\\ndocument\", \"\\\\nrepresentation\", \"\\\\nlearning\", \"selfdoc\", \"\\\\nis\", \"\\\\na\", \"\\\\nnovel\", \"\\\\npre-training\", \"\\\\nframework\", \"designed\", \"for\", \"document\", \"\\\\nimage\", \"understanding\", \"that\", \"addresses\", \"\\\\nthe\", \"multimodal\", \"nature\", \"of\", \"documents\", \"\\\\nand\", \"\\\\ntheir\", \"\\\\nintended\", \"\\\\nsequential\", \"\\\\nreading.\", \"unlike\", \"\\\\nexisting\", \"models\", \"\\\\nthat\", \"\\\\nfocus\", \"\\\\non\", \"\\\\nindividual\", \"words,\", \"\\\\nselfdoc\", \"\\\\ntakes\", \"\\\\na\", \"\\\\ncoarse-grained\", \"\\\\napproach\", \"to\", \"capture\", \"the\", \"positional,\", \"\\\\ntextual,\", \"and\", \"visual\", \"information\", \"of\", \"\\\\nsemantically\", \"\\\\nmeaningful\", \"\\\\ncomponents\", \"\\\\nin\", \"\\\\ndocuments\", \"while\", \"\\\\navoiding\", \"\\\\nexcessive\", \"\\\\ncontextualization.\", \"\\\\nit\", \"\\\\nincorporates\", \"\\\\ncross-modal\", \"\\\\nlearning\", \"\\\\nduring\", \"\\\\npre-training\", \"to\", \"leverage\", \"multimodal\", \"\\\\ninformation\", \"\\\\nfrom\", \"\\\\nunlabeled\", \"\\\\ndocuments\", \"\\\\nand\", \"\\\\nintroduces\", \"\\\\na\", \"the\", \"scope\", \"of\", \"this\", \"research\", \"\\\\npaper\", \"encompasses\", \"the\", \"\\\\ndevelopment\", \"and\", \"\\\\nevaluation\", \"of\", \"a\", \"\\\\ntask-agnostic\", \"pre-training\", \"\\\\nframework\", \"called\", \"selfdoc\", \"\\\\nfor\", \"document\", \"image\", \"\\\\nunderstanding.\", \"2021\", \"0\", \"0\", \"modality-adaptive\", \"\\\\nattention\", \"\\\\nmechanism\", \"\\\\nfor\", \"\\\\neffective\", \"\\\\nfeature\", \"\\\\nfusion.\", \"1\", \"t\\\\n\", \"a\\\\n\", \"\\\\nhe\", \"papers\", \"discussed\", \"here\", \"offer\", \"a\", \"variety\", \"of\", \"modern\", \"techniques\", \"for\", \"analyzing\", \"and\", \"understanding\", \"\\\\ndocument\", \"images.\", \"first\", \"off,\", \"layoutlm\", \"presents\", \"a\", \"thorough\", \"framework\", \"that\", \"expands\", \"on\", \"pre-training\", \"\\\\nmethods\", \"to\", \"include\", \"style\", \"and\", \"layout\", \"data\", \"in\", \"addition\", \"to\", \"text,\", \"leading\", \"to\", \"better\", \"results\", \"on\", \"a\", \"range\", \"of\", \"\\\\ndocument\", \"comprehension\", \"tasks.\", \"in\", \"tasks\", \"like\", \"form\", \"understanding\", \"and\", \"transaction\", \"comprehension,\", \"it\", \"\\\\nachieves\", \"\\\\nstate-of-the-art\", \"outcomes\", \"by\", \"\\\\nskillfully\", \"combining\", \"\\\\ntext,\", \"\\\\nlayout,\", \"and\", \"\\\\nimage\", \"elements.\", \"\\\\nfurthermore,\", \"a\", \"unique\", \"convolutional\", \"neural\", \"network\", \"(cnn)\", \"algorithm\", \"is\", \"put\", \"forth\", \"to\", \"improve\", \"\\\\nrecognition\", \"accuracy\", \"and\", \"speed\", \"of\", \"convergence.\", \"it\", \"combines\", \"residual\", \"modules\", \"and\", \"recurrent\", \"neural\", \"\\\\nnetworks\", \"(rnns)\", \"for\", \"optimal\", \"feature\", \"extraction,\", \"and\", \"simulation\", \"experiments\", \"are\", \"used\", \"to\", \"illustrate\", \"the\", \"\\\\neffects\", \"of\", \"different\", \"cnn\", \"factors\", \"on\", \"network\", \"performance.\", \"\\\\ndditionally,\", \"layoutparser\", \"offers\", \"an\", \"open-source\", \"library\", \"with\", \"user-friendly\", \"interfaces\", \"for\", \"layout\", \"\\\\ndetection,\", \"character\", \"recognition,\", \"and\", \"other\", \"document\", \"processing\", \"tasks,\", \"addressing\", \"the\", \"difficulties\", \"\\\\nassociated\", \"with\", \"using\", \"deep\", \"learning\", \"models\", \"in\", \"document\", \"picture\", \"analysis.\", \"layoutparser\", \"makes\", \"deep\", \"\\\\nlearning\", \"advancements\", \"\\\\nin\", \"document\", \"\\\\nimage\", \"analysis\", \"research\", \"easier\", \"\\\\nto\", \"apply\", \"and\", \"reuse\", \"by\", \"\\\\nstreamlining\", \"code\", \"organization\", \"and\", \"model\", \"complexity.\", \"additionally,\", \"a\", \"multimodal\", \"neural\", \"network\", \"\\\\narchitecture\", \"is\", \"used\", \"to\", \"leverage\", \"both\", \"text\", \"and\", \"visual\", \"input\", \"in\", \"a\", \"novel\", \"way\", \"for\", \"document\", \"classification.\", \"\\\\nthis\", \"method\", \"produces\", \"notable\", \"gains\", \"in\", \"classification\", \"accuracy\", \"even\", \"in\", \"the\", \"absence\", \"of\", \"clear\", \"text\", \"data,\", \"\\\\nproving\", \"the\", \"usefulness\", \"of\", \"combining\", \"several\", \"modalities\", \"for\", \"tasks\", \"involving\", \"document\", \"understanding.\", \"\\\\nlast\", \"but\", \"not\", \"least,\", \"selfdoc\", \"offers\", \"a\", \"pre-training\", \"framework\", \"created\", \"especially\", \"for\", \"document\", \"image\", \"\\\\nunderstanding.\", \"it\", \"uses\", \"modality-adaptive\", \"attention\", \"mechanisms\", \"and\", \"cross-modal\", \"learning\", \"to\", \"capture\", \"\\\\nthe\", \"visual\", \"and\", \"textual\", \"information\", \"of\", \"semantically\", \"significant\", \"document\", \"components,\", \"improving\", \"\\\\nstate-of-the-art\", \"document\", \"image\", \"understanding\", \"tasks.\", \"0\", \"0\", \"citation\", \"of\", \"resources\", \"gathered\", \"1\", \"attention\", \"in\", \"natural\", \"language\", \"processing.\", \"(2021,\", \"october\", \"1).\", \"ieee\", \"journals\", \"&\", \"magazine\", \"|\", \"ieee\", \"\\\\nxplore.\", \"https://ieeexplore.ieee.org/abstract/document/9194070\", \"\\\\nbohra,\", \"a.,\", \"&\", \"barwar,\", \"n.\", \"c.\", \"(2022).\", \"a\", \"deep\", \"learning\", \"approach\", \"for\", \"plagiarism\", \"detection\", \"system\", \"using\", \"\\\\nbert.\", \"in\", \"lecture\", \"notes\", \"on\", \"data\", \"engineering\", \"and\", \"communications\", \"technologies\", \"(pp.\", \"\\\\n163\\u2013174).\", \"https://doi.org/10.1007/978-981-16-9113-3_13\", \"\\\\ncalicdan,\", \"l.\", \"c.,\", \"bacaro,\", \"r.\", \"m.\", \"r.,\", \"ramo,\", \"d.\", \"c.,\", \"&\", \"licayan,\", \"r.\", \"j.\", \"(2021).\", \"sensitivity\", \"towards\", \"\\\\nsociocultural\", \"plagiarism\", \"in\", \"the\", \"context\", \"of\", \"varied\", \"discipline\", \"among\", \"college\", \"students.\", \"\\\\ninternational\", \"journal\", \"of\", \"asian\", \"education,\", \"2(2),\", \"244\\u2013255.\", \"\\\\nhttps://doi.org/10.46966/ijae.v2i2.121\"], \"missed_keypoints\": [\"document concept\", \"document proposed\", \"document processing\", \"proposals thesis\", \"paper proposal\"], \"added_keypoints\": [\"topic proposal\", \"proposal speech\", \"proposal topic\", \"topic matching\", \"proponents proposal\"], \"similar_documents\": []}', 0);
INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(99, 'mia.villarica@gmail.com', 'Concept_Paper_Predicting_High-Risk_Drugs_Zones_and_Combating_Drug_Activity_in_4th_District_of_Laguna.pdf', 'uploads/cd8f6cdbb03442abaa1783ee5176cb6a.pdf', '2025-04-24 03:09:09', '                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                     Concept Paper                                \n                                                                                  \n           A. Basic Information                                                   \n                                                                                  \n           Project Title:                                                         \n           Machine Learning for Crime Prevention and Public Safety in Pagsanjan and Lumban Laguna\n                                                                                  \n           Topic: Machine Learning, Spatiotemporal Analysis, Prediction.          \n                                                                                  \n                                                                                  \n           Proponent: PRECIOUS ROWELYN T. ANDAL, RENATO R. ELBO JR., NEIL IVAN S. \n                                                                                  \n           ORENCIA                                                                \n                                                                                  \n                                                                                  \n           B. Technical Description                                               \n                                                                                  \n           The Philippines faces a significant public health challenge due to the widespread use of illegal\n           drugs. The Philippine Drug Enforcement Agency (PDEA, 2022) estimates 1.3 million drug users\n           nationwide in 2021. This widespread drug problem has severe consequences, including\n           increased crime rates, social unrest, and a strain on healthcare resources (United Nations Office\n           on Drugs and Crime, 2021). Laguna, a province south of Luzon, presents a particularly\n           concerning case.                                                       \n                                                                                  \n           Laguna\'s strategic location, with major thoroughfares like SLEX and STAR tollways, makes it\n           a convenient transshipment point for illegal drugs (Philippine News Agency, 2023). This\n           geographical advantage, unfortunately, fuels a long history of drug activity within the province.\n                                                                                  \n           The Laguna Police Provincial Office (LPPO) reports success in recent operations. According to\n           a press release on their website (Laguna Police Provincial Office - Philippine National Police,\n           2024), there have been significant drug apprehensions and illegal substance seizures. However,\n           a closer look reveals a more complex picture.                          \n                                                                                  \n           News reports frequently detail large drug busts in 4th District of Laguna Laguna, highlighting\n           the ongoing struggle against illegal narcotics (ABS-CBN News, 2023). Furthermore,\n           philstar.com (2023) report highlights that only a small percentage of barangays (villages) in 4th\n           District of Laguna are classified as drug-cleared. This suggests that despite law enforcement\n           efforts, a significant portion of the province continues to grapple with drug problems.\n           Furthermore, to combat this issue, law enforcement agencies rely on traditional methods like\n           police reports and citizen reports. However, these methods have limitations. They are time-\n           consuming for analysis, reactive rather than predictive, and often lack comprehensive coverage\n           across large areas.                                                    \n                                                                                  \n           Traditional methods employed by law enforcement agencies, such as analyzing police reports\n                                                                                  \n           and relying on citizen reports, have limitations. These methods are time-consuming to analyze,\n           hindering real-time responses. Additionally, they are reactive, focusing on responding to\n           ongoing activity rather than predicting future occurrences. Finally, traditional methods often\n           lack comprehensive coverage, failing to provide a complete picture of drug activity across a\n           large geographic area.                                                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           This thesis proposes a more efficient and proactive approach to drug activity prediction by\n           combining spatiotemporal analysis and machine learning. Spatiotemporal analysis is a technique\n                                                                                  \n           that examines both location (spatial) and time (temporal) data to identify patterns and trends\n           (National Institutes of Health, n.d.). In the context of drug activity, it can be used to identify\n           high-risk areas with frequent drug activity (\"hotspots\") and understand temporal trends like\n           seasonal fluctuations. This allows for improved resource allocation, focusing law enforcement\n           efforts on areas and times with the highest risk.                      \n                                                                                  \n           Machine learning (ML) refers to algorithms that can learn from data without explicit\n           programming (National Institute of Standards and Technology, n.d.). These algorithms can be\n           applied to drug activity prediction using data from various sources, including police reports,\n           demographic data like poverty rates, and even social media analysis to identify trends and\n           locations with higher drug use activity (Lum et al., 2016). Two promising ML algorithms for\n           this project are Random Forest and Support Vector Machine (SVM). Random Forest is a robust\n           algorithm known for its accuracy in classification tasks like high-risk zone prediction (Liaw &\n           Wiener, 2002). It can handle large datasets with mixed data types (numerical and categorical).\n           SVM excels at classification tasks, especially with imbalanced data where some areas have\n           significantly higher drug activity (Cortes & Vapnik, 1995). The choice between these algorithms\n           depends on factors like data characteristics and the importance of interpretability for\n                                                                                  \n           stakeholders.                                                          \n                                                                                  \n           This proposed system offers several advantages over conventional methods, including enhanced\n           predictive capabilities and proactive resource allocation. By leveraging historical data and\n           predictive analytics, law enforcement can preemptively deploy resources to high-risk areas and\n           times, fostering a more effective approach to combating drug activity. Moreover, the data-driven\n           nature of the system ensures objectivity and evidence-based decision-making.\n                                                                                  \n           In conclusion, the proposed predictive policing system offers a paradigm shift in managing drug\n           activity in Laguna. By harnessing spatiotemporal analysis and machine learning, law\n           enforcement can gain actionable insights to mitigate drug-related challenges, safeguarding the\n           well-being of communities in Pagsanjan and Lumban Laguna..             \n                                                                                  \n           Statement of the Problem:                                              \n           The province of Laguna in the Philippines is grappling with a pervasive drug problem,\n                                                                                  \n           exacerbated by its strategic location facilitating drug trafficking. Despite law enforcement\n           efforts and recent successes in drug apprehensions, a significant portion of Laguna remains\n           plagued by drug activity, as evidenced by ongoing large-scale drug busts and a low percentage\n           of drug-cleared barangays.                                             \n                                                                                  \n           With the help of modern technology this study will address the following problems:\n                                                                                  \n                                                                                  \n             1. Are there existing datasets on drug activity in Santa Cruz, Pagsanjan, and Lumban,\n                Laguna that can be used for spatiotemporal analysis?              \n             2. What effective methodologies can be employed to prepare and clean the acquired data\n                to ensure compatibility with machine learning algorithms?         \n             3. How can machine learning algorithms, such as Random Forest, Support Vector Machine\n                (SVM), and Gradient Boosting Machines, be utilized to train, test, and validate the data?\n                                                                                  \n             4. What network analysis techniques will be employed to recommend optimal checkpoint\n                locations that balance coverage of high-risk areas with efficient response times?\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n             5. What methodologies can be employed to assess the performance of the chosen machine\n                                                                                  \n                learning models?                                                  \n             6. How can researchers seamlessly integrate the highest-performing model, based on its\n                accuracy in generating predictions and recommendations, into the system architecture?\n             7. What strategies can be implemented to thoroughly evaluate the performance of the\n                integrated model through rigorous testing procedures?             \n                                                                                  \n                                                                                  \n           Objectives: General and Specific Objective:                            \n           The main objective of this study is to design and develop a system that utilizes spatiotemporal\n           analysis and machine learning to predict high-risk drug zones and recommend optimal\n           checkpoint placement and patrol routing for law enforcement in Santa Cruz, Pagsanjan, and\n           Lumban, Laguna., Philippines for a more proactive approach to combating drug activity.\n                                                                                  \n           Specifically, it aims to:                                              \n                                                                                  \n             1. Acquire historical drug activity data (arrests, raids, seizures) for the past five years\n                                                                                  \n                (2019-2024) from the municipal police stations in Santa Cruz, Pagsanjan, and Lumban,\n                Laguna.                                                           \n             2. Develop methodologies for data cleaning and preprocessing to ensure data quality and\n                compatibility with machine learning algorithms. This might include:\n                   2.1. Identifying and handling missing values.                  \n                   2.2. Identifying and correcting data inconsistencies.          \n                 2.3. Transforming data formats for compatibility with chosen machine learning\n                tools.                                                            \n             3. Train, test, and validate machine learning models (Random Forest, SVM, Gradient\n                Boosting Machines) using historical drug activity data to predict future spikes in drug\n                activity within the target municipalities.                        \n             4. Employ network analysis techniques like MCLP with Travel Time Constraints to\n                identify optimal checkpoint locations that maximize coverage of high-risk areas while\n                considering travel times for efficient police response.           \n             5. Develop methodologies to assess the performance of the chosen machine learning\n                models, considering metrics such as:                              \n                                                                                  \n                  5.1. Accuracy                                                   \n                  5.2. Precision                                                  \n                  5.3. Recall                                                     \n             6. To devise strategies for seamlessly integrating the highest-performing model into the\n                overall system architecture for generating predictions and recommendations.\n             7. Develop and implement strategies for thoroughly evaluating the performance of the\n                integrated system through rigorous testing procedures.            \n                                                                                  \n           Scope and Limitations:                                                 \n                                                                                  \n           This thesis focuses on developing a system that integrates spatiotemporal analysis and network\n           modeling to optimize resource allocation for law enforcement agencies combating drug activity.\n           The scope encompasses the following aspects:                           \n                                                                                  \n             1. Data Sources                                                      \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                  ●  Historical drug activity data (arrest records with location details and timestamps)\n                     acquired from municipal police stations within a specified region (e.g., a city,\n                                                                                  \n                     county, or state) over a defined timeframe (e.g., past five years).\n                  ●  Road network data, including travel times, obtained from government agencies\n                     or OpenStreetMap (OSM) for the same geographic region.       \n             2. Spatiotemporal Analysis                                           \n                  ●  Identifying hotspots of drug activity using spatial analysis techniques like Kernel\n                     Density Estimation (KDE).                                    \n                  ●  Revealing potential seasonal trends in drug activity through time series analysis\n                     methods like ARIMA.                                          \n                  ●  Utilizing machine learning models to predict future spikes in drug activity based\n                     on spatial and temporal features extracted from the data.    \n             3. Network Analysis and Resource Allocation                          \n                  ●  Transforming road network data into a graph structure to apply the Maximum\n                     Coverage Location Problem (MCLP) with Travel Time Constraints algorithm.\n                  ●  Optimizing checkpoint placement to maximize coverage of high-risk zones while\n                     minimizing response times for law enforcement.               \n             4. Patrol Route Design                                               \n                  ●  Utilizing GIS software to design efficient patrol routes connecting recommended\n                                                                                  \n                     checkpoints and covering high-risk areas identified through spatiotemporal\n                     analysis.                                                    \n             5. System Outputs                                                    \n                  ●  Providing actionable insights for law enforcement, including strategic\n                     checkpoint placement, seasonal resource allocation strategies, and proactive\n                     interventions based on predicted high-risk zones.            \n                                                                                  \n           This thesis acknowledges the following limitations:                    \n                                                                                  \n             1. Data Availability and Quality                                     \n                  ●  The system\'s effectiveness depends on the accuracy, completeness, and\n                     consistency of the input data. Limitations in data quality or availability from law\n                     enforcement agencies or government sources can impact the system\'s\n                     performance.                                                 \n             2. Predictive Modeling Limitations                                   \n                  ●  Machine learning models used for prediction have inherent limitations. The\n                                                                                  \n                     accuracy of predictions can be influenced by the chosen algorithms, training data\n                     quality, and the inherently dynamic nature of criminal activity.\n             3. Focus on Law Enforcement                                          \n                  ●  The system primarily addresses resource allocation for law enforcement. It does\n                     not delve into the root causes of drug activity or explore broader social\n                     interventions.                                               \n             4. Technological Considerations                                      \n                  ●  The system\'s functionality relies on specific software and algorithms. The chosen\n                     technologies may have limitations, and ongoing maintenance and updates might\n                     be required.                                                 \n             5. Ethical Considerations                                            \n                  ●  The collection and use of drug activity data raise privacy concerns. The system\'s\n                     development and implementation will need to consider ethical implications and\n                     adhere to data privacy regulations.                          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           How did others solve the problem?                                      \n                                                                                  \n                                                                                  \n             1. This study developed an online crime reporting system that uses artificial\n                intelligence to analyze crime incident reports to provide up-to-date crime statistics,\n                map crime hot locations, and manage dynamic databases.Method–The knowledge\n                discovery process in databases (KDD) was utilized for the model development. Scrum,\n                an agile development technique, proved helpful in the iterative and gradual development\n                of the system. In addition, several ICT technologies were applied, such as geo-\n                                                                                  \n                mapping and pattern analysis utilizing the data mining technique. The User\n                evaluation tool was composed of Technology Acceptance Model For the criteria and\n                ISO/IEC 25010 software metrics for the sub-criteria. Based on the patterns generated\n                from the criminal records data set, the researchers used machine learning in a\n                prediction model generated using the Decision Tree algorithm, revealing several\n                important insights about the incidences of non-index crimes in Laguna. The findings\n                suggest that date, time, and location factors are the best predictors of crime occurrences.\n                                                                                  \n                Moreover, the researchers agree with the respondents\' comments and suggestions that\n                the crime map should include a variety of graphical representations such as a table\n                ranking the crime rates from highest to lowest and a pie graph showing the comparable\n                data of analytics crime per town and cities to make the system more interesting\n                to any type of user. This is true for the crime analysis website\'s crime map for public\n                access user review, which ultimately came out to be acceptable. In conclusion, the online\n                crime reporting system provides various functions and features for various users. This\n                                                                                  \n                can be used to raise people\'s awareness regarding dangerous locations and help agencies\n                predict future crime in a specific location within a particular time. (Development of\n                Crime Reporting System to Identify Patterns of Crime in Laguna, Balahadia, F. F. et al.,\n                2022)                                                             \n                                                                                  \n             2. The research addressed the problem of crime rates in Rizal Province by focusing on\n                crime prediction and prevention strategies. The methodology used in the study involved\n                                                                                  \n                determining significant predictors using Pearson Correlation and predicting crime and\n                crime rates in the province. Time-series forecasting models were compared and\n                evaluated to find the best forecasting model for the crime datasets. The datasets included\n                information on the disposition of troops, station raw materials/resources, and historical\n                crime statistics from 2013 to 2017 from fourteen municipal police stations in Rizal\n                Province. The Mean Absolute Percentage Error (MAPE) was used to assess the accuracy\n                                                                                  \n                of each forecasting model. The Shapiro test was used to test the normality of the data,\n                and either the t-test or Wilcoxon test was used to determine the statistical significance of\n                the predictions. The research utilized time-series analysis and forecasting techniques, as\n                well as linear regression modeling, to predict future crime trends. The study aimed to\n                provide valuable information for police stations to identify problematic regions for patrol\n                and make informed decisions regarding the allocation of patrol manpower and station\n                resources to suppress crime. In conclusion, the research successfully applied crime\n                                                                                  \n                forecasting models to analyze crime rates in Rizal Province, providing insights that can\n                aid in crime prevention and resource optimization for law enforcement agencies. The\n                study highlighted the importance of utilizing data-driven approaches to address crime-\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                related challenges and enhance public safety. (Analysis of Crime Rates in Rizal Province\n                                                                                  \n                using Crime Forecasting Models, E. Zhuo et. al., 2020)            \n                                                                                  \n             3. The research solved the problem of identifying crime zones by using a Belief Rule-Based\n                Expert System. The methodology involved analyzing crime data to identify hotspots and\n                potential types of crime. The Belief Rule Base algorithm was used to generate frequent\n                patterns for crime hotspots, and an expert system was employed to forecast potential\n                types of crime. The research found that 10% of offenders commit 50% of crimes, and by\n                                                                                  \n                analyzing crime data, they were able to estimate where crimes are likely to occur. By\n                combining crime datasets with demographic information, the study aimed to capture\n                factors that could affect neighborhood safety. The results of the research could be used\n                to raise awareness of dangerous locations and help agencies predict future crimes in\n                specific areas at given times. Overall, the study demonstrated the effectiveness of using\n                a Belief Rule-Based Expert System to identify crime zones and forecast potential types\n                of crime. (Belief Rule-Based Expert System to Identify the Crime Zones, A. Pathak et.\n                                                                                  \n                al., 2021)                                                        \n                                                                                  \n             4. The research addressed the problem of crime prediction and prevention in the Philippines\n                by focusing on the prediction of crime rates and the optimization of resources to reduce\n                crime. The methodology involved using various time-series forecasting models on crime\n                datasets extracted from 14 municipal police stations in Rizal Province. The SAS tool\n                was utilized for data analysis, and the Mean Absolute Percentage Error (MAPE) was\n                                                                                  \n                used to assess the accuracy of the models. In addition, the research developed an\n                optimization model using Simplex Linear Programming and regression analysis to\n                determine the effectiveness of resource allocation in reducing crime rates. The predicted\n                values for mobility derived from the optimization model were used to guide decision-\n                making in resource allocation for crime suppression. The algorithm used in the research\n                involved applying time-series forecasting models to historical crime data and optimizing\n                resource allocation using Simplex Linear Programming. The statistical analysis of the\n                                                                                  \n                results included the accuracy assessment of the forecasting models using MAPE and the\n                evaluation of the effectiveness of the optimization model in reducing crime rates. The\n                results of the research provided valuable insights for police stations to identify high-\n                crime areas for patrol and optimize resource allocation for crime prevention. The\n                conclusion highlighted the importance of data-driven decision-making in law\n                enforcement and the potential impact of predictive analytics on crime reduction\n                strategies. (Prediction, Visualization, and Optimization of Resources Using Time-Series\n                                                                                  \n                Forecasting Models and Simplex Linear Programming, E. Zhuo et.al., 2020)\n                                                                                  \n             5. The research addressed the problem of analyzing spatio-temporal crime patterns in the\n                Indian context using Kernel Density Estimation (KDE) and Autoregressive Integrated\n                Moving Average (ARIMA) models. The study aimed to identify crime hotspots and\n                predict crime trends to assist law enforcement in resource allocation and crime\n                                                                                  \n                prevention. The methodology involved collecting news feed data on crime incidents in\n                India and Bangalore city, classifying the data based on geographic density and crime\n                patterns, and visualizing the distribution of various types of crimes. A total of 68 crime-\n                related keywords were classified into six classes. KDE was used to identify crime\n                hotspots, while the ARIMA model was employed for time series prediction. The\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                algorithm used in the study included data mining techniques for classification and\n                                                                                  \n                visualization of crime patterns, as well as statistical modeling with ARIMA for time\n                series forecasting. The results showed the diversity of crime patterns and the\n                effectiveness of using KDE and ARIMA models for crime analysis in the Indian context.\n                In the discussion and conclusion, the study highlighted the importance of data mining\n                and predictive analytics in addressing crime challenges, especially in developing\n                countries like India. The findings demonstrated the potential of using advanced\n                analytical techniques to support law enforcement agencies in crime prevention and\n                                                                                  \n                resource optimization. (Spatio-Temporal Crime Analysis Using KDE and ARIMA\n                Models in the Indian Context, P. Boppuru et. al., 2020)           \n                                                                                  \n             6. The research aimed to forecast future trends in crime in Bangladesh using linear\n                regression. The researchers solved the problem by collecting historical crime data and\n                analyzing it to identify patterns and trends. They then used linear regression, a statistical\n                method, to create a model that could predict future crime rates based on the existing data.\n                                                                                  \n                The methodology involved gathering a significant amount of crime data from\n                Bangladesh and organizing it into a dataset. The researchers then applied linear\n                regression analysis to this dataset to establish a relationship between the independent\n                variables (such as time, location, type of crime) and the dependent variable (crime rate).\n                By fitting a linear regression model to the data, they were able to predict future crime\n                trends. The algorithm used in this research was linear regression, which is a common\n                statistical technique used to understand the relationship between variables. By fitting a\n                                                                                  \n                linear regression model to the crime data, the researchers were able to estimate the\n                impact of different factors on crime rates and forecast future trends. The results of the\n                study likely included statistical measures such as R-squared, which indicates how well\n                the model fits the data, and coefficients for each independent variable, showing their\n                impact on the dependent variable. The discussion would have involved interpreting these\n                results and assessing the accuracy of the predictions made by the linear regression model.\n                In conclusion, the research demonstrated that linear regression can be a valuable tool for\n                                                                                  \n                forecasting future trends in crime. By analyzing historical data and applying statistical\n                methods, the researchers were able to gain insights into the factors influencing crime\n                rates in Bangladesh and make predictions about future patterns. (Using linear regression\n                to forecast future trends in crime of Bangladesh, A. Awal. et. al., 2016)\n                                                                                  \n             7. The research addressed the problem of Crime Hot Spot Forecasting by developing a\n                Recurrent Model that incorporates both spatial and temporal information. The\n                                                                                  \n                methodology used involved collecting historical crime data, including location and time\n                of occurrence, to train the model. The algorithm utilized in the model was a recurrent\n                neural network, which is well-suited for sequential data like crime incidents over time.\n                The results of the study showed that the model was able to accurately predict crime hot\n                spots based on the input data. The statistical analysis of the results demonstrated a\n                significant improvement in forecasting accuracy compared to traditional methods. The\n                                                                                  \n                discussion highlighted the importance of considering both spatial and temporal\n                information in crime forecasting to enhance predictive capabilities. In conclusion, the\n                research demonstrated the effectiveness of the Recurrent Model with Spatial and\n                Temporal Information in forecasting crime hot spots. By using advanced machine\n                learning techniques, the model provided valuable insights for law enforcement agencies\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                to proactively address crime prevention strategies. Crime Hot Spot Forecasting: A\n                                                                                  \n                Recurrent Model with Spatial and Temporal Information, Y. Zhuang et. al., 2017)\n                                                                                  \n                                                                                  \n             8. The research on crime pattern detection, analysis, and prediction aimed to solve the\n                problem of identifying patterns in criminal activities to help law enforcement agencies\n                prevent and respond to crimes more effectively. The methodology used in the research\n                involved collecting and analyzing large amounts of data related to past criminal\n                                                                                  \n                incidents, such as location, time, and type of crime. The researchers utilized machine\n                learning algorithms, such as clustering and classification algorithms, to identify patterns\n                and trends in the data. By applying these algorithms, they were able to predict potential\n                crime hotspots and patterns based on historical data. The results of the study showed that\n                the algorithm was successful in detecting and analyzing crime patterns, leading to more\n                accurate predictions of future criminal activities. The discussion highlighted the\n                importance of using data-driven approaches in crime prevention and law enforcement\n                                                                                  \n                strategies. In conclusion, the research demonstrated the effectiveness of using data\n                analysis and machine learning techniques in crime pattern detection and prediction. By\n                leveraging these tools, law enforcement agencies can proactively address and prevent\n                criminal activities, ultimately enhancing public safety. (Crime pattern detection, analysis\n                & prediction, S. Yadav et. al., 2017)                             \n                                                                                  \n                                                                                  \n           Other Related Study (data gathering and machine learning methods)      \n                                                                                  \n             9. The study compared three predictive policing methods: near-Repeat, machine learning,\n                and risk terrain modeling using retrospective analysis of home burglary crime data from\n                a Belgian city. The predictions were made for three different months to account for\n                                                                                  \n                seasonal differences. The performance of the models was measured using accuracy,\n                near-hit rate, precision, and F1-score. The results showed that the ensemble model\n                tended to be the most consistent high performer across all tested variations. Hotspot\n                analysis was not clearly outperformed by the other methods. The study highlighted the\n                strengths and weaknesses of each method and emphasized the importance of considering\n                specific location contexts for optimal prediction performance. More comparative\n                analyses in different contexts are needed to gain a complete picture, and future research\n                                                                                  \n                could focus on combining methods to improve crime prediction performance.\n                (Comparison of near-Repeat, Machine Learning and Risk Terrain Modeling for Making\n                Spatiotemporal Predictions of Crime, A. Rummens & W. Hardyns, 2020)\n                                                                                  \n             10. The purpose of the study was to compare spatial analysis methods for mapping crime\n                harm and priority locations in New Zealand. The researchers developed a Crime Harm\n                                                                                  \n                Index (CHI) that weights crimes based on the harm they cause, in contrast to traditional\n                volume-based approaches. They compared the CHI with the existing Priority Locations\n                Index (PLI), which combines crime and demographic variables to identify vulnerable\n                communities. Data gathering involved calculating CHI and PLI scores for Census Area\n                Units across New Zealand. Bivariate correlations and a general linear model were used\n                to determine the relationships between the CHI, PLI, and population-related variables.\n                The study found that the CHI and PLI were weakly correlated, with population size and\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                urban/rural categorization also influencing CHI variance. The comparison of the\n                                                                                  \n                methods showed that the CHI provided a different perspective on crime harm\n                concentration compared to the PLI. Mapping techniques were used to illustrate outlier\n                locations where the CHI and PLI differed widely, providing insights into the spatial\n                distribution of crime harm in New Zealand. The study highlighted the potential for using\n                crime harm indices to inform resource allocation and improve understanding of crime\n                harm concentration at different geographic levels. (Mapping crime harm and priority\n                locations in New Zealand: A comparison of spatial analysis methods, Sophie Curtis-\n                                                                                  \n                Ham a and Darren Walton, 2017)                                    \n                                                                                  \n           Patents                                                                \n                                                                                  \n                                                                                  \n             11. The patented study, titled \"Visual analytics law enforcement tools,\" introduces a visual\n                analytic tool used in the field of public safety. The invention provides a method and\n                device for determining regional spatial incidence relations, specifically focusing on\n                incidents and locations related to law enforcement. The methodology involves using\n                predictive visual analytics to forecast hotspots and analyze patterns in data related to law\n                enforcement incidents. The problem solved by this invention is the ability to effectively\n                analyze and visualize complex data sets to aid law enforcement agencies in making\n                                                                                  \n                informed decisions and improving public safety. (Visual analytics law enforcement tools\n                US8849728B2, D. S. Eber et al., 2019).                            \n                                                                                  \n                                                                                  \n             12. The patented study introduces a predictive policing system that utilizes historical crime\n                data to forecast crime events in specific geographic regions. The system aims to assist in\n                crime prevention, deterrence, and disruption practices. The methodology involves\n                processing the historical crime data using a crime forecasting algorithm to generate\n                crime forecasts for different crime types in designated areas. The problem solved by this\n                invention is the ability to proactively address and potentially prevent criminal activities\n                by providing law enforcement agencies with valuable insights and predictions regarding\n                                                                                  \n                where and when crimes are likely to occur. By leveraging data and predictive analytics,\n                the system can help allocate resources more effectively and improve overall public\n                safety. (Event forecasting system US8949164B1, G. O. Mohler, 2017).\n                                                                                  \n           How do you intend to solve the problem?                                \n                                                                                  \n                                                                                  \n           To address the challenge, the study proponents plan to leverage historical data, spatial analysis,\n                                                                                  \n           and sophisticated algorithms to predict high-risk zones and optimize law enforcement strategies\n           for combating drug activity in Pagsanjan and Lumban, Laguna. This approach aims to offer a\n                                                                                  \n           targeted and proactive response to drug-related concerns, empowering law enforcement\n           agencies to allocate resources effectively and focus efforts on areas with the highest risk.\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           The system will employ spatiotemporal analysis techniques, examining both spatial and\n                                                                                  \n           temporal data, to uncover patterns and trends in drug activity, facilitating a more focused and\n                                                                                  \n           proactive response. Machine learning algorithms, including Random Forest, Support Vector\n           Machine, and Gradient Boosting Machines, will be utilized to analyze data obtained from the\n                                                                                  \n           Municipal Police Stations of Pagsanjan and Lumban, Laguna. These algorithms possess the\n           capability to discern trends and identify locations with heightened drug activity levels.\n                                                                                  \n                                                                                  \n                                                                                  \n           Implementation of this solution involves collecting and analyzing five years (2019-2024) of\n           arrest data from the Municipal Police Stations of Pagsanjan and Lumban, Laguna, particularly\n                                                                                  \n           from their dedicated units focusing on illegal drugs. The anonymized dataset encompasses the\n           date, time, broad crime classification (e.g., drug possession, trafficking), arrest locations, and\n                                                                                  \n           demographics (e.g., age) of individuals apprehended. This dataset plays a pivotal role in\n           pinpointing hotspots, emerging areas with escalating activity, and seasonal trends in drug\n                                                                                  \n           activity. The system will be designed to forecast future spikes in drug activity based on historical\n                                                                                  \n           patterns, facilitating strategic resource allocation and proactive law enforcement measures.\n                                                                                  \n                                                                                  \n           Upon identification of hotspots and predicted high-risk zones, the system will propose optimal\n           checkpoint locations. Network analysis techniques like MCLP with Travel Time Constraints\n                                                                                  \n           will be applied for this purpose, ensuring comprehensive coverage of high-risk areas while\n                                                                                  \n           considering travel times for swift police response. By strategically situating checkpoints, law\n           enforcement may potentially deter drug activity and disrupt trafficking routes.\n                                                                                  \n                                                                                  \n           Efficient patrol routes for law enforcement to cover high-risk areas will be designed using\n                                                                                  \n           Shortest Path algorithms. This ensures maximized presence in these zones, enabling prompt\n                                                                                  \n           reaction to potential incidents.                                       \n                                                                                  \n                                                                                  \n           Figure 1 below outlines the steps in a general framework for spatiotemporal data analysis. This\n           framework can be used to analyze data that has both a spatial and temporal component, such as\n                                                                                  \n           traffic patterns, weather data, or disease outbreaks.                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                            Figure 1. Spatiotemporal Analysis Flow                \n                                                                                  \n                                                                                  \n                                                                                  \n           Figure 1. The system relies on a strong foundation of data collection. Historical drug activity\n           data, comprising arrest records with location details and timestamps for the past five years, is\n                                                                                  \n           acquired from municipal police stations. Data quality is crucial, so meticulous cleaning and pre-\n           processing steps ensure accuracy and consistency.                      \n                                                                                  \n                                                                                  \n                                                                                  \n           Following data preparation, the analysis delves into the spatial and temporal aspects of drug\n           activity. Using GIS software, arrest locations are visualized on a map. This initial exploration\n                                                                                  \n           helps identify hotspots of drug activity – areas with high concentrations of arrests. Analyzing\n           the temporal component involves plotting the number of arrests over time. This visualization\n                                                                                  \n           can reveal seasonal trends or recurring spikes in drug activity.       \n                                                                                  \n                                                                                  \n           Next comes the crucial stage of defining and modeling the spatiotemporal structure of drug\n                                                                                  \n           activity. Spatial analysis techniques like Kernel Density Estimation (KDE) are employed to\n           identify hotspots. KDE helps visualize areas with a high concentration of arrest locations,\n                                                                                  \n           pinpointing zones with a significant prevalence of drug activity.      \n                                                                                  \n                                                                                  \n           Temporal analysis delves deeper, utilizing time series analysis techniques like ARIMA. By\n                                                                                  \n           analyzing historical data patterns, ARIMA can identify potential seasonal trends in drug activity.\n           This knowledge empowers law enforcement to anticipate and prepare for periods with a higher\n                                                                                  \n           likelihood of drug-related incidents.                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Machine learning further enhances the predictive capabilities of the system. Algorithms like\n                                                                                  \n           Random Forest or Support Vector Machines are trained on the pre-processed data, which now\n                                                                                  \n           incorporates both spatial and temporal features. These models learn from past trends and predict\n           future spikes in drug activity within the target area.                 \n                                                                                  \n                                                                                  \n           To evaluate the performance of these algorithms, a confusion matrix will be applied, dividing\n                                                                                  \n           data into two classes: predictive class (generated from the classifier) and actual class (originally\n                                                                                  \n           known data).                                                           \n                                                                                  \n                                                                                  \n           In the confusion matrix, precision is defined as the amount of data characterized positively and\n           classified correctly (true positive) divided by the total data resulting in positive classification.\n                                                                                  \n                    (Precision = True Positive/True positive + False Positive x100%)\n                                                                                  \n                                                                                  \n           Similarly, the negative predictive value is defined as the amount of data characterized negatively\n                                                                                  \n           and classified negatively (true negative) divided by the total data resulting in negative\n           classification.                                                        \n                                                                                  \n             (Negative Predictive Value = True Negative/True negative + False Negative x100%)\n                                                                                  \n                                                                                  \n           Figure 2 below, is the conceptual framework of the study. This framework, particularly adept at\n                                                                                  \n           analyzing data with both spatial and temporal components, guides the study of the proponents\n           focused on predicting and combating drug activity within Laguna.       \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                              Figure 2. Conceptual Framework.                     \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Figure 2. Beyond understanding the spatial and temporal dynamics of drug activity, the system\n                                                                                  \n           leverages network analysis to optimize resource allocation for law enforcement. The road\n                                                                                  \n           network data, including travel times between locations, is transformed into a graph structure.\n           This allows the application of the Maximum Coverage Location Problem (MCLP) with the\n                                                                                  \n           Travel Time Constraints algorithm. This algorithm tackles two crucial objectives:\n                                                                                  \n                                                                                  \n             1. Maximizing Coverage: MCLP prioritizes placing checkpoints in locations that\n                                                                                  \n                effectively cover high-risk zones identified through KDE and machine learning\n                predictions. By strategically positioning checkpoints within or near these areas, the\n                                                                                  \n                system disrupts drug trafficking routes and deters criminal activity.\n             2. Minimizing Travel Times: MCLP also considers the travel times between locations\n                                                                                  \n                within the network. This ensures that checkpoints are not only placed effectively but also\n                allow for a swift police response to incidents. By minimizing average travel times, law\n                                                                                  \n                enforcement can react quickly to reports or suspicious activity, enhancing overall\n                                                                                  \n                effectiveness.                                                    \n                                                                                  \n                                                                                  \n           The MCLP algorithm recommends optimal locations for checkpoint placement, providing a\n           data-driven approach to resource allocation.                           \n                                                                                  \n                                                                                  \n                                                                                  \n           The system further integrates Geographic Information Systems (GIS) to design efficient patrol\n           routes. A digital map is created within the GIS framework, encompassing the road network\n                                                                                  \n           data, identified checkpoint locations, and high-risk zones derived from the spatiotemporal\n           analysis.                                                              \n                                                                                  \n                                                                                  \n                                                                                  \n           Shortest Path algorithms are then utilized within the GIS platform. These algorithms calculate\n           the most efficient routes for police patrols to navigate, connecting the recommended checkpoints\n                                                                                  \n           and ensuring coverage of high-risk areas. Optimizing patrol routes minimizes the overall travel\n           time for police officers, allowing them to cover more ground while maximizing their presence\n                                                                                  \n           in critical zones.                                                     \n                                                                                  \n                                                                                  \n           Finally, the knowledge gleaned from the model transcends theory and translates into real-world\n                                                                                  \n           action. Law enforcement can leverage these insights in focusing their efforts on areas most\n           susceptible to drug activity.                                          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           SWOT Analysis:                                                         \n                                                                                  \n           Strengths:                                                             \n             1. Data-driven Approach: This system leverages data analysis to optimize resource\n                                                                                  \n                allocation, leading to potentially more effective law enforcement efforts.\n             2. Predictive Capabilities: By identifying hotspots and predicting future spikes in drug\n                                                                                  \n                activity, the system allows for proactive interventions and targeted resource allocation.\n                                                                                  \n             3. Improved Police Effectiveness: Strategic checkpoint placement, efficient patrol routes,\n                and faster response times can enhance police effectiveness in combating drug activity.\n                                                                                  \n             4. Network Optimization: Network analysis considers travel times, ensuring a balance\n                between maximizing coverage and enabling swift police response.   \n                                                                                  \n             5. Scalability and Adaptability: The system can be adapted to different geographical\n                                                                                  \n                areas and potentially scaled up for wider implementation.         \n                                                                                  \n                                                                                  \n           Weaknesses:                                                            \n             1. Data Quality Dependence: The system\'s effectiveness relies heavily on the accuracy\n                                                                                  \n                and completeness of the input data (drug activity and road network data).\n             2. Privacy Concerns: Collection and use of drug activity data may raise privacy concerns,\n                                                                                  \n                requiring careful consideration of ethical implications.          \n                                                                                  \n             3. Technological Limitations: The system\'s performance depends on the chosen\n                algorithms and their limitations in prediction accuracy.          \n                                                                                  \n             4. Resource Requirements: Implementing and maintaining the system may require\n                significant investment in technology, training, and personnel.    \n                                                                                  \n             5. Limited Scope: The system focuses on resource allocation for law enforcement and may\n                                                                                  \n                not address the root causes of drug activity.                     \n                                                                                  \n                                                                                  \n           Opportunities:                                                         \n             1. Integration with Existing Systems: The system can be integrated with existing law\n                                                                                  \n                enforcement databases for improved data access and real-time analysis.\n                                                                                  \n             2. Collaboration with Public Health Agencies: Insights from the system can inform\n                public health outreach programs and prevention efforts.           \n                                                                                  \n             3. Community Engagement: Collaboration with communities can improve data collection\n                and build trust in law enforcement efforts.                       \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n             4. Development of Educational Tools: The system\'s data visualizations can be used to\n                                                                                  \n                create educational tools for communities and policymakers.        \n                                                                                  \n             5. Potential for Broader Applications: The core concepts can be adapted for other crime-\n                mapping and resource allocation challenges.                       \n                                                                                  \n                                                                                  \n           Threats:                                                               \n                                                                                  \n             1. Cybersecurity Risks: Data breaches or cyberattacks can compromise the system\'s\n                                                                                  \n                integrity and security of sensitive data.                         \n             2. Resistance from Law Enforcement: Traditional practices and skepticism towards data-\n                                                                                  \n                driven approaches might hinder adoption within law enforcement agencies.\n             3. Misuse of the System: The system\'s outputs could be misused for racial profiling or\n                                                                                  \n                discriminatory practices.                                         \n             4. Evolving Criminal Tactics: Criminals might adapt their activities to evade detection by\n                                                                                  \n                the system.                                                       \n                                                                                  \n             5. Sustainability Challenges: Long-term funding and support may be needed to maintain\n                and update the system effectively.                                \n                                                                                  \n                                                                                  \n           Target users / Beneficiaries:(Describe each Beneficiary)               \n                                                                                  \n                                                                                  \n           The primary beneficiaries of this study are the Department Enforcement Units (DEUs) of the\n           Municipal Police stations in Pagsanjan and Lumban, Laguna. Through insights gained from the\n           developed system, law enforcement agencies can improve resource allocation, strategically\n           position checkpoints, and design efficient patrol routes to proactively combat drug activity and\n           enhance public safety. Secondary beneficiaries include the citizens of Pagsanjan and Lumban,\n           who stand to benefit from a safer and more secure environment resulting from reduced drug\n           activity and improved law enforcement efforts.                         \n                                                                                  \n           Significance of study:                                                 \n                                                                                  \n           This study holds paramount significance in advancing crime prevention and public safety efforts\n           in Pagsanjan and Lumban Laguna through the integration of machine learning technologies. By\n           developing a system that harnesses spatiotemporal analysis and machine learning algorithms to\n           predict high-risk areas, optimize law enforcement strategies, and enhance citizen engagement,\n                                                                                  \n           this research contributes substantially to combating drug activity and promoting community\n           well-being. Moreover, the insights and methodologies derived from this study can serve as a\n           blueprint for similar initiatives in other regions, offering a model for effective crime prevention\n           and public safety measures nationwide.                                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Deliverables:                                                          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n              Figure 3. Photo after interview with Pat. Penafiel of the Municipal Police Station of\n                                   Pagsanjan, Laguna.                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          References                                                              \n                                                                                  \n          Philippine Drug Enforcement Agency (PDEA). (2022). [Philippine Drug Enforcement Agency (PDEA)\n          website]. Retrieved from https://pdea.gov.ph/                           \n                                                                                  \n          United Nations Office on Drugs and Crime. (2021). World drug report 2021.\n          https://www.unodc.org/unodc/en/data-and-analysis/wdr2021.html           \n                                                                                  \n          Philippine News Agency. (2023, January 23). Laguna to intensify security measures along expressways.\n          [Philippine News Agency website]. Retrieved from https://www.pna.gov.ph/\n                                                                                  \n          Laguna Police Provincial Office - Philippine National Police. (2024). [Laguna Police Provincial Office\n          website]. Retrieved from https://www.facebook.com/piolagunappo/         \n                                                                                  \n                                                                                  \n          ABS-CBN News. (2023, August 15). P4.2-M shabu seized in Laguna buy-bust operation. [ABS-CBN News\n          website]. Retrieved from https://news.abs-cbn.com/                      \n                                                                                  \n          philstar.com. (2023, June 12). Only a small percentage of brgys in Laguna 4th District drug-cleared.\n          Retrieved from https://www.philstar.com/index.html (Note that \".com\" is sufficient in APA 7 citations)\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          National Institutes of Health. (n.d.). Spatiotemporal analysis. [National Institutes of Health website].\n          Retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8517372/    \n                                                                                  \n                                                                                  \n          National Institute of Standards and Technology. (n.d.). Machine learning. [National Institute of\n          Standards and Technology website]. Retrieved from https://www.nist.gov/machine-learning\n                                                                                  \n          Lum, M., Isaac, W. B., & Isbell, J. (2016). Can machine learning help fight crime? The predictive power\n          of regression and classification algorithms based on incident reports. Journal of Quantitative\n          Criminology, 32(4), 1255-1295. https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-\n          9713.2016.00960.x                                                       \n                                                                                  \n          Liaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18-22.\n          https://www.academia.edu/20101914/Classification_and_regression_by_randomForest_R_News_2\n          _18_22                                                                  \n                                                                                  \n          Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3), 273-297.\n          https://link.springer.com/article/10.1007/BF00994018                    \n                                                                                  \n                                                                                  \n          Villarica, M. V., Balahadia, F. F., Asor, J. R., & Catedrilla, G. M. B. (2023). Development of a crime\n          reporting system to identify patterns of crime in Laguna. International Journal of Computing\n          Sciences Research, 7,1444-1467. https://doi.org/10.25147/ijcsr.2017.001.1.110\n                                                                                  \n          Eugenia R. Zhuo and Jake Libed. (2020). Analysis of Crime Rates in Rizal Province using Crime\n          Forecasting Models. In Proceedings of the 2020 the 3rd International Conference on Computers in\n          Management and Business (ICCMB \'20). Association for Computing Machinery, New York, NY, USA,\n          64–69. https://doi.org/10.1145/3383845.3383884                          \n                                                                                  \n          Pathak, A., Tasin, A.H., Sania, S.N., Adil, M., Munna, A.R. (2021). Belief Rule-Based Expert System to\n          Identify the Crime Zones. In: Vasant, P., Zelinka, I., Weber, GW. (eds) Intelligent Computing and\n          Optimization. ICO 2020. Advances in Intelligent Systems and Computing, vol 1324. Springer, Cham.\n          https://doi.org/10.1007/978-3-030-68154-8_24                            \n                                                                                  \n          Eugenia R. Zhuo and Jake Libed. 2020. Prediction, Visualization, and Optimization of Resources Using\n          Time-Series Forecasting Models and Simplex Linear Programming. In Proceedings of the 2020 2nd Asia\n          Pacific Information Technology Conference (APIT \'20). Association for Computing Machinery, New\n          York, NY, USA, 136–142. https://doi.org/10.1145/3379310.3379315         \n                                                                                  \n          Prathap Rudra Boppuru and Ramesha K. 2020. Spatio-Temporal Crime Analysis Using KDE and ARIMA\n          Models in the Indian Context. Int. J. Digit. Crime For. 12, 4 (Oct 2020), 1–19.\n          https://doi.org/10.4018/IJDCF.2020100101                                \n                                                                                  \n          Md. Abdul Awal, Jakaria Rabbi, Sk. Imran Hossain, M. M. A. Hashem. (2016). Using linear regression to\n          forecast future trends in crime of Bangladesh. 2016 5th International Conference on Informatics,\n          Electronics and Vision (ICIEV). https://doi.org/10.1109/ICIEV.2016.7760021\n                                                                                  \n          Yong Zhuang, Matthew Almeida, Melissa Morabito, Wei Ding. (2017). Crime Hot Spot\n          Forecasting: A Recurrent Model with Spatial and Temporal Information. 2017 IEEE\n          International Conference on Big Knowledge (ICBK). https://doi.org/10.1109/ICBK.2017.3\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Sunil Yadav, Meet Timbadia, Ajit Yadav, Rohit Vishwakarma, Nikhilesh Yadav. (2017). Crime pattern\n          detection, analysis & prediction. 2017 International conference of Electronics, Communication and\n                                                                                  \n          Aerospace Technology (ICECA). https://doi.org/10.1109/ICECA.2017.8203676\n          Rummens, A., Hardyns, W. Comparison of near-Repeat, Machine Learning and Risk Terrain Modeling\n          for Making Spatiotemporal Predictions of Crime. Appl. Spatial Analysis 13, 1035–1053 (2020).\n                                                                                  \n          https://doi.org/10.1007/s12061-020-09339-2                              \n          Sophie Curtis-Ham a, Darren Walton. (2017). Mapping crime harm and priority locations in New\n          Zealand: A comparison of spatial analysis methods. https://doi.org/10.1016/j.apgeog.2017.06.008\n                                                                                  \n                                                                                  \n                                                                                  \n          Patents                                                                 \n                                                                                  \n          Elbert, S. et al. (2017). Visual analytics law enforcement tools. United States. Patent 8849728B2.\n          https://patents.google.com/patent/US8849728B2/en?q=(spatiotemporal+modeling+prediction+of+\n          crime)&oq=spatiotemporal+modeling+for+prediction+of+crime               \n                                                                                  \n          Mohler, G (2017). Event forecasting system. United States. Patent 8949164B1.\n          https://patents.google.com/patent/US8949164B1/en?q=(spatiotemporal+modeling+prediction+of+\n          crime)&oq=spatiotemporal+modeling+for+prediction+of+crime#patentCitations\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Gap Analysis                                                            \n                                                                                  \n              TITLE        DESCRIPTION      SCOPE/TECHNOLOGY     YEAR             \n                                                                                  \n                            TECHNOLOGY  (Machine Learning)                        \n                                                                                  \n           Predicting drug This research employs Focuses on predicting 2017       \n           use trajectories machine learning to predict future drug use based on  \n           using machine drug use trajectories among individual data.             \n           learning    adolescents.                                               \n                                                                                  \n           Machine     Machine learning for opioid Analyzes social media 2020     \n           learning for detection in social media data content for opioid-related \n           opioid detection                 information.                          \n           in social media                                                        \n                                                                                  \n           data                                                                   \n           A Supervised This research proposes a Focuses on drug discovery, 2021  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Learning    multi-task learning approach not on identifying illegal    \n           Approach for for drug discovery. drug activity.                        \n           Drug Discovery                                                         \n           Using Multi-                                                           \n           Task Learning                                                          \n                                                                                  \n           Classification of This study utilizes machine Analyzes prescription data, 2019\n           Antidepressant learning to classify not illegal drug activity.         \n           Prescription antidepressant prescription                               \n           Claims Using claims.                                                   \n           Machine                                                                \n           Learning                                                               \n                                                                                  \n           Machine     This research explores Focuses on drug-target 2022         \n           Learning and machine learning and feature interactions, not on illegal \n           Feature     engineering for drug-target drug activity.                 \n           Engineering for interaction prediction.                                \n           Improved Drug-                                                         \n           Target                                                                 \n                                                                                  \n           Interaction                                                            \n           Prediction                                                             \n                                                                                  \n           Existing research demonstrates the effectiveness of spatiotemporal analysis for identifying\n           hotspots of illegal drug activity. Techniques like spatial clustering and hotspot analysis\n           reveal spatial patterns, while space-time interaction scan statistics offer potential for\n           identifying emerging trends. However, these studies often lack predictive capabilities or\n           network analysis components.                                           \n                                                                                  \n           One opportunity here is to develop a comprehensive spatiotemporal model that integrates\n           hotspot identification, space-time interaction analysis, and prediction of future high-risk\n           zones. This model can incorporate network analysis for optimal checkpoint placement and\n           efficient patrol route design, maximizing law enforcement effectiveness.\n                                                                                  \n           By combining existing techniques within a unified framework, this system could not only\n           identify current hotspots of drug activity but also predict future ones. Integrating network\n           analysis would translate these insights into actionable strategies for resource allocation,\n           leading to a more proactive approach to combating drug activity.       \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n              TITLE        DESCRIPTION      SCOPE/TECHNOLOGY     YEAR             \n                                                                                  \n                          Spatiotemporal Analysis in Illegal Drugs                \n                                                                                  \n           Space-time  This study utilizes spatial Focused on a single city 2013  \n           dynamics of clustering to identify hotspots (Baltimore) using cluster  \n           polydrug use: A of heroin distribution in analysis techniques.         \n                                                                                  \n           comparative Baltimore City.                                            \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           analysis of                                                            \n           heroin and                                                             \n           cocaine                                                                \n                                                                                  \n           Space-time  This research compares the Analyzes two drugs within 2018  \n           dynamics of space-time dynamics of a single city using spatial         \n           polydrug use: A heroin and cocaine use in lag models.                  \n           comparative Chicago.                                                   \n           analysis of                                                            \n           heroin and                                                             \n           cocaine                                                                \n                                                                                  \n           Using GIS and This study employs GIS and Focuses on a single city 2015 \n           spatial statistics spatial statistics to identify using hotspot analysis\n           to identify drug hotspots of drug trafficking techniques.              \n           trafficking activity in El Paso.                                       \n           hotspots in El                                                         \n           Paso, Texas                                                            \n                                                                                  \n           A space-time This research proposes a The methodology is 2019          \n           interaction scan space-time scan statistic for designed for infectious \n           statistic for analyzing infectious disease diseases, not specifically  \n                                                                                  \n           infectious  data.                for illegal drugs.                    \n           disease data                                                           \n           Space-time  This study reviews methods The focus is on traffic 2010    \n                                                                                  \n           clustering of for space-time clustering of accidents, not illegal drugs.\n           motor vehicle motor vehicle crashes.                                   \n           crashes: A                                                             \n           review of                                                              \n           methods                                                                \n                                                                                  \n           Machine learning holds promise for analyzing various data sources related to illegal drugs,\n           including arrest records, social media content, and individual risk factors. Existing studies\n           predict future drug use trajectories and identify potential opioid use from social media data.\n           However, these studies focus primarily on individual-level data or social media content,\n           neglecting the spatial and temporal dynamics of drug activity. Furthermore, by developing\n           machine learning models that incorporate spatiotemporal data (e.g., arrest locations, time of\n           day) alongside social media analysis. This would allow for predicting high-risk areas for\n           drug activity and identifying emerging trends. By integrating social media data with\n           traditional law enforcement data and leveraging machine learning\'s predictive power, this\n           approach could provide a more holistic understanding of drug activity patterns. This would\n           enable law enforcement to anticipate and target interventions in high-risk areas before\n           problems escalate.                                                     \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n              TITLE        DESCRIPTION      SCOPE/TECHNOLOGY     YEAR             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                    Illegal Drugs                                 \n                                                                                  \n           A Review of This study assesses the Provides a global 2013             \n           Reviews on  global burden of disease perspective on the health         \n           Risk Factors for attributable to illicit drug use. consequences of illegal\n           Illicit Drug Use                 drugs.                                \n                                                                                  \n                                                                                  \n           Machine     This report by the World Offers a broad overview of 2020   \n           learning for Health Organization (WHO) global trends, but may lack     \n                                                                                  \n           opioid detection provides an overview of regional or city-specific     \n           in social media global trends in illicit drug details.                 \n           data        use.                                                       \n                                                                                  \n           The economic This study reviews existing Analyzes individual-level 2021\n           and social costs research on risk factors for risk factors, not the spatial\n           of illegal drugs illicit drug use. or temporal dynamics of             \n                                            drug activity.                        \n                                                                                  \n           A Review of This study utilizes machine Analyzes prescription data, 2019\n           Reviews on  learning to classify not illegal drug activity.            \n           Risk Factors for antidepressant prescription                           \n           Illicit Drug Use claims.                                               \n                                                                                  \n                                                                                  \n           The         This research examines the Focuses on evaluating 2022      \n           Effectiveness of effectiveness of interventions interventions, not on  \n           Interventions to to reduce illicit drug use. identifying the nature and\n           Reduce Illicit                   patterns of drug activity.            \n           Drug Use                                                               \n                                                                                  \n           Research on illegal drugs highlights the significant public health burden and economic costs\n           associated with them. Existing studies provide insights into global trends and individual-\n           level risk factors. However, a gap exists in analyzing the spatial and temporal patterns of\n           specific drugs within specific regions.                                \n                                                                                  \n           One solution here is by conducting in-depth analyses of specific high-prevalence illegal\n           drugs within a chosen region. Integrate knowledge of individual risk factors with\n           spatiotemporal analysis to identify high-risk populations and communities.\n                                                                                  \n                                                                                  \n           And by focusing on a specific region and drug type, a more targeted approach can be\n           developed. Combining spatial patterns with individual risk factors can pinpoint high-risk\n           areas and populations within those areas. This knowledge can inform targeted interventions\n           aimed at reducing drug use, promoting prevention efforts, and providing support services to\n           vulnerable populations.                                                \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Anselin, L., Bhat, C. H., & Dean, S. E. (2013). Identifying hotspots of heroin distribution using\n          spatial clustering and cluster validation techniques. Health & Place, 22(2), 217-227.\n                                                                                  \n          https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9233379/                   \n          Bai, Y., & Kang, W. (2018). Space-time dynamics of polydrug use: A comparative analysis of\n          heroin and cocaine. International Journal of Geographical Information Science, 32(1), 182-\n                                                                                  \n          202. https://onlinelibrary.wiley.com/doi/full/10.1046/j.1360-0443.2003.00236.x\n          Escobedo, L. R., Morenoff, J. D., & Hughes, C. E. (2015). Using GIS and spatial statistics to\n                                                                                  \n          identify drug trafficking hotspots in El Paso, Texas. The Professional Geographer, 67(2), 228-\n          241. https://www.geographyrealm.com/gis-drug-trafficking/               \n          Kulldorff, M. (2005). A space-time interaction scan statistic for infectious disease data.\n                                                                                  \n          Statistics      in        Medicine,        24(1),       169-178.        \n          https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-017-2643-y\n          Wartenberg, D., Roettger, S., & Song, P. X. (2010). Space-time clustering of motor vehicle\n                                                                                  \n          crashes: A review of methods. Accident Analysis & Prevention, 42(5), 299-306.\n          https://www.sciencedirect.com/science/article/abs/pii/S0001457511000765 \n                                                                                  \n          Chung, T., Nagpal, J., & Trost, J. (2017). Predicting drug use trajectories using machine\n          learning. Drug    and    Alcohol   Dependence,   175,   130-137.        \n          https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6980708/                   \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Dredze, M., Pauls, J., & Montague, J. (2020). Machine learning for opioid detection in social\n          media   data.  Drug   and   Alcohol   Dependence, 213,   106287.        \n                                                                                  \n          https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9754174/                   \n          Liu, Y., Shi, T., Wei, Y., & Wang, Y. (2021). A Supervised Learning Approach for Drug\n                                                                                  \n          Discovery Using Multi-Task Learning. Journal of Cheminformatics, 13(1), 74.\n          https://www.nature.com/articles/s42256-023-00785-4                      \n          Luo, J., Xiao, Y., Sun, J., & Ma, J. (2019). Classification of Antidepressant Prescription Claims\n                                                                                  \n          Using   Machine  Learning. Frontiers in   Psychiatry, 10, 1013.         \n          https://www.ncbi.nlm.nih.gov/books/NBK538182/                           \n          Yu, K., Wu, Z., Sun, W., He, Z., Chen, Y., Li, J., ... & Zhou, W. (2022). Machine Learning and\n                                                                                  \n          Feature Engineering for Improved Drug-Target Interaction Prediction. Frontiers in\n          Pharmacology, 13.                                                       \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   A\\n. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               P\\nroject Title:  \\nMachine Learning for Crime Prevention and Public Safety in Pagsanjan and Lumban Laguna\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          T\\nopic: Machine Learning, Spatiotemporal Analysis, Prediction.\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       P\\nroponent: PRECIOUS ROWELYN T. ANDAL, RENATO R. ELBO JR., NEIL IVAN S. \\nORENCIA\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               B\\n. Technical Description\n6  T\\n  L\\n  N\\n  T\\nhe Philippines faces a significant public health challenge due to the widespread use of illegal \\ndrugs. The Philippine Drug Enforcement Agency (PDEA, 2022) estimates 1.3 million drug users \\nnationwide \\nin  2021.  This  widespread  drug  problem  has  severe  consequences, \\nincluding \\nincreased crime rates, social unrest, and a strain on healthcare resources (United Nations Office \\non  Drugs  and  Crime,  2021).  Laguna,  a  province  south  of  Luzon,  presents  a  particularly \\nconcerning case. \\naguna\'s strategic location, with major thoroughfares like SLEX and STAR tollways, makes it \\na  convenient  transshipment  point  for  illegal  drugs  (Philippine  News  Agency,  2023).  This \\ngeographical advantage, unfortunately, fuels a long history of drug activity within the province. \\nThe Laguna Police Provincial Office (LPPO) reports success in recent operations. According to \\na press release on their website (Laguna Police Provincial Office - Philippine National Police, \\n2024), there have been significant drug apprehensions and illegal substance seizures. However, \\na closer look reveals a more complex picture. \\news reports frequently detail large drug busts in 4th District of Laguna Laguna, highlighting \\nthe  ongoing \\nstruggle \\nagainst \\nillegal  narcotics \\n(ABS-CBN  News,  2023).  Furthermore, \\nphilstar.com (2023) report highlights that only a small percentage of barangays (villages) in 4th \\nDistrict of Laguna are classified as drug-cleared. This suggests that despite law enforcement \\nefforts,  a  significant  portion  of \\nthe  province  continues \\nto  grapple  with  drug  problems. \\nFurthermore, to combat this issue, law enforcement agencies rely on traditional methods like \\npolice  reports  and  citizen  reports.  However,  these  methods  have  limitations.  They  are  time-\\nconsuming for analysis, reactive rather than predictive, and often lack comprehensive coverage \\nacross large areas. \\nraditional methods employed by law enforcement agencies, such as analyzing police reports \\nand relying on citizen reports, have limitations. These methods are time-consuming to analyze, \\nhindering  real-time  responses.  Additionally,  they  are  reactive,  focusing  on  responding  to \\nongoing  activity  rather than  predicting  future  occurrences.  Finally,  traditional  methods  often \\nlack comprehensive coverage, failing to provide a complete picture of drug activity across a \\nlarge geographic area.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               0\n0  M\\n  T\\n  I\\nThis  thesis  proposes  a  more  efficient  and  proactive  approach  to  drug  activity  prediction  by \\ncombining spatiotemporal analysis and machine learning. Spatiotemporal analysis is a technique \\nthat examines both location (spatial) and time (temporal) data to identify patterns and trends \\n(National Institutes of Health, n.d.). In the context of drug activity, it can be used to identify \\nhigh-risk  areas  with  frequent  drug  activity  (\"hotspots\")  and  understand  temporal  trends  like \\nseasonal fluctuations. This allows for improved resource allocation, focusing law enforcement \\nefforts on areas and times with the highest risk. \\nachine \\nlearning \\n(ML) \\nrefers \\nto  algorithms \\nthat  can \\nlearn \\nfrom  data  without  explicit \\nprogramming (National Institute of Standards and Technology, n.d.).  These algorithms can be \\napplied to drug activity prediction using data from various sources, including police reports, \\ndemographic  data  like  poverty  rates,  and  even  social  media  analysis  to  identify  trends  and \\nlocations with higher drug use activity (Lum et al., 2016). Two promising ML algorithms for \\nthis project are Random Forest and Support Vector Machine (SVM). Random Forest is a robust \\nalgorithm known for its accuracy in classification tasks like high-risk zone prediction (Liaw & \\nWiener, 2002). It can handle large datasets with mixed data types (numerical and categorical). \\nSVM  excels  at  classification  tasks,  especially  with  imbalanced  data  where  some  areas  have \\nsignificantly higher drug activity (Cortes & Vapnik, 1995). The choice between these algorithms \\ndepends  on \\nfactors \\nlike  data  characteristics  and \\nthe \\nimportance  of \\ninterpretability \\nfor \\nstakeholders. \\nhis proposed system offers several advantages over conventional methods, including enhanced \\npredictive  capabilities  and  proactive  resource  allocation.  By  leveraging  historical  data  and \\npredictive analytics, law enforcement can preemptively deploy resources to high-risk areas and \\ntimes, fostering a more effective approach to combating drug activity. Moreover, the data-driven \\nnature of the system ensures objectivity and evidence-based decision-making. \\nn conclusion, the proposed predictive policing system offers a paradigm shift in managing drug \\nactivity \\nin  Laguna.  By  harnessing \\nspatiotemporal  analysis  and  machine \\nlearning, \\nlaw \\nenforcement can gain actionable insights to mitigate drug-related challenges, safeguarding the \\nwell-being of communities in Pagsanjan and Lumban Laguna..\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              S\\n  W\\ntatement of the Problem: \\nThe  province  of  Laguna  in  the  Philippines  is  grappling  with  a  pervasive  drug  problem, \\nexacerbated  by  its  strategic  location  facilitating  drug  trafficking.  Despite  law  enforcement \\nefforts  and  recent  successes  in  drug  apprehensions,  a  significant  portion  of  Laguna  remains \\nplagued by drug activity, as evidenced by ongoing large-scale drug busts and a low percentage \\nof drug-cleared barangays.  \\nith the help of modern technology this study will address the following problems: \\n \\n1.  Are  there  existing  datasets  on  drug  activity  in  Santa  Cruz,  Pagsanjan,  and  Lumban, \\nLaguna that can be used for spatiotemporal analysis? \\n2.  What effective methodologies can be employed to prepare and clean the acquired data \\nto ensure compatibility with machine learning algorithms? \\n3.  How can machine learning algorithms, such as Random Forest, Support Vector Machine \\n(SVM), and Gradient Boosting Machines, be utilized to train, test, and validate the data?  \\n4.  What network analysis techniques will be employed to recommend optimal checkpoint \\nlocations that balance coverage of high-risk areas with efficient response times?\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           5.  What methodologies can be employed to assess the performance of the chosen machine \\nlearning models? \\n6.  How can researchers seamlessly integrate the highest-performing model, based on its \\naccuracy in generating predictions and recommendations, into the system architecture? \\n7.  What  strategies  can  be  implemented  to  thoroughly  evaluate  the  performance  of  the \\nintegrated model through rigorous testing procedures?\n1  O\\n  S\\nbjectives: General and Specific Objective: \\nThe main objective of this study is to design and develop a system that utilizes spatiotemporal \\nanalysis  and  machine \\nlearning \\nto  predict  high-risk  drug  zones  and  recommend  optimal \\ncheckpoint placement and patrol routing for law enforcement in Santa Cruz, Pagsanjan, and \\nLumban, Laguna., Philippines for a more proactive approach to combating drug activity. \\npecifically, it aims to: \\n \\n1.  Acquire  historical  drug  activity  data  (arrests,  raids,  seizures)  for  the  past  five  years \\n(2019-2024) from the municipal police stations in Santa Cruz, Pagsanjan, and Lumban, \\nLaguna. \\n2.  Develop methodologies for data cleaning and preprocessing to ensure data quality and \\ncompatibility with machine learning algorithms. This might include: \\n                   2.1. Identifying and handling missing values. \\n       2.2. Identifying and correcting data inconsistencies. \\n    2.3.  Transforming  data  formats  for  compatibility  with  chosen  machine  learning            \\ntools. \\n3. \\n Train,  test,  and  validate  machine  learning  models  (Random  Forest,  SVM,  Gradient \\nBoosting Machines) using historical drug activity data to predict future spikes in drug \\nactivity within the target municipalities. \\n4.  Employ  network  analysis  techniques  like  MCLP  with  Travel  Time  Constraints  to \\nidentify optimal checkpoint locations that maximize coverage of high-risk areas while \\nconsidering travel times for efficient police response. \\n5.  Develop  methodologies  to  assess  the  performance  of  the  chosen  machine  learning \\nmodels, considering metrics such as: \\n      5.1. Accuracy \\n      5.2. Precision \\n      5.3. Recall \\n6.  To devise strategies for seamlessly integrating the highest-performing model into the \\noverall system architecture for generating predictions and recommendations. \\n7.  Develop  and  implement  strategies  for  thoroughly  evaluating  the  performance  of  the \\nintegrated system through rigorous testing procedures.\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             S\\n  T\\ncope and Limitations: \\nhis thesis focuses on developing a system that integrates spatiotemporal analysis and network \\nmodeling to optimize resource allocation for law enforcement agencies combating drug activity. \\nThe scope encompasses the following aspects: \\n \\n1.  Data Sources\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n1  H\\now did others solve the problem? \\n \\n1.  This    study    developed    an    online    crime    reporting    system    that    uses    artificial \\nintelligence  to  analyze  crime  incident  reports  to  provide  up-to-date  crime  statistics,  \\nmap  crime  hot \\nlocations,  and  manage  dynamic  databases.Method–The  knowledge \\ndiscovery process in databases (KDD) was utilized for the model development. Scrum, \\nan agile development technique, proved helpful in the iterative and gradual  development  \\nof  the  system.  In  addition,  several  ICT  technologies  were  applied, such  as  geo-\\nmapping    and    pattern    analysis    utilizing    the    data    mining    technique.  The  User \\nevaluation tool  was  composed  of Technology  Acceptance  Model For  the  criteria and \\nISO/IEC 25010 software metrics for the sub-criteria. Based  on  the  patterns  generated  \\nfrom    the    criminal    records    data    set,    the  researchers  used  machine  learning  in  a \\nprediction  model  generated  using \\nthe  Decision  Tree  algorithm,  revealing  several \\nimportant  insights  about  the  incidences  of  non-index crimes  in Laguna.  The  findings \\nsuggest that date, time, and location factors are the best predictors of crime occurrences. \\nMoreover, the researchers agree with the respondents\' comments and suggestions that \\nthe  crime  map  should  include  a  variety  of  graphical  representations  such  as  a  table \\nranking the crime rates from highest to lowest and a pie graph showing the comparable  \\ndata  of  analytics  crime  per  town  and  cities  to  make  the  system  more interesting \\nto any type of user. This is true for the crime analysis website\'s crime map for public \\naccess user review, which ultimately came out to be acceptable. In conclusion, the online \\ncrime reporting system provides various functions and features for various users. This \\ncan be used to raise people\'s awareness regarding dangerous locations and help agencies \\npredict  future  crime  in  a  specific  location  within  a  particular  time.  (Development  of \\nCrime Reporting System to Identify Patterns of Crime in Laguna, Balahadia, F. F. et al., \\n2022) \\n \\n2.  The  research  addressed  the  problem  of  crime  rates  in  Rizal  Province  by  focusing  on \\ncrime prediction and prevention strategies. The methodology used in the study involved \\ndetermining significant predictors using Pearson Correlation and predicting crime and \\ncrime  rates \\nin \\nthe  province.  Time-series  forecasting  models  were  compared  and \\nevaluated to find the best forecasting model for the crime datasets. The datasets included \\ninformation on the disposition of troops, station raw materials/resources, and historical \\ncrime  statistics  from  2013  to  2017  from  fourteen  municipal  police  stations  in  Rizal \\nProvince. The Mean Absolute Percentage Error (MAPE) was used to assess the accuracy \\nof each forecasting model. The Shapiro test was used to test the normality of the data, \\nand either the t-test or Wilcoxon test was used to determine the statistical significance of \\nthe predictions. The research utilized time-series analysis and forecasting techniques, as \\nwell as linear regression modeling, to predict future crime trends. The study aimed to \\nprovide valuable information for police stations to identify problematic regions for patrol \\nand make informed decisions regarding the allocation of patrol manpower and station \\nresources  to  suppress  crime.  In  conclusion,  the  research  successfully  applied  crime \\nforecasting models to analyze crime rates in Rizal Province, providing insights that can \\naid in crime prevention and resource optimization for law enforcement agencies. The \\nstudy highlighted the importance of utilizing data-driven approaches to address crime-\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0\n0  urban/rural  categorization  also \\ninfluencing  CHI  variance.  The  comparison  of \\nthe \\nmethods  showed \\nthat \\nthe  CHI  provided  a  different  perspective  on  crime  harm \\nconcentration compared to the PLI. Mapping techniques were used to illustrate outlier \\nlocations  where  the  CHI  and  PLI  differed  widely,  providing  insights  into  the  spatial \\ndistribution of crime harm in New Zealand. The study highlighted the potential for using \\ncrime harm indices to inform resource allocation and improve understanding of crime \\nharm  concentration at  different  geographic  levels.  (Mapping crime  harm  and  priority \\nlocations  in  New  Zealand:  A  comparison  of  spatial analysis  methods,  Sophie  Curtis-\\nHam a and  Darren Walton, 2017) \\n \\nPatents \\n \\n11.  The patented study, titled \"Visual analytics law enforcement tools,\" introduces a visual \\nanalytic  tool  used  in  the  field  of  public  safety. The  invention  provides a  method and \\ndevice  for  determining  regional  spatial  incidence  relations,  specifically  focusing  on \\nincidents  and  locations  related  to  law  enforcement.  The  methodology  involves  using \\npredictive visual analytics to forecast hotspots and analyze patterns in data related to law \\nenforcement incidents. The problem solved by this invention is the ability to effectively \\nanalyze  and  visualize  complex  data  sets  to  aid  law  enforcement  agencies  in  making \\ninformed decisions and improving public safety. (Visual analytics law enforcement tools \\nUS8849728B2, D. S. Eber et al., 2019). \\n \\n12. The patented study introduces a predictive policing system that utilizes historical crime \\ndata to forecast crime events in specific geographic regions. The system aims to assist in \\ncrime  prevention,  deterrence,  and  disruption  practices.  The  methodology \\ninvolves \\nprocessing  the  historical  crime  data  using  a  crime  forecasting  algorithm  to  generate \\ncrime forecasts for different crime types in designated areas. The problem solved by this \\ninvention is the ability to proactively address and potentially prevent criminal activities \\nby providing law enforcement agencies with valuable insights and predictions regarding \\nwhere and when crimes are likely to occur. By leveraging data and predictive analytics, \\nthe  system  can  help  allocate  resources  more  effectively  and  improve  overall  public \\nsafety. (Event forecasting system US8949164B1, G. O. Mohler, 2017).\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    T\\nHow do you intend to solve the problem? \\no address the challenge, the study proponents plan to leverage historical data, spatial analysis, \\nand sophisticated algorithms to predict high-risk zones and optimize law enforcement strategies \\nfor combating drug activity in Pagsanjan and Lumban, Laguna. This approach aims to offer a \\ntargeted  and  proactive  response \\nto  drug-related  concerns,  empowering \\nlaw  enforcement \\nagencies to allocate resources effectively and focus efforts on areas with the highest risk.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0 1 2 3 4\n0  T\\n  I\\n  S\\n  F\\nMachine learning  further  enhances the  predictive capabilities  of  the  system.  Algorithms  like \\nRandom Forest or Support Vector Machines are trained on the pre-processed data, which now \\nincorporates both spatial and temporal features. These models learn from past trends and predict \\nfuture spikes in drug activity within the target area.  \\no evaluate the performance of these algorithms, a confusion matrix will be applied, dividing \\ndata into two classes: predictive class (generated from the classifier) and actual class (originally \\nknown data). \\nn the confusion matrix, precision is defined as the amount of data characterized positively and \\nclassified correctly (true positive) divided by the total data resulting in positive classification. \\n(Precision = True Positive/True positive + False Positive x100%) \\nimilarly, the negative predictive value is defined as the amount of data characterized negatively \\nand  classified  negatively  (true  negative)  divided  by \\nthe \\ntotal  data  resulting \\nin  negative \\nclassification. \\n(Negative Predictive Value = True Negative/True negative + False Negative x100%) \\nigure 2 below, is the conceptual framework of the study. This framework, particularly adept at \\nanalyzing data with both spatial and temporal components, guides the study of the proponents \\nfocused on predicting and combating drug activity within Laguna. \\n \\nFigure 2. Conceptual Framework.        \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       S\n1  O\\nWOT Analysis: \\nStrengths: \\n1.  Data-driven  Approach:  This  system  leverages  data  analysis  to  optimize  resource \\nallocation, leading to potentially more effective law enforcement efforts. \\n2.  Predictive Capabilities: By identifying hotspots and predicting future spikes in drug \\nactivity, the system allows for proactive interventions and targeted resource allocation. \\n3. \\nImproved Police Effectiveness: Strategic checkpoint placement, efficient patrol routes, \\nand faster response times can enhance police effectiveness in combating drug activity. \\n4.  Network Optimization:  Network analysis considers travel times, ensuring a balance \\nbetween maximizing coverage and enabling swift police response. \\n5.  Scalability  and  Adaptability:  The  system  can  be  adapted  to  different  geographical \\nareas and potentially scaled up for wider implementation. \\n \\nWeaknesses: \\n1.  Data Quality Dependence: The system\'s effectiveness relies heavily on the accuracy \\nand completeness of the input data (drug activity and road network data). \\n2.  Privacy Concerns: Collection and use of drug activity data may raise privacy concerns, \\nrequiring careful consideration of ethical implications. \\n3.  Technological  Limitations:  The \\nsystem\'s  performance  depends  on \\nthe \\nchosen \\nalgorithms and their limitations in prediction accuracy. \\n4.  Resource  Requirements:  Implementing  and  maintaining \\nthe  system  may  require \\nsignificant investment in technology, training, and personnel. \\n5.  Limited Scope: The system focuses on resource allocation for law enforcement and may \\nnot address the root causes of drug activity. \\npportunities: \\n1. \\nIntegration  with  Existing  Systems:  The  system  can  be  integrated  with  existing  law \\nenforcement databases for improved data access and real-time analysis. \\n2.  Collaboration  with  Public  Health  Agencies:  Insights  from  the  system  can  inform \\npublic health outreach programs and prevention efforts. \\n3.  Community Engagement: Collaboration with communities can improve data collection \\nand build trust in law enforcement efforts.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0\n0  T\\n4.  Development of Educational Tools:  The system\'s data visualizations can be used to \\ncreate educational tools for communities and policymakers. \\n5.  Potential for Broader Applications: The core concepts can be adapted for other crime-\\nmapping and resource allocation challenges. \\n \\nThreats: \\n1.  Cybersecurity  Risks:  Data  breaches  or  cyberattacks  can  compromise  the  system\'s \\nintegrity and security of sensitive data. \\n2.  Resistance from Law Enforcement: Traditional practices and skepticism towards data-\\ndriven approaches might hinder adoption within law enforcement agencies. \\n3.  Misuse of the System:  The system\'s outputs could be misused for racial profiling or \\ndiscriminatory practices. \\n4.  Evolving Criminal Tactics: Criminals might adapt their activities to evade detection by \\nthe system. \\n5.  Sustainability Challenges: Long-term funding and support may be needed to maintain \\nand update the system effectively.\n1                                                                                                                                                                                                                                                                                      T\\narget users / Beneficiaries:(Describe each Beneficiary) \\nhe primary beneficiaries of this study are the Department Enforcement Units (DEUs) of the \\nMunicipal Police stations in Pagsanjan and Lumban, Laguna. Through insights gained from the \\ndeveloped  system,  law  enforcement  agencies  can  improve  resource  allocation,  strategically \\nposition checkpoints, and design efficient patrol routes to proactively combat drug activity and \\nenhance public safety. Secondary beneficiaries include the citizens of Pagsanjan and Lumban, \\nwho stand to benefit from a safer and more secure environment resulting from reduced drug \\nactivity and improved law enforcement efforts.\n2                                                                                                                                                                                                              S\\n  T\\nignificance of study: \\nhis study holds paramount significance in advancing crime prevention and public safety efforts \\nin Pagsanjan and Lumban Laguna through the integration of machine learning technologies. By \\ndeveloping a system that harnesses spatiotemporal analysis and machine learning algorithms to \\npredict high-risk areas, optimize law enforcement strategies, and enhance citizen engagement, \\nthis  research  contributes  substantially  to  combating  drug  activity  and  promoting  community \\nwell-being. Moreover, the insights and methodologies derived from this study can serve as a \\nblueprint for similar initiatives in other regions, offering a model for effective crime prevention \\nand public safety measures nationwide.\n\n  0                                                                                                           1 2\n0                                                                                                                \n1                                                                                                                \n2    Figure 3. Photo after interview with Pat. Penafiel of the Municipal Police Station of \\nPagsanjan, Laguna.  \n\n                                                                    0                                                                                                 1                                                                    2     3\n0                       TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                             \n1                                       TECHNOLOGY (Machine Learning)                                                                                                                                                                             \n2       Predicting drug \\nuse trajectories \\nusing machine \\nlearning  This research employs \\nmachine learning to predict \\ndrug use trajectories among \\nadolescents.  Focuses on predicting \\nfuture drug use based on \\nindividual data.  2017\n3  Machine \\nlearning for \\nopioid detection \\nin social media \\ndata                                      Machine learning for opioid \\ndetection in social media data    Analyzes social media \\ncontent for opioid-related \\ninformation.  2020\n4                                                        A Supervised                                                                          This research proposes a                                           Focuses on drug discovery,  2021\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0                                                                                                              1                                                                       2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Learning \\nApproach for \\nDrug Discovery \\nUsing Multi-\\nTask Learning                                                             multi-task learning approach \\nfor drug discovery.                             not on identifying illegal \\ndrug activity.      \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Classification of \\nAntidepressant \\nPrescription \\nClaims Using \\nMachine \\nLearning                     This study utilizes machine \\nlearning to classify \\nantidepressant prescription \\nclaims.                Analyzes prescription data, \\nnot illegal drug activity.  2019\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Machine \\nLearning and \\nFeature \\nEngineering for \\nImproved Drug-\\nTarget \\nInteraction \\nPrediction  This research explores \\nmachine learning and feature \\nengineering for drug-target \\ninteraction prediction.  Focuses on drug-target \\ninteractions, not on illegal \\ndrug activity.  2022\n3  O\\n  B\\nExisting research demonstrates the effectiveness of spatiotemporal analysis for identifying \\nhotspots  of  illegal  drug  activity.  Techniques  like  spatial  clustering  and  hotspot  analysis \\nreveal  spatial  patterns,  while  space-time \\ninteraction  scan  statistics  offer  potential  for \\nidentifying  emerging  trends.  However,  these  studies  often  lack  predictive  capabilities  or \\nnetwork analysis components. \\nne opportunity here is to develop a comprehensive spatiotemporal model that integrates \\nhotspot  identification,  space-time  interaction  analysis,  and  prediction  of  future  high-risk \\nzones. This model can incorporate network analysis for optimal checkpoint placement and \\nefficient patrol route design, maximizing law enforcement effectiveness. \\ny combining existing techniques within a unified framework, this system could not only \\nidentify current hotspots of drug activity but also predict future ones. Integrating network \\nanalysis  would  translate  these  insights  into  actionable  strategies  for  resource  allocation, \\nleading to a more proactive approach to combating drug activity.                                                                                                                                                                                             \n\n                                                          0                                                                                                            1                                                                            2     3\n0             TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                \n1                  Spatiotemporal Analysis in Illegal Drugs                                                                                                                                                                                                \n2  Space-time \\ndynamics of \\npolydrug use: A \\ncomparative  This study utilizes spatial \\nclustering to identify hotspots \\nof heroin distribution in \\nBaltimore City.  Focused on a single city \\n(Baltimore) using cluster \\nanalysis techniques.  2013\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0                                                                                                                  1                                                                                               2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              analysis of \\nheroin and \\ncocaine                                                                                                                                                                                                                         \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Space-time \\ndynamics of \\npolydrug use: A \\ncomparative \\nanalysis of \\nheroin and \\ncocaine                         This research compares the \\nspace-time dynamics of \\nheroin and cocaine use in \\nChicago.                           Analyzes two drugs within \\na single city using spatial \\nlag models.  2018\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Using GIS and \\nspatial statistics \\nto identify drug \\ntrafficking \\nhotspots in El \\nPaso, Texas  This study employs GIS and \\nspatial statistics to identify \\nhotspots of drug trafficking \\nactivity in El Paso.                                 Focuses on a single city \\nusing hotspot analysis \\ntechniques.  2015\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     A space-time \\ninteraction scan \\nstatistic for \\ninfectious \\ndisease data                    This research proposes a \\nspace-time scan statistic for \\nanalyzing infectious disease \\ndata.  The methodology is \\ndesigned for infectious \\ndiseases, not specifically \\nfor illegal drugs.  2019\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Space-time \\nclustering of \\nmotor vehicle \\ncrashes: A \\nreview of \\nmethods                                 This study reviews methods \\nfor space-time clustering of \\nmotor vehicle crashes.                                         The focus is on traffic \\naccidents, not illegal drugs.  2010\n5  Machine learning holds promise for analyzing various data sources related to illegal drugs, \\nincluding arrest records, social media content, and individual risk factors. Existing studies \\npredict future drug use trajectories and identify potential opioid use from social media data. \\nHowever,  these  studies  focus  primarily  on  individual-level  data  or  social  media content, \\nneglecting the spatial and temporal dynamics of drug activity. Furthermore, by developing \\nmachine learning models that incorporate spatiotemporal data (e.g., arrest locations, time of \\nday) alongside social media analysis. This would allow for predicting high-risk areas for \\ndrug  activity  and  identifying  emerging  trends.  By  integrating  social  media  data  with \\ntraditional law enforcement data and leveraging machine learning\'s predictive power, this \\napproach could provide a more holistic understanding of drug activity patterns. This would \\nenable  law  enforcement  to  anticipate  and  target  interventions  in  high-risk  areas  before \\nproblems escalate.                                                                                                                                                                                                                         \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0                                                                                                                      1                                                                                                        2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Illegal Drugs                                                                                                                                                                                                                                      \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       A Review of \\nReviews on \\nRisk Factors for \\nIllicit Drug Use                                 This study assesses the \\nglobal burden of disease \\nattributable to illicit drug use.                         Provides a global \\nperspective on the health \\nconsequences of illegal \\ndrugs.  2013\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Machine \\nlearning for \\nopioid detection \\nin social media \\ndata  This report by the World \\nHealth Organization (WHO) \\nprovides an overview of \\nglobal trends in illicit drug \\nuse.          Offers a broad overview of \\nglobal trends, but may lack \\nregional or city-specific \\ndetails.  2020\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The economic \\nand social costs \\nof illegal drugs                                         This study reviews existing \\nresearch on risk factors for \\nillicit drug use.     Analyzes individual-level \\nrisk factors, not the spatial \\nor temporal dynamics of \\ndrug activity.  2021\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       A Review of \\nReviews on \\nRisk Factors for \\nIllicit Drug Use                             This study utilizes machine \\nlearning to classify \\nantidepressant prescription \\nclaims.                                                 Analyzes prescription data, \\nnot illegal drug activity.  2019\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The \\nEffectiveness of \\nInterventions to \\nReduce Illicit \\nDrug Use                              This research examines the \\neffectiveness of interventions \\nto reduce illicit drug use.  Focuses on evaluating \\ninterventions, not on \\nidentifying the nature and \\npatterns of drug activity.  2022\n6  O\\n  A\\nResearch on illegal drugs highlights the significant public health burden and economic costs \\nassociated with them. Existing studies provide insights into global trends and individual-\\nlevel risk factors. However, a gap exists in analyzing the spatial and temporal patterns of \\nspecific drugs within specific regions. \\nne  solution  here  is  by  conducting  in-depth  analyses  of  specific  high-prevalence  illegal \\ndrugs  within  a  chosen \\nregion. \\nIntegrate  knowledge  of \\nindividual \\nrisk \\nfactors  with \\nspatiotemporal analysis to identify high-risk populations and communities. \\nnd  by  focusing  on  a  specific  region  and  drug  type,  a  more  targeted  approach  can  be \\ndeveloped. Combining spatial patterns with individual risk factors can pinpoint high-risk \\nareas and populations within those areas. This knowledge can inform targeted interventions \\naimed at reducing drug use, promoting prevention efforts, and providing support services to \\nvulnerable populations.                                                                                                                                                                                                                                      ', '', '', 0);
INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(100, 'mia.villarica@gmail.com', 'LSHS_-_Career_Assessment-Concept_Paper.pdf', 'uploads/3e6d09697a504f68ab1da04ca99838eb.pdf', '2025-04-24 05:54:20', '                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                     Concept Paper                                \n                                                                                  \n                                                                                  \n           A. Basic Information                                                   \n                                                                                  \n                                                                                  \n           Project Title: Career Compass: Personalized Career Guidance System for Laguna Senior High\n           School (LSHS) Students through the use of NLP, Machine Learning and Data Analytics\n                                                                                  \n                                                                                  \n           Topic: Natural Language Processing, Machine Learning, Senior High School Students, Career\n           Guidance System                                                        \n                                                                                  \n                                                                                  \n           Proponent: JAREEN PIA B. ANDRES, EDRIAN B. FLORES, ANDREL JOHN M.      \n           PANTANOZA                                                              \n                                                                                  \n                                                                                  \n                                                                                  \n           B. Technical Description                                               \n                                                                                  \n           The current status of employment in today\'s date has been shown as a competitive global\n           economy, it is paramount for students to make well-informed decisions regarding their career\n           paths, especially with the growing opportunities for overseas education. While studying abroad\n           offers numerous avenues for personal and professional growth, it can also pose challenges,\n           particularly for students grappling with uncertainty about their future endeavors.\n                                                                                  \n           This is where the significance of career guidance becomes evident. Career guidance plays a\n           pivotal role in assisting students in comprehending their individual strengths, weaknesses, and\n           interests, thereby providing them with a clearer understanding of the diverse career avenues\n           available. Through tailored guidance, students gain insights into various industries, job roles,\n                                                                                  \n           and the requisite skills and qualifications essential for success in their chosen fields (Bhargava,\n           P. 2023, March 01) .                                                   \n                                                                                  \n           Currently, a mandatory exam called the National Career Assessment Examination (NCAE) is\n           being implemented for grade 9 students nationwide. The NCAE is an aptitude test designed to\n           provide information for self-assessment, career awareness, and guidance for high school\n           students as they prepare for their post-secondary courses or apply for scholarships (DEPED\n           Bohol, 2013).                                                          \n                                                                                  \n           The primary objective of the NCAE is to bridge the gap between student skillsets and the\n           requirements of the labor market. By identifying aptitudes in distinct areas, students can be\n           guided toward appropriate Senior High School (SHS) tracks and prospective careers that align\n           with the Philippines\' workforce enhancement efforts (DEPED Bohol, 2013).\n                                                                                  \n           As per DepEdTambayan.com, the results of the NCAE are purely suggestive, without any\n           prescribed cut-off score. The generated results regarding the Senior High School Track are not\n                                                                                  \n           mandatory for students to participate in.                              \n                                                                                  \n           Additionally, the importance of thorough career guidance extends to:   \n           Providing students with the opportunity to explore/navigate on their own:\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Offering students the chance to explore and navigate on their own is crucial. While\n           guidance is essential, it\'s important not to impose restrictions, as each individual is unique in\n                                                                                  \n           various aspects. Allowing them to explore independently ensures a personalized approach\n           tailored to their specific needs and interests, as well as their strength, weakness and other\n           characteristics.                                                       \n                                                                                  \n           Tracking career trajectories:                                          \n           With numerous options and opportunities available, it can be challenging to monitor one\'s\n           career path. Similar to regular health check-ups, maintaining consistent communication with a\n           career counselor at predetermined intervals can assist students in confirming they are\n           advancing in the correct career path.                                  \n                                                                                  \n           Addressing the influence of misinformation:                            \n           Today, one of the major hurdles students encounter is parental influence on their career\n           decisions. While parents often aim to guide their children towards what they perceive as the\n           ideal career, their notions may not always align with the child\'s aspirations or the evolving job\n           market. Moreover, with careers constantly evolving and numerous options available, it\'s crucial\n           for both students and parents to stay informed about changing trends to make informed\n           decisions.                                                             \n                                                                                  \n                                                                                  \n           Correcting career expectations:                                        \n           We must recognize that careers have their limitations and boundaries. It\'s essential to assess\n           the scope of a career path and explore potential avenues available presently and in the future.\n           Before committing to a university course, students should consider how it aligns with their\n           professional aspirations. While we cannot predict all potential changes, we can evaluate the\n           viability of a profession based on current trends and insights into the industry\'s landscape.\n           Mitigating, if not eliminating, uncertainty:                           \n                                                                                  \n           One of the biggest issues for students in their college years is their uncertainty with their\n           current course, especially at times when they are facing hardships. They tend to consider\n           shifting to another course or in worst case scenarios, they choose to drop out as they lack\n           motivation since their judgment is clouded by uncertainty.             \n                                                                                  \n           Statement             of               the              Problem:       \n                                                                                  \n                                                                                  \n             The Career Compass project seeks to address the prevalent gap in senior high school\n           students\' understanding of suitable curriculum choices in alignment with their future career\n           aspirations. Despite the importance of this decision, students often lack access to personalized\n           guidance, leading to confusion and uncertainty regarding their educational paths.\n                                                                                  \n             1. How can the Career Compass system effectively utilize machine learning algorithms to\n                classify and analyze students\' skills, and knowledge per particular subjects, thereby\n                providing personalized career recommendations?                    \n                                                                                  \n             2. What data preprocessing techniques can be implemented within the Career Compass\n                system to optimize the accuracy and reliability of the training dataset, ensuring that it\n                adequately represents students\' diverse backgrounds and career aspirations and\n                alignment?                                                        \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n             3. In what ways can data analytics, and NLP be integrated into the Career Compass system\n                to forecast/show the outline for College courses and future job trends and industry\n                                                                                  \n                demands, enabling timely and relevant career recommendations for senior high school\n                students?                                                         \n                                                                                  \n             4. Will the Career Compass system have access to existing datasets for training and\n                validation, or will it need to collect and curate new datasets to ensure the effectiveness\n                and reliability of its career guidance functionalities?           \n                                                                                  \n             5. How accurately and reliably can the Career Compass system leverage the combination\n                of machine learning and nlp to provide tailored career guidance to senior high school\n                students, and what metrics will be utilized to evaluate its performance and effectiveness\n                in addressing students\' needs and aspirations?                    \n                                                                                  \n           Objectives: General and Specific General Objective:                    \n           The main objective of this study is to design and develop a robust machine learning model that\n           utilizes algorithms to classify students\' interests, skills, and preferences, non-technical skills\n           (strength and weaknesses) along with suitable course alignment starting from their SHS up till\n                                                                                  \n           College courses and Job target interest.                               \n                                                                                  \n           Specifically, it aims to:                                              \n                                                                                  \n             1. Gather relevant datasets, including students’ academic performance, and industry\n                based data, to train and validate the machine learning model for accurate career\n                alignment suggestions.                                            \n                                                                                  \n                  ●  Student based Dataset: Will be provided by Laguna Senior High School\n                                                                                  \n                  ●  Industry based Dataset: Online resources and references will be utilized.\n                                                                                  \n             2. Implement data preprocessing techniques to enhance the quality and reliability of the\n                training dataset, ensuring it adequately represents students\' diverse backgrounds and\n                career aspirations.                                               \n                                                                                  \n                                                                                  \n                  ●  Natural Language Processing Techniques:                      \n                     -Data Cleaning                                               \n                     -Feature Selection and Categorization                        \n                     -Encoding Categorical Variables                              \n                     -Data Normalization                                          \n                     -Exploratory Data Analysis                                   \n                     -Validation                                                  \n                                                                                  \n             3. Integrate data analytics tools to analyze job market trends and industry demands,\n                enabling the system to provide timely and relevant career recommendations.\n                                                                                  \n                  ●  Data Analysis Techniques                                     \n                  ●  Job Market Analysis                                          \n                  ●  Industry Demand Analysis                                     \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n             4. Design and develop a user-friendly web-based system that serves as a platform for\n                senior high school students to access personalized career guidance based on their\n                                                                                  \n                individual profiles and preferences.                              \n                                                                                  \n                  ●  Development of a web-based system to enable easier access for students or\n                     institutes. As suggested through a preliminary interview with an expert in the\n                     field of education.                                          \n                                                                                  \n                                                                                  \n                                                                                  \n           How did others solve the problem?                                      \n                                                                                  \n             1. NCAE       proposed     solutions   (Teacherph.com,   2016):      \n                                                                                  \n                                                                                  \n                The NCAE offers a standardized assessment that evaluates students\' aptitudes and\n                interests across various occupational areas. This approach provides a more objective\n                evaluation compared to solely relying on student preferences or anecdotal observations.\n                                                                                  \n                Data-driven recommendations are provided based on the NCAE results, offering students\n                guidance on suitable Senior High School (SHS) tracks that align with their assessed\n                strengths and interests.                                          \n                                                                                  \n                                                                                  \n                By combining the NCAE results with guidance counselor support, students are\n                empowered to make more informed decisions about their future education and career\n                paths.                                                            \n                                                                                  \n                                                                                  \n             2. Implementation of OJT on Select Colleges in Quezon City (Hebron, D., September\n                2020)                                                             \n                                                                                  \n                The advantages of On-the-Job Training (OJT) for students serve as a crucial bridge\n                between academic learning and professional readiness. OJT accelerates skill\n                development, instills confidence, and fosters a sense of belonging within the\n                workplace. By immersing students in real-world scenarios, OJT equips them with\n                industry-specific knowledge and practical experience. Moreover, OJT enhances growth\n                                                                                  \n                opportunities by providing tailored feedback and preparing students to handle\n                unforeseen challenges effectively. Despite some challenges encountered during OJT,\n                such as inadequate equipment or labor-intensive tasks, the overall experience\n                empowers students to develop essential skills, adapt to change, and formulate realistic\n                career plans                                                      \n                                                                                  \n           Other Related Study (data gathering and machine learning methods)      \n                                                                                  \n             1. Guidance interview with a careers’ adviser (University of Kent)   \n                The data gathering is characterized by its impartial, confidential, challenging, and\n                supportive nature. Careers advisers provide objective exploration without bias, maintain\n                confidentiality, and challenge your goals to ensure thorough consideration. Additionally,\n                                                                                  \n                the process is supportive, offering a safe environment for discussion as privacy is\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                respected. It\'s essential to recognize that career choice is a continuous process, and the\n                                                                                  \n                interview serves as a starting point, requiring further research and action plan updates.\n                                                                                  \n             2. The National Career Assessment Examination (NCAE) gathers datasets from examinees\n                through standardized scores and percentile ranks.                 \n                                                                                  \n                Standard scores are calculated with a mean of 500 and a standard deviation of 100. The\n                highest scores typically range in the 700s, while the lowest scores are found in the 300s.\n                                                                                  \n                These scores provide a standardized measure of each examinee\'s performance relative to\n                the mean and standard deviation of the entire population.         \n                                                                                  \n                Percentile ranks indicate the test taker\'s position among all examinees. For example, if\n                an examinee scores at percentile rank 99+, it signifies that they scored higher than 99%\n                of the other examinees. This percentile rank offers insight into an individual\'s relative\n                standing within the entire group of test takers.From then on, they use the gathered data\n                                                                                  \n                to analyze and suggest SHS track based on students’ criterias.    \n                                                                                  \n             3. Based on José-García et al. (2022), career guidance systems like C3-IoC provide self-\n                assessment tools, searchable occupation databases, and decision support models. These\n                systems advance by matching student competencies with job requirements and aiding in\n                identifying aligned positions.                                    \n                                                                                  \n                                                                                  \n                However, effective assessment extends beyond technical skills to include non-technical\n                skills, interests, and personality traits. Modern systems, like MBTI and O*NET Interest\n                Profiler offers diverse approaches, while CAPA suggests college major clusters based on\n                interests.                                                        \n                                                                                  \n                To ensure accuracy, systems rely on databases like ONET and ESCO. Yet, they may lack\n                specificity, especially in industries like UK IT. C3-IoC addresses this with\n                                                                                  \n                complementary datasets, merging research-based taxonomies with real-time job market\n                data for a comprehensive understanding of skill requirements.     \n                                                                                  \n                                                                                  \n           Patents                                                                \n                                                                                  \n             1. In their study titled \"C3-IoC: A Career Guidance System for Assessing Student Skills\n                using Machine Learning and Network Visualization\" (December 2022), José-García et\n                al. introduce a novel approach to personalized career exploration and skill assessment,\n                particularly in the IT sector. The research aims to bridge the gap in existing career\n                guidance systems by developing the C3-IoC system, which provides users with insights\n                                                                                  \n                into both technical and non-technical skills required for various IT job roles. This\n                system is built upon three main modules: a knowledge base of skills and job roles\n                curated from recent UK IT job vacancies, a user skill profiling module allowing for\n                skill input and refinement, and a personalized job role matching and visualization\n                module enabling users to explore potential career paths through network visualizations.\n                                                                                  \n                Through text mining techniques and analysis of job titles, the study constructs a\n                comprehensive database of technical skills and common job roles within the IT\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                industry. Users can then input their skills and refine their profiles using visualizations\n                                                                                  \n                such as radar charts, facilitating a personalized assessment of their strengths and\n                weaknesses. The system further aids users in exploring job roles through network\n                visualizations, allowing them to visualize their placement in the IT job role space based\n                on their skill profiles. Overall, the C3-IoC system serves as a valuable tool for\n                empowering students to make informed decisions about their career paths within the\n                dynamic landscape of the IT job market.                           \n                                                                                  \n                                                                                  \n                                                                                  \n           Theoretical Framework:                                                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Figure 1. C3-IoC: A Career Guidance System for Assessing Student Skills using Machine\n                                                                                  \n             Learning and Network Visualisation (José-García, A., et al. (2023). C3-IoC: Career\n                         Guidance System. Journal Name, 33, 1092–1119.)           \n                                                                                  \n           The current C3-IoC system aims to offer personalized career exploration and facilitate users\'\n           understanding of both technical and non-technical skills essential for IT sector careers. While\n                                                                                  \n           primarily focusing on IT, the system also includes information on various job roles to cater to\n                                                                                  \n           users outside this sector.                                             \n                                                                                  \n                                                                                  \n           The system architecture comprises three main modules: a knowledge base of skills and job\n           roles, a user skill profiling module, and a personalized job role matching and visualization\n                                                                                  \n           module. The user journey involves three stages: initial extraction of skills through a CV parser\n                                                                                  \n           and questionnaire, refinement of skill profiles, and exploration of job roles through network\n           visualization.                                                         \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           This framework emphasizes the system\'s objective of providing tailored career guidance and\n                                                                                  \n           enhancing users\' comprehension of requisite skills, ensuring a comprehensive approach to\n                                                                                  \n           career exploration within and beyond the IT domain.                    \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           How do you intend to solve the problem?                                \n                                                                                  \n              To address the educational and career planning challenges faced by senior high school\n                                                                                  \n           students at Laguna Senior High School (LSHS), the proponent plans the development and\n           implementation of \"Career Compass,\" a personalized career guidance system powered by\n                                                                                  \n           machine learning, NLP and data analytics.                              \n                                                                                  \n                                                                                  \n              Career Compass aims to provide tailored assistance to students by offering a user-friendly\n                                                                                  \n           interface designed to meet their specific needs. It will incorporate informative modules covering\n           various aspects of career planning and educational pathways, ensuring students have access to\n                                                                                  \n           relevant                                               information.    \n             Furthermore, it will prioritize assessing students’ capability/knowledge per subject then\n                                                                                  \n           course alignment as a key feature. It will offer practical tools to help students identify the best\n           college course to take based on their interests and academic performance. Through informative\n                                                                                  \n           modules and interactive features, the system will guide students in understanding the alignment\n                                                                                  \n           between their chosen SHS strand and potential college curricula. By integrating course\n           alignment functionalities, Career Compass aims to provide students with the necessary guidance\n                                                                                  \n           to make informed decisions about their educational pathways. This emphasis on course\n           alignment will ensure that students are equipped with the knowledge and resources to navigate\n                                                                                  \n           their educational and career journeys effectively. The pathway does not just stop upon college\n                                                                                  \n           course alignment, it would also show the specifics when it comes to certain jobs/industries along\n           with up to date income range.                                          \n                                                                                  \n           In short…                                                              \n             The criteria for alignment suggestions will be based on students’ grade per subject, interests\n                                                                                  \n           (added        feature),      then         career       aspirations.    \n                                                                                  \n                                                                                  \n           In return, students will receive visualizations regarding the alignment between their interests and\n                                                                                  \n           potential career pathways. This includes recommendations for the best associated college\n           curricula, applicable or potential job industries, and up-to-date salary ranges for these industries.\n                                                                                  \n           They will also be able to see the relevance of their results per area and identify the exact areas\n                                                                                  \n           that lack nourishment if they have decided to pursue a certain path/job. Additionally, the system\n           will show specific areas students should navigate during their early age to help them become\n                                                                                  \n           more familiar with the background and fundamentals.                    \n           For example, if a student wants to be a game developer, even during their SHS, they may already\n                                                                                  \n           explore various programming languages and certain fundamentals to help them achieve their\n                                                                                  \n           goal.                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Scope:                                                                 \n                                                                                  \n                                                                                  \n           Design and development of a machine learning-based career guidance system aimed at\n           assisting senior high school students in selecting appropriate educational and career paths\n           aligned with their capability in terms of their graded knowledge per subject.\n                                                                                  \n           Utilization of student-based data provided by the school for training the model, complemented\n           by industry data sourced from online resources to align career suggestions with current job\n           market demands.                                                        \n                                                                                  \n                                                                                  \n           Implementation of machine learning algorithms and data preprocessing techniques to analyze\n           students\' academic performance, along with job market trends, for personalized career\n           recommendations.                                                       \n                                                                                  \n           In terms of system development, a user-friendly web-based application for students and\n           educational institutions, enabling easy access to personalized guidance and\n           recommendations.                                                       \n                                                                                  \n                                                                                  \n                                                                                  \n           Limitations                                                            \n                                                                                  \n           The system\'s effectiveness may be limited by the availability and quality of student-based data\n           provided by the school. Insufficient or inaccurate data can impact the accuracy of career\n           recommendations.                                                       \n                                                                                  \n           Reliance on industry data sourced from online resources introduces the risk of outdated or\n           inaccurate information. Changes in job market trends may not be promptly reflected in the\n           system\'s recommendations.                                              \n                                                                                  \n           The system\'s ability to generalize recommendations to diverse student profiles and career\n           preferences may be a challenge. Customizing recommendations for individual students with\n           unique interests and goals requires sophisticated algorithms and a comprehensive\n           understanding of user preferences.                                     \n                                                                                  \n                                                                                  \n           Handling sensitive student data and ensuring privacy and security measures in data storage,\n           processing, and transmission are critical concerns that need to be addressed to comply with\n           data protection regulations and maintain user trust.                   \n                                                                                  \n           In terms of the industry-based data, the rapidly changing nature of job markets and the\n           emergence of new career paths could affect the long-term accuracy and relevance of the\n           system\'s recommendations.                                              \n                                                                                  \n           Target users / Beneficiaries:(Describe each Beneficiary)               \n                                                                                  \n           Students:                                                              \n           The Career Compass system will be a benefit for the students by providing personalized career\n           guidance and course recommendations, helping them make informed decisions about their\n           educational and career pathways.                                       \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Parents:                                                               \n                                                                                  \n           Parents will benefit from increased confidence in their children\'s future prospects, as well as\n           access to resources based on facts and support for guiding their children through the career\n           exploration process.                                                   \n                                                                                  \n           Schools:                                                               \n           Educational institutions can enhance student engagement and retention by integrating the Career\n           Compass system into their existing platforms, providing tailored career guidance and course\n           recommendations to students based on their interests and aspirations. This implementation\n           supports more informed curriculum planning, aligning educational offerings with students\'\n           career goals and fostering a more supportive learning environment.     \n                                                                                  \n           Companies:                                                             \n           Employers will benefit from a more skilled and prepared workforce, leading to improved\n           recruitment outcomes and reduced skill gaps in the job market.         \n                                                                                  \n           Significance of study:                                                 \n                                                                                  \n           The Career Compass project is significant due to its help targeted to senior high school\n           students at Laguna Senior High School in the Philippines in terms of planning for their future\n           careers. This system uses technology to give students personalized advice on which courses to\n           take and which careers might suit them best. It\'s important as it helps students make better\n                                                                                  \n           choices about their education and future jobs. Additionally, it supports schools by providing\n           them with a helpful tool to assist their students in career planning. Ultimately, Career Compass\n           aims to assist students to make informed decisions and achieve success in their academic and\n           professional lives in the long run.                                    \n                                                                                  \n          Gap Analysis                                                            \n               TITLE             DESCRIPTION        SCOPE/TECHNOLOGY  YEAR        \n                                   TECHNOLOGY: C3 IoC                             \n           C3-IoC: A Career The C3-IoC stands as a pioneering solution C3-IoC career assessment 2022\n           Guidance System for in the realm of career guidance systems, system specific for the IT\n           Assessing Student specifically tailored to empower students in sector. \n           Skills using Machine navigating the complex landscape of the           \n           Learning and  Information Technology (IT) sector. The scope of the C3-IoC\n           Network Visualisation Rooted in the principles of Artificial extends across the vast expanse\n           (José-García, A., et Intelligence (AI), this system revolutionizes of the IT sector, encompassing\n           al., 2023).   the traditional approach to career diverse domains ranging from\n                         exploration by offering a comprehensive software development and data\n                         suite of tools and resources aimed at analytics to cybersecurity and\n                         equipping users with the knowledge and cloud computing.  \n                         insights needed to make informed decisions               \n                         about their professional trajectories. Leveraging a wealth of data\n                                                   sources, including job         \n                         At its core, the C3-IoC endeavors to bridge advertisements and established\n                         the gap between educational attainment and skill databases such as O*NET,\n                         industry demands within the IT sector. By the system curates a rich\n                         harnessing advanced AI technologies, the repository of job roles and\n                         system facilitates the seamless alignment of associated skill requirements\n                         users\' skills, qualifications, and aspirations tailored to the ever-evolving\n                         with the dynamic job market landscape. landscape of the IT industry.\n                         Through an innovative similarity metric                  \n                         method, the C3-IoC establishes meaningful                \n                         connections between existing job roles and               \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                         a diverse range of technical and non-                    \n                         technical skills, thus enabling users to gain            \n                         deeper insights into the skillsets required              \n                         for various positions.                                   \n           Presented above, the C3- IoC is a system created for a career assessment system specific for the\n           IT sector, with the same goal of bridging lacking knowledge between educational attainment\n           and industry demands within the IT sector as aforementioned before.    \n                                                                                  \n           In the proposed study of Career Compass, the goal is to develop a system where it is not just\n           limited to a particular sector, but instead focused on career alignment and job trends specific\n           within the country. It aims for a comprehensive line up of career alignment starting from College\n           course to take > Aligned Job > Respective up to date salary estimate.  \n                                                                                  \n                                                                                  \n                                                                                  \n               TITLE               DESCRIPTION         SCOPE/TECHNOLOGY YEAR      \n                          TECHNOLOGY: Data Analytics in the context of NLP        \n           Analysis of Students’ This study delved into the correlation between student Data preprocessing: 2021\n           Aptitude and aptitude and academic performance among Grade 10 Cleaning, filtering, and\n           Academic     students, leveraging data analytics techniques to glean organizing the NCAE\n           Performance: insights from the National Career Assessment dataset to ensure data\n           Input to Curriculum Examination (NCAE) results. The analysis encompassed quality and consistency.\n           Enhancement  three domains: General Scholastic Ability (GSA),          \n           (Sugano, S. G. C., & Technical-Vocational Aptitude (TVA), and Academic Descriptive analytics:\n           Mamolo, L. A. and Track (AT), shedding light on students\' proficiency levels Utilizing statistical\n           Shalom Grace C. across various aptitude areas. methods to summarize and\n           Sugano., 2021 )                             describe key               \n                        This study applied data analytics techniques to analyze the characteristics and trends\n                        correlation between student aptitude and academic within the dataset.\n                        performance among Grade 10 students, with a specific      \n                        focus on insights derived from the National Career Correlation analysis:\n                        Assessment Examination (NCAE) data. By leveraging Investigating relationships\n                        advanced analytical methods, the research aimed to extract between variables such as\n                        valuable insights into students\' aptitude levels and career student aptitude levels and\n                        preferences.                   academic performance       \n                                                       metrics.                   \n                                                       Predictive analytics:      \n                                                       Employing predictive       \n                                                       modeling techniques to     \n                                                       forecast future academic   \n                                                       outcomes based on          \n                                                       historical data patterns.  \n           While the aforementioned study provides valuable insights into the relationship between student\n           aptitude and academic performance using data analytics, it may lack a comprehensive approach\n           to career guidance and decision-making. The study primarily focuses on analyzing existing data\n           to understand correlations between aptitude and academic performance but may not offer\n           personalized guidance or actionable recommendations for individual students.\n           In contrast, the Career Compass aims to address this gap by offering a personalized and\n           interactive platform for students to explore various career paths based on their interests and\n           grade per subject. Additionally, the Career Compass incorporates elements of self-assessment\n           and reflection, allowing students to actively engage in the career exploration process and make\n           informed decisions about their academic and professional futures.      \n           It is also notable that the aforementioned study regarding NCAE does not provide visualizations\n           for the results while the Career Compass does.                         \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           By integrating data analytics techniques with personalized career guidance, the Career Compass\n           offers a more holistic approach to supporting students in their academic and career development\n                                                                                  \n           journey, empowering them to make informed choices and pursue pathways aligned with their\n           interests and aspirations.                                             \n                                                                                  \n               TITLE              DESCRIPTION          SCOPE/TECHNOLOGY YEAR      \n                                                                                  \n                           Technology: Machine Learning in Career Assessment      \n            Machine learning The study explores the application of machine learning 2019\n           approach for student (ML) in career assessment for students transitioning from Machine Learning\n               career    secondary school to higher education. It addresses the   \n            assessment in the challenge of students not knowing how to choose their The study focuses on\n             modern world academic career and the importance of assessing their utilizing machine learning\n                          capabilities in subjects like mathematics and physics. (ML) techniques to address\n            ( Sai Kuswanth, V., Traditionally, this assessment was done manually by the challenge of career\n            Gogineni Krishna counselors, but in the modern world, an expert system assessment among\n           Chaitanya, B., Sekhar employing ML techniques is utilized. This expert system secondary school students\n           Babu, B., & Uppuluri presents students with questions to assess their transitioning to higher\n              Lakshmi    capabilities and performance, allowing for more efficient education. It involves\n            Soundharya., 2019, and objective career assessment. ML is described as a set developing an expert\n               March)    of artificial intelligence techniques that enable computers system that automates the\n                        to \"learn\" from data without being explicitly programmed. assessment process, aiming\n                          It involves training a model using past data to make to provide efficient and\n                          predictions or decisions on new, unseen data. ML is objective evaluations of\n                         particularly useful in scenarios where designing specific students\' capabilities and\n                          algorithms with high performance is challenging or performance.\n                          infeasible, such as email filtering, network intrusion  \n                        detection, and optical character recognition. In the context Through the expert system,\n                         of career assessment, ML helps in analyzing student data students are presented with\n                        and making informed suggestions for suitable career paths questions designed to\n                         based on their performance and capabilities in relevant assess their abilities and\n                         subjects. The study emphasizes the importance of data- interests, particularly in\n                         driven approaches in handling various types of data and subjects like mathematics\n                          highlights ML as a valuable tool for transforming the and physics, which are\n                            traditional approach to career assessment. crucial for academic and\n                                                       career success. ML         \n                                                       algorithms analyze student \n                                                       responses to these         \n                                                       questions and generate     \n                                                       personalized career        \n                                                       recommendations based on   \n                                                       their performance.         \n           The study employing machine learning for career assessment lacks the personalized and\n           dynamic approach that the Career Compass, proposed by its proponents, will offer. While the\n           ML-based expert system administers standardized questions to assess student capabilities, it\n           may overlook the nuanced and evolving needs of individual students.    \n           In contrast, the Career Compass will incorporate a personalized feedback loop mechanism,\n           continuously adapting to each student\'s preferences, grade per subject, and aspirations.\n           Additionally, the ML approach (study being referred to) may solely focus on academic\n           performance in subjects like mathematics and physics, neglecting other crucial factors such as\n           students\' interests.                                                   \n           The Career Compass, on the other hand, will employ a holistic approach, considering a wide\n           range of factors to provide comprehensive career guidance tailored to each student\'s unique\n           profile.                                                               \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                  Links and References:                           \n                                                                                  \n                                                                                  \n          The growing importance of career guidance. (2023, March 1). The Economic Times.\n          https://economictimes.indiatimes.com/nri/work/the-growing-importance-of-career-\n          guidance/articleshow/98328216.cms                                       \n                                                                                  \n                                                                                  \n          Richards, E. (2023, May 10). Advantages of On-The-Job Training for Students.\n          https://trainingmag.com/advantages-of-on-the-job-training-for-students/ \n                                                                                  \n                                                                                  \n                                                                                  \n          Basic Facts on the DepEd National Career Assessment Examination (NCAE) • DepEd Tambayan.\n          (2018, December 7). Depedtambayan.net. https://depedtambayan.net/national-career-assessment-\n          examination/                                                            \n                                                                                  \n                                                                                  \n          José-García, A., Sneyd, A., Melro, A., Ollagnier, A., Tarling, G., Zhang, H., Stevenson, M., Everson, R.,\n          & Arthur, R. (2022). C3-IoC: A Career Guidance System for Assessing Student Skills using Machine\n          Learning and Network Visualisation. International Journal of Artificial Intelligence in Education.\n          https://doi.org/10.1007/s40593-022-00317-y                              \n                                                                                  \n                                                                                  \n          Sugano, S. G. C., & Mamolo, L. A. (2021). Analysis of Students’ Aptitude and Academic Performance:\n          Input to Curriculum Enhancement. Anatolian Journal of Education, 6(2), 51–62.\n          https://doi.org/10.29333/aje.2021.625a                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Machine learning approach for student career assessment in the modern world:\n          https://www.ijrte.org/wp-content/uploads/papers/v7i6s/F03370376S19.pdf  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              A\\n. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    P\\nroject Title: Career Compass: Personalized Career Guidance System for Laguna Senior High \\nSchool (LSHS) Students through the use of NLP, Machine Learning and Data Analytics\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       T\\nopic: Natural Language Processing, Machine Learning, Senior High School Students, Career \\nGuidance System\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    P\\nroponent: JAREEN PIA B. ANDRES,  EDRIAN B. FLORES, ANDREL JOHN M. \\nPANTANOZA\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          B\\n. Technical Description\n6  T\\n  T\\n  C\\n  T\\n  A\\n  A\\nhe  current  status  of  employment  in  today\'s  date  has  been  shown  as  a  competitive  global \\neconomy, it is paramount for students to make well-informed decisions regarding their career \\npaths, especially with the growing opportunities for overseas education. While studying abroad \\noffers  numerous  avenues  for  personal  and  professional  growth,  it  can  also  pose  challenges, \\nparticularly for students grappling with uncertainty about their future endeavors. \\nhis is where the significance of career guidance becomes evident. Career guidance plays a \\npivotal role in assisting students in comprehending their individual strengths, weaknesses, and \\ninterests, thereby providing them with a clearer understanding of the diverse career avenues \\navailable. Through tailored guidance, students gain insights into various industries, job roles, \\nand the requisite skills and qualifications essential for success in their chosen fields (Bhargava, \\nP. 2023, March 01) . \\nurrently, a mandatory exam called the National Career Assessment Examination (NCAE) is \\nbeing implemented for grade 9 students nationwide. The NCAE is an aptitude test designed to \\nprovide information for self-assessment, career awareness, and guidance for high school \\nstudents as they prepare for their post-secondary courses or apply for scholarships (DEPED \\nBohol, 2013). \\nhe primary objective of the NCAE is to bridge the gap between student skillsets and the \\nrequirements of the labor market. By identifying aptitudes in distinct areas, students can be \\nguided toward appropriate Senior High School (SHS) tracks and prospective careers that align \\nwith the Philippines\' workforce enhancement efforts (DEPED Bohol, 2013). \\ns per DepEdTambayan.com, the results of the NCAE are purely suggestive, without any \\nprescribed cut-off score. The generated results regarding the Senior High School Track are not \\nmandatory for students to participate in. \\ndditionally, the importance of thorough career guidance extends to: \\nProviding students with the opportunity to explore/navigate on their own:\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n0  T\\n  A\\n  C\\n  O\\nOffering students the chance to explore and navigate on their own is crucial. While \\nguidance is essential, it\'s important not to impose restrictions, as each individual is unique in \\nvarious aspects. Allowing them to explore independently ensures a personalized approach \\ntailored to their specific needs and interests, as well as their strength, weakness and other \\ncharacteristics. \\nracking career trajectories: \\nWith numerous options and opportunities available, it can be challenging to monitor one\'s \\ncareer path. Similar to regular health check-ups, maintaining consistent communication with a \\ncareer counselor at predetermined intervals can assist students in confirming they are \\nadvancing in the correct career path. \\nddressing the influence of misinformation: \\nToday, one of the major hurdles students encounter is parental influence on their career \\ndecisions. While parents often aim to guide their children towards what they perceive as the \\nideal career, their notions may not always align with the child\'s aspirations or the evolving job \\nmarket. Moreover, with careers constantly evolving and numerous options available, it\'s crucial \\nfor both students and parents to stay informed about changing trends to make informed \\ndecisions. \\norrecting career expectations: \\nWe must recognize that careers have their limitations and boundaries. It\'s essential to assess \\nthe scope of a career path and explore potential avenues available presently and in the future. \\nBefore committing to a university course, students should consider how it aligns with their \\nprofessional aspirations. While we cannot predict all potential changes, we can evaluate the \\nviability of a profession based on current trends and insights into the industry\'s landscape. \\nMitigating, if not eliminating, uncertainty: \\nne of the biggest issues for students in their college years is their uncertainty with their \\ncurrent course, especially at times when they are facing hardships. They tend to consider \\nshifting to another course or in worst case scenarios, they choose to drop out as they lack \\nmotivation since their judgment is clouded by uncertainty.\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 S\\n   \\ntatement \\nof \\nthe \\nProblem: \\n     The  Career  Compass  project  seeks  to  address  the  prevalent  gap  in  senior  high  school \\nstudents\'  understanding  of  suitable  curriculum  choices  in  alignment  with  their  future  career \\naspirations. Despite the importance of this decision, students often lack access to personalized \\nguidance, leading to confusion and uncertainty regarding their educational paths. \\n \\n1.  How can the Career Compass system effectively utilize machine learning algorithms to \\nclassify  and  analyze  students\'  skills,  and  knowledge  per  particular  subjects,  thereby \\nproviding personalized career recommendations? \\n \\n2.  What  data  preprocessing  techniques  can  be  implemented  within  the  Career  Compass \\nsystem to optimize the accuracy and reliability of the training dataset, ensuring that it \\nadequately \\nrepresents \\nstudents\'  diverse  backgrounds \\nand \\ncareer \\naspirations \\nand \\nalignment?\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                3. \\nIn what ways can data analytics, and NLP be integrated into the Career Compass system \\nto  forecast/show  the  outline  for  College  courses  and  future  job  trends  and  industry \\ndemands, enabling timely and relevant career recommendations for senior high school \\nstudents? \\n \\n4.  Will  the  Career  Compass  system  have  access  to  existing  datasets  for  training  and \\nvalidation, or will it need to collect and curate new datasets to ensure the effectiveness \\nand reliability of its career guidance functionalities? \\n \\n5.  How accurately and reliably can the Career Compass system leverage the combination \\nof machine learning and nlp to provide tailored career guidance to senior high school \\nstudents, and what metrics will be utilized to evaluate its performance and effectiveness \\nin addressing students\' needs and aspirations?\n1  S\\nObjectives: General and Specific General Objective: \\nThe main objective of this study is to design and develop a robust machine learning model that \\nutilizes algorithms to classify students\' interests, skills, and preferences, non-technical skills \\n(strength and weaknesses) along with suitable course alignment starting from their SHS up till \\nCollege courses and Job target interest. \\npecifically, it aims to: \\n  \\n1.  Gather relevant datasets, including students’ academic performance, and industry \\nbased data, to train and validate the machine learning model for accurate career \\nalignment suggestions. \\n \\n● \\nStudent based Dataset: Will be provided by  Laguna Senior High School  \\n \\n● \\nIndustry based Dataset: Online resources and references will be utilized. \\n \\n2. \\nImplement data preprocessing techniques to enhance the quality and reliability of the \\ntraining dataset, ensuring it adequately represents students\' diverse backgrounds and \\ncareer aspirations. \\n \\n●  Natural Language Processing Techniques: \\n-Data Cleaning \\n-Feature Selection and Categorization \\n-Encoding Categorical Variables \\n-Data Normalization \\n-Exploratory Data Analysis \\n-Validation \\n \\n3. \\nIntegrate data analytics tools to analyze job market trends and industry demands, \\nenabling the system to provide timely and relevant career recommendations. \\n \\n●  Data Analysis Techniques \\n● \\nJob Market Analysis \\n● \\nIndustry Demand Analysis\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      H\\n4.  Design and develop a user-friendly web-based system that serves as a platform for \\nsenior high school students to access personalized career guidance based on their \\nindividual profiles and preferences. \\n \\n●  Development of a web-based system to enable easier access for students or \\ninstitutes. As suggested through a preliminary interview with an expert in the \\nfield of education.\n1  T\\n  D\\n  B\\now did others solve the problem? \\n \\n1.  NCAE \\nproposed \\nsolutions \\n(Teacherph.com, \\n2016):  \\nhe  NCAE  offers  a  standardized  assessment  that  evaluates  students\'  aptitudes  and \\ninterests  across  various  occupational  areas.  This  approach  provides  a  more  objective \\nevaluation compared to solely relying on student preferences or anecdotal observations. \\nata-driven recommendations are provided based on the NCAE results, offering students \\nguidance  on  suitable  Senior  High  School  (SHS)  tracks  that  align  with  their  assessed \\nstrengths and interests. \\ny  combining \\nthe  NCAE \\nresults  with  guidance  counselor  support,  students  are \\nempowered to make more informed decisions about their future education and career \\npaths. \\n \\n2. \\nImplementation of OJT on Select Colleges in Quezon City (Hebron, D., September \\n2020)  \\nThe advantages of On-the-Job Training (OJT) for students serve as a crucial bridge \\nbetween academic learning and professional readiness. OJT accelerates skill \\ndevelopment, instills confidence, and fosters a sense of belonging within the \\nworkplace. By immersing students in real-world scenarios, OJT equips them with \\nindustry-specific knowledge and practical experience. Moreover, OJT enhances growth \\nopportunities by providing tailored feedback and preparing students to handle \\nunforeseen challenges effectively. Despite some challenges encountered during OJT, \\nsuch as inadequate equipment or labor-intensive tasks, the overall experience \\nempowers students to develop essential skills, adapt to change, and formulate realistic \\ncareer plans \\nOther Related Study (data gathering and machine learning methods) \\n \\n1.  Guidance \\ninterview \\nwith \\na \\ncareers’ \\nadviser \\n(University \\nof \\nKent) \\nThe  data  gathering  is  characterized  by  its  impartial,  confidential,  challenging,  and \\nsupportive nature. Careers advisers provide objective exploration without bias, maintain \\nconfidentiality, and challenge your goals to ensure thorough consideration. Additionally, \\nthe  process  is  supportive,  offering  a  safe  environment  for  discussion  as  privacy  is\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0 1                                               2 3 4\n0  T\\nindustry. Users can then input their skills and refine their profiles using visualizations \\nsuch as radar charts, facilitating a personalized assessment of their strengths and \\nweaknesses. The system further aids users in exploring job roles through network \\nvisualizations, allowing them to visualize their placement in the IT job role space based \\non their skill profiles. Overall, the C3-IoC system serves as a valuable tool for \\nempowering students to make informed decisions about their career paths within the \\ndynamic landscape of the IT job market. \\n \\nTheoretical Framework: \\nFigure 1. C3-IoC: A Career Guidance System for Assessing Student Skills using Machine \\nLearning and Network Visualisation (José-García, A., et al. (2023). C3-IoC: Career \\nThe current C3-IoC system aims to offer personalized career exploration and facilitate users\' \\nunderstanding of both technical and non-technical skills essential for IT sector careers. While \\nprimarily focusing on IT, the system also includes information on various job roles to cater to \\nusers outside this sector. \\nhe system architecture comprises three main modules: a knowledge base of skills and job \\nroles, a user skill profiling module, and a personalized job role matching and visualization \\nmodule. The user journey involves three stages: initial extraction of skills through a CV parser \\nand questionnaire, refinement of skill profiles, and exploration of job roles through network \\nvisualization.                                                      \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Guidance System. Journal Name, 33, 1092–1119.)    \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0\n0  P\\n  S\\n  C\\narents: \\nParents will benefit from increased confidence in their children\'s future prospects, as well as \\naccess  to  resources  based  on  facts  and  support  for  guiding  their  children  through  the  career \\nexploration process. \\nchools: \\nEducational institutions can enhance student engagement and retention by integrating the Career \\nCompass  system  into  their  existing  platforms,  providing  tailored career  guidance  and  course \\nrecommendations  to  students  based  on  their  interests  and  aspirations.  This  implementation \\nsupports  more  informed  curriculum  planning,  aligning  educational  offerings  with  students\' \\ncareer goals and fostering a more supportive learning environment. \\nompanies:  \\nEmployers  will  benefit  from  a  more  skilled  and  prepared  workforce,  leading  to  improved \\nrecruitment outcomes and reduced skill gaps in the job market.\n1                                                                                                                                                                                        T\\nSignificance of study: \\nhe Career Compass project is significant due to its help targeted to senior high school \\nstudents at Laguna Senior High School in the Philippines in terms of planning for their future \\ncareers. This system uses technology to give students personalized advice on which courses to \\ntake and which careers might suit them best. It\'s important as it helps students make better \\nchoices about their education and future jobs. Additionally, it supports schools by providing \\nthem with a helpful tool to assist their students in career planning. Ultimately, Career Compass \\naims to assist students to make informed decisions and achieve success in their academic and \\nprofessional lives in the long run.\n\n                                                                                                                                                               0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2     3\n0                                                                                                                  TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n1                                                                                                                                             TECHNOLOGY: C3 IoC                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n2  C3-IoC: A Career \\nGuidance System for \\nAssessing Student \\nSkills using Machine \\nLearning and \\nNetwork Visualisation \\n(José-García, A., et \\nal., 2023).  A\\nThe C3-IoC stands as a pioneering solution \\nin  the  realm  of  career  guidance  systems, \\nspecifically tailored to empower students in \\nnavigating  the  complex  landscape  of  the \\nInformation \\nTechnology \\n(IT) \\nsector. \\nRooted \\nin \\nthe \\nprinciples \\nof  Artificial \\nIntelligence (AI), this system revolutionizes \\nthe \\ntraditional \\napproach \\nto \\ncareer \\nexploration  by  offering  a  comprehensive \\nsuite  of \\ntools \\nand \\nresources \\naimed \\nat \\nequipping  users  with  the  knowledge  and \\ninsights needed to make informed decisions \\nabout their professional trajectories. \\nt its core, the C3-IoC endeavors to bridge \\nthe gap between educational attainment and \\nindustry demands within the IT sector. By \\nharnessing  advanced  AI  technologies,  the \\nsystem facilitates the seamless alignment of \\nusers\' skills, qualifications, and aspirations \\nwith \\nthe  dynamic \\njob  market \\nlandscape. \\nThrough  an \\ninnovative  similarity  metric \\nmethod, the C3-IoC establishes meaningful \\nconnections between existing job roles and  T\\n   \\nC3-IoC career assessment \\nsystem specific for the IT \\nsector. \\nhe scope of the C3-IoC \\nextends across the vast expanse \\nof the IT sector, encompassing \\ndiverse domains ranging from \\nsoftware development and data \\nanalytics to cybersecurity and \\ncloud computing. \\nLeveraging a wealth of data \\nsources, including job \\nadvertisements and established \\nskill databases such as O*NET, \\nthe system curates a rich \\nrepository of job roles and \\nassociated skill requirements \\ntailored to the ever-evolving \\nlandscape of the IT industry.  2022\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                             a  diverse \\nrange  of \\ntechnical \\nand  non-\\ntechnical skills, thus enabling users to gain \\ndeeper  insights  into  the  skillsets  required \\nfor various positions.\n1  I\\nPresented above, the C3- IoC is a system created for a career assessment system specific for the \\nIT sector, with the same goal of bridging lacking knowledge between educational attainment \\nand industry demands within the IT sector as aforementioned before.  \\nn the proposed study of Career Compass, the goal is to develop a system where it is not just \\nlimited to a particular sector, but instead focused on career alignment and job trends specific \\nwithin the country. It aims for a comprehensive line up of career alignment starting from College \\ncourse to take > Aligned Job > Respective up to date salary estimate.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       TECHNOLOGY: Data Analytics in the context of NLP                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Analysis of Students’ \\nAptitude and \\nAcademic \\nPerformance:  \\nInput to Curriculum  \\nEnhancement \\n(Sugano, S. G. C., & \\nMamolo, L. A. and  \\nShalom Grace C. \\nSugano., 2021 )  T\\n   \\nThis  study  delved  into  the  correlation  between  student \\naptitude  and  academic  performance  among  Grade  10 \\nstudents,  leveraging  data  analytics  techniques  to  glean \\ninsights \\nfrom \\nthe \\nNational \\nCareer \\nAssessment \\nExamination  (NCAE)  results.  The  analysis  encompassed \\nthree \\ndomains:  General \\nScholastic  Ability \\n(GSA), \\nTechnical-Vocational  Aptitude \\n(TVA),  and  Academic \\nTrack (AT), shedding light on students\' proficiency levels \\nacross various aptitude areas. \\nhis study applied data analytics techniques to analyze the \\ncorrelation \\nbetween \\nstudent \\naptitude \\nand \\nacademic \\nperformance  among  Grade  10  students,  with  a  specific \\nfocus  on \\ninsights  derived \\nfrom \\nthe  National  Career \\nAssessment  Examination  (NCAE)  data.  By \\nleveraging \\nadvanced analytical methods, the research aimed to extract \\nvaluable insights into students\' aptitude levels and career \\npreferences.  D\\n  C\\n  P\\nData preprocessing: \\nCleaning, filtering, and \\norganizing the NCAE \\ndataset to ensure data \\nquality and consistency. \\nescriptive analytics: \\nUtilizing statistical \\nmethods to summarize and \\ndescribe key \\ncharacteristics and trends \\nwithin the dataset. \\norrelation analysis: \\nInvestigating relationships \\nbetween variables such as \\nstudent aptitude levels and \\nacademic performance \\nmetrics. \\nredictive analytics: \\nEmploying predictive \\nmodeling techniques to \\nforecast future academic \\noutcomes based on \\nhistorical data patterns.  2021\n3  I\\n  I\\nWhile the aforementioned study provides valuable insights into the relationship between student \\naptitude and academic performance using data analytics, it may lack a comprehensive approach \\nto career guidance and decision-making. The study primarily focuses on analyzing existing data \\nto  understand  correlations  between  aptitude  and  academic  performance  but  may  not  offer \\npersonalized guidance or actionable recommendations for individual students. \\nn  contrast,  the  Career  Compass  aims  to  address  this  gap  by  offering  a  personalized  and \\ninteractive  platform  for  students  to  explore  various  career  paths  based  on  their interests  and \\ngrade per subject. Additionally, the Career Compass incorporates elements of self-assessment \\nand reflection, allowing students to actively engage in the career exploration process and make \\ninformed decisions about their academic and professional futures. \\nt is also notable that the aforementioned study regarding NCAE does not provide visualizations \\nfor the results while the Career Compass does.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Technology: Machine Learning in Career Assessment                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Machine learning \\napproach for student \\ncareer  \\nassessment in the \\nmodern world \\n \\n( Sai Kuswanth, V., \\nGogineni Krishna \\nChaitanya, B., Sekhar \\nBabu, B., & Uppuluri \\nLakshmi \\nSoundharya., 2019, \\nMarch)  The study explores the application of machine learning \\n(ML) in career assessment for students transitioning from \\nsecondary school to higher education. It addresses the \\nchallenge of students not knowing how to choose their \\nacademic career and the importance of assessing their \\ncapabilities in subjects like mathematics and physics. \\nTraditionally, this assessment was done manually by \\ncounselors, but in the modern world, an expert system \\nemploying ML techniques is utilized. This expert system \\npresents students with questions to assess their \\ncapabilities and performance, allowing for more efficient \\nand objective career assessment. ML is described as a set \\nof artificial intelligence techniques that enable computers \\nto \"learn\" from data without being explicitly programmed. \\nIt involves training a model using past data to make \\npredictions or decisions on new, unseen data. ML is \\nparticularly useful in scenarios where designing specific \\nalgorithms with high performance is challenging or \\ninfeasible, such as email filtering, network intrusion \\ndetection, and optical character recognition. In the context \\nof career assessment, ML helps in analyzing student data \\nand making informed suggestions for suitable career paths \\nbased on their performance and capabilities in relevant \\nsubjects. The study emphasizes the importance of data-\\ndriven approaches in handling various types of data and \\nhighlights ML as a valuable tool for transforming the \\ntraditional approach to career assessment.  M\\n  T\\n  T\\nachine Learning \\nhe study focuses on \\nutilizing machine learning \\n(ML) techniques to address \\nthe challenge of career \\nassessment among \\nsecondary school students \\ntransitioning to higher \\neducation. It involves \\ndeveloping an expert \\nsystem that automates the \\nassessment process, aiming \\nto provide efficient and \\nobjective evaluations of \\nstudents\' capabilities and \\nperformance. \\nhrough the expert system, \\nstudents are presented with \\nquestions designed to \\nassess their abilities and \\ninterests, particularly in \\nsubjects like mathematics \\nand physics, which are \\ncrucial for academic and \\ncareer success. ML \\nalgorithms analyze student \\nresponses to these \\nquestions and generate \\npersonalized career \\nrecommendations based on \\ntheir performance.  2019\n3  T\\n   \\n   \\nhe study employing machine learning for career assessment lacks the personalized and \\ndynamic approach that the Career Compass, proposed by its proponents, will offer. While the \\nML-based expert system administers standardized questions to assess student capabilities, it \\nmay overlook the nuanced and evolving needs of individual students. \\nIn contrast, the Career Compass will incorporate a personalized feedback loop mechanism, \\ncontinuously adapting to each student\'s preferences, grade per subject, and aspirations. \\nAdditionally, the ML approach (study being referred to) may solely focus on academic \\nperformance in subjects like mathematics and physics, neglecting other crucial factors such as \\nstudents\' interests. \\nThe Career Compass, on the other hand, will employ a holistic approach, considering a wide \\nrange of factors to provide comprehensive career guidance tailored to each student\'s unique \\nprofile.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ', 'hello testing\nhello\nhello\ncareer campus personalized career guidance system for laguna senior high school students\n', '{\"status\": \"success\", \"speech_similarity\": 74.48, \"missed_keypoints\": [\"career student\", \"career planning\", \"learning career\", \"guidance career\", \"career plans\"], \"added_keypoints\": [\"career campus\", \"hello career\", \"guidance laguna\", \"laguna senior\", \"personalized career\"], \"suggested_titles\": [\"Analysis of Careers in Research Context\", \"Analysis of Career in Research Context\", \"Analysis of Vocational in Research Context\"]}', 0);
INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(101, 'janeeeeverdad@gmail.com', 'NEWG1.PDF', 'uploads/c135e9d96d31457ea0da9cb7e88a2230.PDF', '2025-04-24 07:32:00', '                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                     Concept Paper                                  \n                                                                                    \n           A. BasicInformation                                                      \n                                                                                    \n           Project Title:                                                           \n           GreeneryRecognition and ObservationOptimization Tool(GROOT): A MobileApplication\n           for DigitalIdentificationof MajorPests andDiseasesin SelectedIndigenousTreesinSta.\n           Maria,Laguna                                                             \n                                                                                    \n           Topic: ComputerVision, Forestry                                          \n                                                                                    \n           Proponent:DELA CRUZ, ARIANEJOYM. |GONZALODO, PAUL JOSHUAF.               \n           VILLADIEGO, TRISH P.                                                     \n                                                                                    \n                                                                                    \n           B.Technical Description                                                  \n                                                                                    \n                                                                                    \n           An application that is easier and gives information about pests and diseases in selected\n           indigenous trees (Almon, Mayapis, Narra, Tanguile, and White Lauan). The present manual\n           methods, such physical observation and pen and paper recording. To improve their current\n           process, our answer is a portable gadget or user-friendly mobile application with a large\n           database and cutting-edge picture recognition technology. By facilitating rapid species\n           detection and offering comprehensive information on illnesses and pests, this application\n           completely transforms the identification of major pests and diseases in selected indigenous\n           trees.                                                                   \n                                                                                    \n           By scanning bark or foliage, users can access vital information, enhancing monitoring efforts\n           and fosteringastronger connection withnature.Thisinnovationbenefits forestryprofessionals\n                                                                                    \n           by improving workflows and enriches forestry education for students. The application offers\n           detailed profiles of trees, including common and scientific names, habitats, growth patterns,\n           and ecological significance. It also diagnoses pests and diseases, offering management and\n           treatment recommendations.                                               \n                                                                                    \n           Through technology and environmental administration, we empower communities to protect\n           local woodlands and support conservation efforts, leading the way for a more sustainable\n           future.                                                                  \n                                                                                    \n                                                                                    \n           Statement of the Problem:                                                \n                                                                                    \n           To address the challenges faced by the Department of Environment and Natural Resources\n           (DENR) in effectively monitoring and preservingtree species,especiallyinthe contextoftree\n           cutting activities and ecosystem conservation, we proposed the development of a specialized\n           application by virtualizing the recordingprocess andintegratingtechnical termsto identifythe\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           signs andsymptoms of pests, anddiseases inselected indigenoustrees.This studywill address\n           thefollowing:                                                            \n                                                                                    \n             1. What arethecommonpestsinforest plantation treesinSanta Maria,Laguna?\n                                                                                    \n             2. What arethecommondiseases offorest plantation treesinSanta Maria,Laguna?\n             3. What applicationisused toidentifycommon pestsanddiseases?           \n             4. Howcantheapplicationprovideassistance onidentifyingmajor pestsanddiseases?\n             5. Howeffective GROOTapplication inidentifying the majorpestsanddiseases in\n                selected indigenous treesin SantaMaria, Laguna?                     \n                                                                                    \n                                                                                    \n           Objectives: GeneralandSpecific GeneralObjective:                         \n           This studyisambitiousandhas thepotential tobeagame-changer for forestry,ecology,and\n           evencitizenscience.Thegoalis todevelop auser-friendlyapplication toeasilyidentify major\n           pestsand diseasesin selectedindigenoustrees inSta.Maria, Laguna.         \n                                                                                    \n           Specifically,it aimsto:                                                  \n                                                                                    \n             1. Collect imagesshowcasingcommon pestsaffectingthespecifiedtree specieslike,\n                Ambrosia Beetle,Ips Calligraphus,Lymantria, andTeakDefoliator Mealybug,\n                showcasingdifferentstages ofinfestationand associateddamagefromERDBand\n                                                                                    \n                CFNR.                                                               \n             2. Collect imagesshowcasingcommon diseases affectingthespecifiedtreespecies like\n                leaf blight,leaf spot, powderymildew, gall rust,andblack raydisease fromERDB and\n                CFNR.                                                               \n                                                                                    \n             3. Developan application thatutilizes YOLO,apre-trained Convolutional Neural\n                Network,for advanced objectdetectionandrecognition.                 \n             4. Developa mobileapplication thatwouldprovidea platform toidentifymajor pestsand\n                diseases inselected indigenoustreesthrough the datagathered.        \n             5. Determine theaccuracyof theoutput ofthe imageprocessingmodel.       \n           Howdid otherssolvethe problem?                                           \n             1. Theresearchers addressedthe problemofbark identification byutilizinga combination\n                of techniques. They applied random square cropping with thresholding to the images\n                before inputting them into the convolutional neural networks (CNNs). This approach\n                involved randomly selecting a pixel length in the range of 40-60% of the total width\n                                                                                    \n                for each crop, and then randomly sampling the position of the cropping square.\n                Additionally, they used a data augmentation process called \'RandAugment\' to increase\n                the training data by giving slight modifications. This involved randomly selecting a\n                predefined number of augmentation functions and applying them with a randomly\n                sampled magnitude from a predefined range. These techniques aimed to minimize the\n                loss of bark features, provide flexible cropping,andincreasethe trainingdata for more\n                robust model training.The researchers addressed the problem of bark identification by\n                                                                                    \n                utilizing a combination of techniques. They applied random square cropping with\n                thresholding to the images before inputting them into the convolutional neural\n                networks (CNNs). This approach involved randomly selecting a pixel length in the\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                range of 40-60% of the total width for each crop, and then randomly sampling the\n                                                                                    \n                position of the cropping square. Additionally, they used a data augmentation process\n                called \'RandAugment\' to increase the training data bygiving slightmodifications.This\n                involved randomly selecting a predefined number of augmentation functions and\n                applying them with a randomly sampled magnitude from a predefined range. These\n                techniques aimed to minimize the loss of bark features, provide flexible cropping,and\n                increase the training data for morerobustmodel training.Kim,T. K., Hong, J.,Ryu,D.,\n                Kim, S., Byeon, S. Y., Huh, W., ... & Kim, H. S. (2022). Identifying and extracting\n                                                                                    \n                bark key features of 42 tree species using convolutional neural networks and class\n                activation mapping. Scientific Reports,12(1), 772.4                 \n             2. Researchers utilized threevisualizationmethodsto tacklethechallenge ofvisualizing\n                thecorrelationbetween treebark characteristicsandthe mechanismsofdeep\n                convolutionalneural networks.Firstly,theyemployedIntegrated Gradients,which\n                attributes adeepnetwork\'sprojection toits input byinvokingthe gradientoperator,\n                offering awidelyapplicableapproach withastrongtheoretical foundation.Secondly,\n                Smooth GradCAM++ combinedwithGrad-CAM andSmoothGrad wasutilized,    \n                modelingand visualizingasubsetof featuremaps orneuronsat eachneural network\n                level.This technique producedhierarchicalfeatureseffectivelyincorporating visual\n                appeal,localization,and object-likecaptureelements inthe outputvisualization.\n                Lastly,Deep FeatureDecomposition providedinsightintoclusteringpatterns inthe\n                featurespace,presenting results asheat maps. Itsobjectivewasto explainthe\n                                                                                    \n                predictionsof deepconvolutional neuralnetworksbyhighlightingthe contributing\n                regions or features.These visualizationmethodscollectivelyshed lightonthe\n                correlationbetweenthe biologicalcharacteristicsof varioustreespecies andthe visual\n                mechanismsof deepconvolutional neuralnetworks,offering valuableinsightsinto the\n                intricate relationship betweennatural patterns andmachinelearning processes.Cui,Z.,\n                Li, X., Li, T.,& Li, M.(2023). Improvementand Assessmentof Convolutional Neural\n                Networkfor Tree SpeciesIdentificationBased onBarkCharacteristics.Forests,14(7),\n                1292.                                                               \n             3. Theresearchers solvedthe problemofestimatingtree diameterandcircumference\n                usingcomputervision (CV)technologybydevelopinganon-contact tree     \n                circumferencemonitoring system.Theyutilized asmartphone camera incorporated\n                with CVtechnology asanalternative low-costtool. Thesystemwasdesignedto\n                accelerate andincreasethe effectivenessandefficiencyinmeasuring treediameterand\n                circumferencewithin plantation areas.Thestudy focusedonhomogeneousforests,\n                suchasrubber and Albiziaplantations,and utilizedadvancedtechnologytoachieve\n                proper identification,tracking, andmeasurementof treetargets for further image\n                processing. Theresearchershypothesized thatthe useof CVtechnologycan providean\n                                                                                    \n                effective andefficient solutionfor measuring treediameterandcircumference in\n                plantationareas.Putra, B.T. W.,Ramadhani, N. J.,Soedibyo,D. W.,Marhaenanto,B.,\n                Indarto, I., & Yualianto, Y.(2021). Theuse ofcomputer vision toestimatetree\n                diameterand circumference inhomogeneousandproduction forestsusinga  \n                non-contact method. ForestScience andTechnology,17(1), 32-38.       \n             4. Theresearchers addressedthe issueofclassimbalance intheir datasetbyallowing\n                considerable overlap betweenpatches for classeswith fewerimages.Thisapproach,\n                known asminority classoversampling,has beenshowntobe effectivefor training\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                Convolutional Neural Networks (CNNs)inthe presenceof classimbalance.\n                Additionally,theycreateda datasettotrain andevaluatethe genus-levelclassifierby\n                                                                                    \n                taking asubsetof training andtesting patchesinsuch awaythat thespecies image\n                proportions withina genuswere respected.Thisensuredthat the modelwas trainedand\n                evaluatedwith abalancedrepresentationof specieswithin each genus.Ravindran,P.,\n                Costa, A.,Soares,R., &Wiedenhoeft,A. C. (2018). Classificationof CITES-listed and\n                otherneotropicalMeliaceaewood imagesusing convolutionalneural networks.Plant\n                methods,14,1-10.                                                    \n                                                                                    \n             5. Theresearchers solvedthe problembyadopting animage-capturingprocedure froma\n                previous studyandcapturing 20scenesfrompoints at18º intervalsalong concentric\n                circular pathsaround thetree trunk.Theyensured aminimumof 50%coverage\n                between anysequential pairofimages andusedred flagtapestomarkthe locationsof\n                pictures takenalongthe circularpath.Additionally,they set thedistance betweenthe\n                photo point andthe treetrunk to2mandcalibrated thecamera elevationat each photo\n                point usinga measuringstaff. Theyalsoprinted andinstalled 16-bit digitmarkerson\n                theedgeof thetreetrunk tooptimize thephoto alignmentprogress. Furthermore,they\n                measured individualtreeDBH(diameter atbreast height)using acaliper at18°\n                intervalsalongconcentric circularpaths aroundthe treetrunk tovalidate the3D\n                reconstruction fittingalgorithms.The2D imageswere alignedusing Agisoft\n                Metashape Professional,anda densepoint cloudwas generated.Theextracted3D\n                                                                                    \n                point clouddata were processedusing ahigh-performance computingsystem,andthe\n                processtook around 20minutesfor each treemeasurement.Woo, H.,Kim, I.,&Choi,\n                B.(2021). ComputerVision Techniquesin ForestInventoryAssessment:Improving\n                Accuracy of TreeDiameterMeasurement UsingSmartphoneCameraand        \n                Photogrammetry.Sensors&Materials, 33.                               \n                                                                                    \n             6. Theresearchers solvedthe problemofpest detection throughimageanalysis by\n                conductingexperimentsin paddyfieldsusing anetwork ofwireless camerasandsticky\n                traps tocaptureinsectpests.Theythen processed thecaptured imagesusinga local\n                machine equippedwithan Inteli3processorand4GB RAM.Thearchitecturaldesign\n                of theproposedsystemwas crucialin facilitatingthe imageacquisition and\n                pre-processing.Theresearchersalso utilized imagepre-processingtechniquesto\n                convert RGBimagesinto grayscaleimages,making themethod moreefficient.\n                Additionally,theyemployed adetectionmechanism that comparedthe pixel valuesof\n                successivecaptured imagestodetectdifferences andidentify insectpests.Miranda, J.\n                L., Gerardo,B.D.,& TanguiligIII,B. T.(2014). Pest detectionand extractionusing\n                imageprocessing techniques.Internationaljournal ofcomputer andcommunication\n                engineering,3(3), 189-192.                                          \n                                                                                    \n             7. Theresearchers addressedthe issuebycollectingadditional imagesof palmdiseases\n                usingdifferent cameras andat differenttimesof day,includingnighttimewithflash.\n                                                                                    \n                Theymanually croppedthe regionsof interestintheimages topreserveasmuch\n                information aspossible,andthen appliedimageaugmentation techniquessuch as\n                rotation, flipping, andbrightness adjustment, resultingin alargerdataset for each\n                disease.Theyalsoexperimented withdifferentclassificationalgorithmssuch as\n                LinearSVCfor the SupportVectorMachine (SVM)model, whichachieved a93%\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                accuracy rate.Additionally,they enhancedtheConvolutional NeuralNetwork(CNN)\n                model andconductedexperimentsto testthemodels\'ability todetectleafspots and\n                                                                                    \n                blight spotsdiseasesunder variouscircumstances.Alaa, H., Waleed,K., Samir,M.,\n                Tarek,M., Sobeah, H.,& Salam,M. A.(2020). An intelligentapproachfor detecting\n                palm treesdiseasesusing imageprocessingand machinelearning.Int. J.Adv.Comput.\n                Sci.Appl,11(7), 434-441.                                            \n                                                                                    \n                                                                                    \n           Howdo youintend to solvethe problem?                                     \n           A mobile application aims to revolutionize environmental management by identifying major\n                                                                                    \n           pests and diseases in selected Indigenous Trees. The application uses advanced image\n                                                                                    \n           recognition algorithms to provide insightsinto majorpestsanddiseases inselected indigenous\n           trees.Theapplication alsoserves asaplatform for community engagement,fosteringasenseof\n                                                                                    \n           ownershipand responsibility towardsenvironmentalconservation.            \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           Targetusers /Beneficiaries:(Describe eachBeneficiary)                    \n                                                                                    \n           This Study will bebeneficialfor Researchers, agriculturistandforester making it convenient\n           to major pestsand diseases inselected indigenoustrees providing insightsand moredetails\n           aboutthemajor pestsanddiseasesin selectedindigenoustrees.                \n                                                                                    \n                                                                                    \n           Significance of study:                                                   \n                                                                                    \n           Theproposedmobileapplicationsareanessentialapplication for bothcommon people and\n           environmental enthusiasts.It offers anextensive amountof informationregarding majorpests\n                                                                                    \n           and diseasesin selectedindigenoustrees, accommodatesarangeof learningstyles,and creates\n           afeeling of communityamongthose who sharesimilar interests.Thesoftware helps usersget\n           abetter knowledgeof theirrelationshipwith natureandtheirresponsibility asenvironmental\n           stewards,actingasa catalystfor personal developmentandself-discovery.    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n          SurveyMatrix                                                              \n                                                                                    \n           TitleofStudy        Purpose           Technology          Year           \n           Identifyingandextractingbark Thestudyinvestigatesthe convolutionalneuralnetworks 2022\n           keyfeaturesof42treespecies effectivenessofcomputer classactivationmapping\n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           usingconvolutionalneural visionmachinesinidentifying                     \n           networksandclassactivation treebarksusinglarge-scale                     \n           mapping             barkimagedatasets,comparing                          \n                               CNNalgorithms(VGG-16and                              \n                               EfficientNet)andidentifying                          \n                               diagnosticfeatures.                                  \n           ImprovementandAssessmentof Thestudyexploresthe convolutionalneuralnetworks 2023\n           ConvolutionalNeural relationshipbetweentreebark ConvNeXtnetwork          \n           NetworkforTreeSpecies characteristicsanddeep BarkNetV2                   \n           IdentificationBasedon convolutionalneuralnetworks,                       \n           BarkCharacteristics aimingtoimprovetreespecies                           \n                               identificationefficiencyand                          \n                               forestresourcemanagement.                            \n           ClassificationofCITES-listed Thepurposeofthestudywas computervisionclassification 2018\n           andother            todevelopacomputervision model                       \n           neotropicalMeliaceaewood classificationmodelusingdeep deepconvolutionalneural\n           imagesusing         convolutionalneuralnetworks networks                 \n           convolutionalneuralnetworks toidentifyneotropical                        \n                               Meliaceaewoodspecies.This                            \n                               wasaimedatprovidinga                                 \n                               reliable,consistent,and                              \n                               cost-effectivefieldscreening                         \n                               methodforeffectiveglobal                             \n                               scaleenforcementof                                   \n                               internationaltreatiessuchas                          \n                               theConventiononthe                                   \n                               InternationalTradein                                 \n                               EndangeredSpecies(CITES)                             \n                               ornationallawsgoverning                              \n                               timbertradeandimports.The                            \n                               studyfocusedon10                                     \n                               neotropicalspeciesinthe                              \n                               familyMeliaceae,including                            \n                               CITES-listedspecies,withthe                          \n                               goalofachievingspecies-level                         \n                               discrimination,whichis                               \n                               essentialforcombatingillegal                         \n                               loggingandensuringthe                                \n                               protectionofendangeredwood                           \n                               species.                                             \n           PestDetectionandExtraction Thepurposeofthestudyisto ImageProcessing 2014 \n           UsingImageProcessing developaninnovativedecision                         \n           Techniques          supportsystemforearlypest                            \n                               detectioninagriculturalfields.                       \n                               Theresearchersaimtouse                               \n                               imageanalysisandscene                                \n                               interpretationfrom                                   \n                               multi-cameradatatoidentify                           \n                               insectpestsinrealtime.The                            \n                               goalistoreducepesticideuse                           \n                               byenablingearlydetectionof                           \n                               pestsonplantorganssuchas                             \n                               leaves.Thestudyalsofocuses                           \n                               oncreatingasystemthatcan                             \n                               easilyadapttodifferent                               \n                               categoriesofbioaggressors,                           \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                               contributingtomoreefficient                          \n                               andsustainablepest                                   \n                               managementpracticesin                                \n                               agriculture.                                         \n           AnIntelligentApproachfor Thepurposeofthestudyisto Thermalimaging 2020    \n           DetectingPalmTrees  detectRedPalmWeevil ImageProcessing                  \n           DiseasesusingImageProcessing (RPW)infestationinpalm ConvolutionalNeuralNetwork\n           andMachine          treesusingthermalimaging. SupportVectorMachine       \n           Learning            Thestudyaimstouseuncooled MobileApplication          \n                               infraredthermalcamerasand                            \n                               microbolometersensorsto                              \n                               captureimagesofpalmtrees,                            \n                               analyzetheimagesusing                                \n                               softwaretoassesswaterstress                          \n                               andtemperaturerates,and                              \n                               identifyinfectedtreesbasedon                         \n                               theobserveddifferencesin                             \n                               temperatureandwaterstress.                           \n                               Thestudyalsoexplorestheuse                           \n                               ofmachinelearningmodels                              \n                               suchasSupportVector                                  \n                               Machines(SVM)and                                     \n                               ConvolutionalNeural                                  \n                               Networks(CNN)for                                     \n                               classificationanddetectionof                         \n                               RPWinfestationinpalmtrees.                           \n          Gap Analysis                                                              \n               TITLE            DESCRIPTION         SCOPE/TECHNOLOGY  YEAR          \n                                     TECHNOLOGY                                     \n           Identifyingand                          convolutionalneuralnetworks 2022 \n           extractingbarkkey The research delving into bark classactivationmapping  \n           featuresof42tree identification using convolutional neural               \n                         networks (CNNs) alongside class                            \n           speciesusing                                                             \n                         activation mapping (CAM) yieldedseveral                    \n           convolutionalneural                                                      \n                         significant findings. Firstly, CNNs                        \n           networks                                                                 \n                         exhibited remarkable proficiency in                        \n           andclassactivation                                                       \n                         identifying the barks of 42 distinct tree                  \n           mapping                                                                  \n                         species, achieving accuracy rates                          \n                         surpassing 90%. Notably, comparative                       \n                         analysis between the two employed CNN                      \n                         models, namely VGG-16andEfficientNet,                      \n                         revealed onlymarginalvariancesinoverall                    \n                         accuracy. The study identified diagnostic                  \n                         keys for each species, correlating them                    \n                         with distinct bark features such asblisters,               \n                         stripes, lenticels of various shapes, and                  \n                         crevices. Interestingly, the two CNN                       \n                         models demonstrated discrepancies in the                   \n                         quality of diagnostic features, with the                   \n                         older model presenting more general yet                    \n                         well-fitting patterns,whilethenewer,more                   \n                         intricate model indicatedlocalizedpatterns                 \n                         less pertinent to bark identification.                     \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                         Furthermore, CNNs showcased the                            \n                         capability to predict untrained species                    \n                         within the correct genus and family by                     \n                         approximately 41.98% and 48.67%,                           \n                         respectively. Thesefindingsunderscorethe                   \n                         potential of CNNs and CAM in not only                      \n                         accurately identifying and visualizing                     \n                         essential bark traits but also in their                    \n                         broaderapplicabilitytootherplantorgans.                    \n           Improvementand                          convolutionalneuralnetworks 2023 \n           Assessmentof  The study employed three distinct ConvNeXtnetwork          \n           Convolutional visualization methods, namely Integrated BarkNetV2         \n                         Gradients, Smooth Grad CAM++, and                          \n           Neural                                                                   \n                         Deep Feature Decomposition, to elucidate                   \n           NetworkforTree                                                           \n                         the network workflow. Through these                        \n           Species                                                                  \n                         methods, researchers identified specific                   \n           IdentificationBased                                                      \n                         features in tree bark images, including                    \n           on                                                                       \n                         grooves, cracks, and lenticels, which the                  \n           BarkCharacteristics neural networkweightsselectivelyfocused              \n                         on. This selective attention paralleled                    \n                         human recognitionoftreespeciesbasedon                      \n                         bark images, enhancing our understanding                   \n                         of the network\'s decision-making process.                  \n                         Moreover, the visualization results                        \n                         obtained through deep feature                              \n                         decomposition and semantic segmentation                    \n                         exhibited similarities,offeringinsightsinto                \n                         how the network identifies different tree                  \n                         species based on barkimageblocks.These                     \n                         findings underscored the correlation                       \n                         between the biological characteristics of                  \n                         diverse tree species and the visual                        \n                         mechanisms of deep convolutional neural                    \n                         networks, providing valuable insights into                 \n                         both the network\'s functioning and its                     \n                         relationship with natural features. Overall,               \n                         these outcomes shedlightontheprinciples                    \n                         and characteristics of the network                         \n                         workflow and its correlation with the                      \n                         biological features of tree species,                       \n                         advancing our understanding of both                        \n                         machine learning processes and natural                     \n                         phenomena.                                                 \n           Classificationof The study aimed to develop machine computervisionclassification 2018\n           CITES-listedandother learning models for wood identification model       \n           neotropicalMeliaceae based on images of transverse surfaces of deepconvolutionalneural\n           woodimagesusing wood specimens. The researcherscaptured networks         \n           convolutionalneural high-resolution images of wood                       \n           networks      specimens, annotated them for various                      \n                         characteristics, and then created a dataset                \n                         for training and testing the machine                       \n                         learning models. Theyspecificallyfocused                   \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                         on distinguishing between species-level                    \n                         and genus-level accuracy, recognizing the                  \n                         traditionallimitationofwoodidentification                  \n                         at the specieslevel.Thestudyinvolvedthe                    \n                         creation of patch datasets, training of                    \n                         convolutional neural network (CNN)                         \n                         models, and evaluation of the model                        \n                         accuracies. The models were trained using                  \n                         the VGG16 network as feature extractors                    \n                         and the custom top-level layers were                       \n                         trained using stochastic gradient descent                  \n                         and the Adam optimizer. The study also                     \n                         included thecreationofconfusionmatrices                    \n                         and training curves for the models to                      \n                         analyzetheerrorsmadebythemodels.                           \n           PestDetectionand The study presents the development of an ImageProcessing 2014\n           ExtractionUsing automatic detection and extraction system                \n           ImageProcessing for insectpestsinpaddyfieldsusingimage                   \n           Techniques    processingtechniques.Theauthorssetupa                      \n                         network of wireless cameras and sticky                     \n                         traps in the paddy fields to capture insect                \n                         pests. They used CISCO Linksys                             \n                         Wireless-G Internet Home Monitoring                        \n                         Cameras to capture images at 10 frames                     \n                         per second with 8-megapixel resolution.                    \n                         The captured images wereprocessedusing                     \n                         a local machine equipped with an Intel i3                  \n                         processorand4GBRAM.                                        \n                         The study utilized image pre-processing                    \n                         techniques toenhancethecapturedimages,                     \n                         including converting RGB images into                       \n                         grayscale using a specific formula. The                    \n                         authorsalsodevelopedanalgorithmforthe                      \n                         detection of pests in the images, involving                \n                         the extraction of isolated patterns of                     \n                         interestbasedonrobustfeatureextraction.                    \n                         The experimental results of the proposed                   \n                         system showed its efficiency in detecting                  \n                         and extracting insect pests in the paddy                   \n                         fields. The system was tested over five                    \n                         consecutive days, and the results of the                   \n                         detected images of different insect pests                  \n                         wererecordedandpresentedinatable.                          \n                         The study aims tocontributetothefieldof                    \n                         agricultural research byprovidingasimple                   \n                         yet efficient system for automatic pest                    \n                         detection and extraction using image                       \n                         processingtechniques.                                      \n           AnIntelligent Thestudyinvolvedtheuseofadataset Thermalimaging 2020       \n           ApproachforDetecting fromKagglecontaining91,360imagesfor ImageProcessing \n           PalmTrees     leafspotsandblightspotsdiseases.Dueto ConvolutionalNeuralNetwork\n                         thelowvariationintheimages,the SupportVectorMachine        \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n           DiseasesusingImage originalimageswereanalyzedbefore MobileApplication    \n           Processingand augmentation,resultingintheselectionof                     \n           Machine       35leafspotsimages,40imagesforblight                        \n           Learning      spots,and50morepalmimagesforeach                           \n                         disease.Theoriginalimageswere                              \n                         manuallycroppedtopreservetheinfected                       \n                         partsandthenresizedto224*224input                          \n                         size.Imageaugmentationtechniquessuch                       \n                         asrotation,flipping,andadjusting                           \n                         brightnesswereapplied,resultingin5250                      \n                         imagesforeachdisease.Thestudyalso                          \n                         involvedtheuseofinfraredthermal                            \n                         camerastocaptureimagesofpalmtreesin                        \n                         ordertodetectwaterstressandtheeffects                      \n                         ofRedPalmWeevil(RPW)infestation.                           \n                         Furthermore,thestudyutilizeda                              \n                         ConvolutionalNeuralNetwork(CNN)                            \n                         modelbuiltonthepre-structuredVGG16                         \n                         Networkforefficientfeatureextraction                       \n                         anddiseaseclassification.                                  \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n                                                                                    \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      A. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Project Title:\\nGreenery Recognition and Observation Optimization Tool (GROOT): A Mobile Application\\nfor Digital Identification of Major Pests and Diseases in Selected Indigenous Trees in Sta.\\nMaria, Laguna\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Topic: Computer Vision, Forestry\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Proponent: DELA CRUZ, ARIANE JOY M.\\n| GONZALODO, PAUL JOSHUA F.\\nVILLADIEGO, TRISH P.\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  B. Technical Description\n6  An\\napplication\\nthat\\nis\\neasier\\nand gives\\ninformation about pests\\nand\\ndiseases\\nin\\nselected\\nindigenous trees (Almon, Mayapis, Narra, Tanguile, and White Lauan). The present manual\\nmethods,\\nsuch physical observation and pen and paper\\nrecording. To improve their current\\nprocess, our\\nanswer\\nis\\na\\nportable gadget\\nor\\nuser-friendly mobile application with a large\\ndatabase\\nand\\ncutting-edge\\npicture\\nrecognition\\ntechnology. By\\nfacilitating\\nrapid\\nspecies\\ndetection and\\noffering comprehensive\\ninformation on\\nillnesses\\nand pests,\\nthis\\napplication\\ncompletely transforms\\nthe identification of major pests and diseases in selected indigenous\\ntrees.\\nBy scanning bark or foliage, users can access vital\\ninformation, enhancing monitoring efforts\\nand fostering a stronger connection with nature. This innovation benefits forestry professionals\\nby improving workflows and enriches forestry education for students. The application offers\\ndetailed profiles of\\ntrees,\\nincluding common and scientific names, habitats, growth patterns,\\nand ecological\\nsignificance.\\nIt also diagnoses pests and diseases, offering management and\\ntreatment recommendations.\\nThrough technology and environmental administration, we empower communities to protect\\nlocal woodlands\\nand\\nsupport conservation efforts,\\nleading the way for a more sustainable\\nfuture.\n7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Statement of the Problem:\\nTo address\\nthe challenges\\nfaced by the Department of Environment and Natural Resources\\n(DENR) in effectively monitoring and preserving tree species, especially in the context of tree\\ncutting activities and ecosystem conservation, we proposed the development of a specialized\\napplication by virtualizing the recording process and integrating technical terms to identify the\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          signs and symptoms of pests, and diseases in selected indigenous trees. This study will address\\nthe following:\\n1. What are the common pests in forest plantation trees in Santa Maria, Laguna?\\n2. What are the common diseases of forest plantation trees in Santa Maria, Laguna?\\n3. What application is used to identify common pests and diseases?\\n4.\\nHow can the application provide assistance on identifying major pests and diseases?\\n5.\\nHow effective GROOT application in identifying the major pests and diseases in\\nselected indigenous trees in Santa Maria, Laguna?\n1                                                                                                    Objectives: General and Specific General Objective:\\nThis study is ambitious and has the potential to be a game-changer for forestry, ecology, and\\neven citizen science. The goal is to develop a user-friendly application to easily identify major\\npests and diseases in selected indigenous trees in Sta. Maria, Laguna.\\nSpecifically, it aims to:\\n1.\\nCollect images showcasing common pests affecting the specified tree species like,\\nAmbrosia Beetle, Ips Calligraphus, Lymantria, and Teak Defoliator Mealybug,\\nshowcasing different stages of infestation and associated damage from ERDB and\\nCFNR.\\n2.\\nCollect images showcasing common diseases affecting the specified tree species like\\nleaf blight, leaf spot, powdery mildew, gall rust, and black ray disease from ERDB and\\nCFNR.\\n3.\\nDevelop an application that utilizes YOLO, a pre-trained Convolutional Neural\\nNetwork, for advanced object detection and recognition.\\n4.\\nDevelop a mobile application that would provide a platform to identify major pests and\\ndiseases in selected indigenous trees through the data gathered.\\n5.\\nDetermine the accuracy of the output of the image processing model.\n2  How did others solve the problem?\\n1.\\nThe researchers addressed the problem of bark identification by utilizing a combination\\nof\\ntechniques. They applied random square cropping with thresholding to the images\\nbefore inputting them into the convolutional neural networks (CNNs). This approach\\ninvolved randomly selecting a pixel\\nlength in the range of 40-60% of the total width\\nfor\\neach\\ncrop,\\nand\\nthen\\nrandomly\\nsampling\\nthe position\\nof\\nthe\\ncropping square.\\nAdditionally,\\nthey used a data augmentation process called \'RandAugment\'\\nto increase\\nthe training data by giving slight modifications. This involved randomly selecting a\\npredefined number\\nof\\naugmentation functions\\nand applying them with a randomly\\nsampled magnitude from a predefined range. These techniques aimed to minimize the\\nloss of bark features, provide flexible cropping, and increase the training data for more\\nrobust model\\ntraining.The researchers addressed the problem of bark identification by\\nutilizing\\na\\ncombination of\\ntechniques. They\\napplied random square cropping with\\nthresholding\\nto\\nthe\\nimages\\nbefore\\ninputting\\nthem into\\nthe\\nconvolutional\\nneural\\nnetworks\\n(CNNs). This approach involved randomly selecting a pixel\\nlength in the\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n0                                                                                                                          accuracy rate. Additionally, they enhanced the Convolutional Neural Network (CNN)\\nmodel and conducted experiments to test the models\' ability to detect leaf spots and\\nblight spots diseases under various circumstances.Alaa, H., Waleed, K., Samir, M.,\\nTarek, M., Sobeah, H., & Salam, M. A. (2020). An intelligent approach for detecting\\npalm trees diseases using image processing and machine learning. Int. J. Adv. Comput.\\nSci. Appl, 11(7), 434-441.\n1                                                                                          How do you intend to solve the problem?\\nA mobile application aims to revolutionize environmental management by identifying major\\npests\\nand\\ndiseases\\nin\\nselected\\nIndigenous Trees. The\\napplication\\nuses\\nadvanced\\nimage\\nrecognition algorithms to provide insights into major pests and diseases in selected indigenous\\ntrees.The application also serves as a platform for community engagement, fostering a sense of\\nownership and responsibility towards environmental conservation.\n2                                                                                                                                                                                                                                                                     Target users / Beneficiaries:(Describe each Beneficiary)\\nThis Study will be beneficial for Researchers, agriculturist and forester making it convenient\\nto major pests and diseases in selected indigenous trees providing insights and more details\\nabout the major pests and diseases in selected indigenous trees.\n3  Significance of study:\\nThe proposed mobile applications are an essential application for both common people and\\nenvironmental enthusiasts. It offers an extensive amount of information regarding major pests\\nand diseases in selected indigenous trees, accommodates a range of learning styles, and creates\\na feeling of community among those who share similar interests. The software helps users get\\na better knowledge of their relationship with nature and their responsibility as environmental\\nstewards, acting as a catalyst for personal development and self-discovery.\n\n                                                                                                                              0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1                                                                           2     3\n0                                                            using convolutional neural\\nnetworks and class activation\\nmapping                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 vision machines in identifying\\ntree barks using large-scale\\nbark image datasets, comparing\\nCNN algorithms (VGG-16 and\\nEfficientNet) and identifying\\ndiagnostic features.                                                                                  \n1  Improvement and Assessment of\\nConvolutional Neural\\nNetwork for Tree Species\\nIdentification Based on\\nBark Characteristics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The study explores the\\nrelationship between tree bark\\ncharacteristics and deep\\nconvolutional neural networks,\\naiming to improve tree species\\nidentification efficiency and\\nforest resource management.                  convolutional neural networks\\nConvNeXt network\\nBarkNetV2  2023\n2            Classification of CITES-listed\\nand other\\nneotropical Meliaceae wood\\nimages using\\nconvolutional neural networks  The purpose of the study was\\nto develop a computer vision\\nclassification model using deep\\nconvolutional neural networks\\nto identify neotropical\\nMeliaceae wood species. This\\nwas aimed at providing a\\nreliable, consistent, and\\ncost-effective field screening\\nmethod for effective global\\nscale enforcement of\\ninternational treaties such as\\nthe Convention on the\\nInternational Trade in\\nEndangered Species (CITES)\\nor national laws governing\\ntimber trade and imports. The\\nstudy focused on 10\\nneotropical species in the\\nfamily Meliaceae, including\\nCITES-listed species, with the\\ngoal of achieving species-level\\ndiscrimination, which is\\nessential for combating illegal\\nlogging and ensuring the\\nprotection of endangered wood\\nspecies.  computer vision classification\\nmodel\\ndeep convolutional neural\\nnetworks  2018\n3                                                             Pest Detection and Extraction\\nUsing Image Processing\\nTechniques                                                                                                                                                                                                                                                                            The purpose of the study is to\\ndevelop an innovative decision\\nsupport system for early pest\\ndetection in agricultural fields.\\nThe researchers aim to use\\nimage analysis and scene\\ninterpretation from\\nmulti-camera data to identify\\ninsect pests in real time. The\\ngoal is to reduce pesticide use\\nby enabling early detection of\\npests on plant organs such as\\nleaves. The study also focuses\\non creating a system that can\\neasily adapt to different\\ncategories of bioaggressors,                                                            Image Processing  2014\n\n                                                                                                           0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1                                                                                                            2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  contributing to more efficient\\nand sustainable pest\\nmanagement practices in\\nagriculture.                                                                                                                   \n1  An Intelligent Approach for\\nDetecting Palm Trees\\nDiseases using Image Processing\\nand Machine\\nLearning  The purpose of the study is to\\ndetect Red Palm Weevil\\n(RPW) infestation in palm\\ntrees using thermal imaging.\\nThe study aims to use uncooled\\ninfrared thermal cameras and\\nmicrobolometer sensors to\\ncapture images of palm trees,\\nanalyze the images using\\nsoftware to assess water stress\\nand temperature rates, and\\nidentify infected trees based on\\nthe observed differences in\\ntemperature and water stress.\\nThe study also explores the use\\nof machine learning models\\nsuch as Support Vector\\nMachines (SVM) and\\nConvolutional Neural\\nNetworks (CNN) for\\nclassification and detection of\\nRPW infestation in palm trees.  Thermal imaging\\nImage Processing\\nConvolutional Neural Network\\nSupport Vector Machine\\nMobile Application  2020\n\n                                                                                                                                         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1                                                        2     3\n0                                                                                               TITLE\\nDESCRIPTION\\nSCOPE/TECHNOLOGY\\nYEAR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n1                                                                                                                               TECHNOLOGY                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n2  Identifying and\\nextracting bark key\\nfeatures of 42 tree\\nspecies using\\nconvolutional neural\\nnetworks\\nand class activation\\nmapping  The\\nresearch\\ndelving\\ninto\\nbark\\nidentification\\nusing\\nconvolutional\\nneural\\nnetworks\\n(CNNs)\\nalongside\\nclass\\nactivation mapping (CAM) yielded several\\nsignificant\\nfindings.\\nFirstly,\\nCNNs\\nexhibited\\nremarkable\\nproficiency\\nin\\nidentifying\\nthe\\nbarks\\nof\\n42\\ndistinct\\ntree\\nspecies,\\nachieving\\naccuracy\\nrates\\nsurpassing\\n90%.\\nNotably,\\ncomparative\\nanalysis between the two employed CNN\\nmodels, namely VGG-16 and EfficientNet,\\nrevealed only marginal variances in overall\\naccuracy. The\\nstudy identified diagnostic\\nkeys\\nfor\\neach\\nspecies,\\ncorrelating\\nthem\\nwith distinct bark features such as blisters,\\nstripes,\\nlenticels\\nof\\nvarious\\nshapes,\\nand\\ncrevices.\\nInterestingly,\\nthe\\ntwo\\nCNN\\nmodels demonstrated discrepancies\\nin the\\nquality\\nof\\ndiagnostic\\nfeatures, with\\nthe\\nolder model presenting more general yet\\nwell-fitting patterns, while the newer, more\\nintricate model\\nindicated localized patterns\\nless\\npertinent\\nto\\nbark\\nidentification.  convolutional neural networks\\nclass activation mapping  2022\n\n                                                                                                                                  0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1                                                                           2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Furthermore,\\nCNNs\\nshowcased\\nthe\\ncapability\\nto\\npredict\\nuntrained\\nspecies\\nwithin\\nthe\\ncorrect\\ngenus\\nand\\nfamily\\nby\\napproximately\\n41.98%\\nand\\n48.67%,\\nrespectively. These findings underscore the\\npotential of CNNs and CAM in not only\\naccurately\\nidentifying\\nand\\nvisualizing\\nessential\\nbark\\ntraits\\nbut\\nalso\\nin\\ntheir\\nbroader applicability to other plant organs.                                                                                  \n1  Improvement and\\nAssessment of\\nConvolutional\\nNeural\\nNetwork for Tree\\nSpecies\\nIdentification Based\\non\\nBark Characteristics  The\\nstudy\\nemployed\\nthree\\ndistinct\\nvisualization methods,\\nnamely\\nIntegrated\\nGradients,\\nSmooth\\nGrad\\nCAM++,\\nand\\nDeep Feature Decomposition,\\nto elucidate\\nthe\\nnetwork\\nworkflow.\\nThrough\\nthese\\nmethods,\\nresearchers\\nidentified\\nspecific\\nfeatures\\nin\\ntree\\nbark\\nimages,\\nincluding\\ngrooves,\\ncracks,\\nand lenticels, which the\\nneural network weights selectively focused\\non.\\nThis\\nselective\\nattention\\nparalleled\\nhuman recognition of tree species based on\\nbark images, enhancing our understanding\\nof\\nthe network\'s decision-making process.\\nMoreover,\\nthe\\nvisualization\\nresults\\nobtained\\nthrough\\ndeep\\nfeature\\ndecomposition and semantic segmentation\\nexhibited similarities, offering insights into\\nhow the\\nnetwork identifies different\\ntree\\nspecies based on bark image blocks. These\\nfindings\\nunderscored\\nthe\\ncorrelation\\nbetween\\nthe\\nbiological\\ncharacteristics\\nof\\ndiverse\\ntree\\nspecies\\nand\\nthe\\nvisual\\nmechanisms of deep convolutional neural\\nnetworks, providing valuable insights into\\nboth\\nthe\\nnetwork\'s\\nfunctioning\\nand\\nits\\nrelationship with natural features. Overall,\\nthese outcomes shed light on the principles\\nand\\ncharacteristics\\nof\\nthe\\nnetwork\\nworkflow\\nand\\nits\\ncorrelation with\\nthe\\nbiological\\nfeatures\\nof\\ntree\\nspecies,\\nadvancing\\nour\\nunderstanding\\nof\\nboth\\nmachine\\nlearning\\nprocesses\\nand\\nnatural\\nphenomena.                  convolutional neural networks\\nConvNeXt network\\nBarkNetV2  2023\n2               Classification of\\nCITES-listed and other\\nneotropical Meliaceae\\nwood images using\\nconvolutional neural\\nnetworks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The\\nstudy\\naimed\\nto\\ndevelop machine\\nlearning models\\nfor wood\\nidentification\\nbased on images of\\ntransverse surfaces of\\nwood specimens. The researchers captured\\nhigh-resolution\\nimages\\nof\\nwood\\nspecimens,\\nannotated\\nthem for\\nvarious\\ncharacteristics,\\nand then created a dataset\\nfor\\ntraining\\nand\\ntesting\\nthe\\nmachine\\nlearning models. They specifically focused  computer vision classification\\nmodel\\ndeep convolutional neural\\nnetworks  2018\n\n                                                                    0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1                                                                                        2     3\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   on\\ndistinguishing\\nbetween\\nspecies-level\\nand genus-level accuracy,\\nrecognizing the\\ntraditional limitation of wood identification\\nat\\nthe species level. The study involved the\\ncreation\\nof\\npatch\\ndatasets,\\ntraining\\nof\\nconvolutional\\nneural\\nnetwork\\n(CNN)\\nmodels,\\nand\\nevaluation\\nof\\nthe model\\naccuracies. The models were trained using\\nthe VGG16 network as\\nfeature extractors\\nand\\nthe\\ncustom top-level\\nlayers\\nwere\\ntrained\\nusing\\nstochastic\\ngradient\\ndescent\\nand\\nthe Adam optimizer. The\\nstudy also\\nincluded the creation of confusion matrices\\nand\\ntraining\\ncurves\\nfor\\nthe models\\nto\\nanalyze the errors made by the models.                                                                                               \n1  Pest Detection and\\nExtraction Using\\nImage Processing\\nTechniques  The study presents\\nthe development of an\\nautomatic detection and extraction system\\nfor insect pests in paddy fields using image\\nprocessing techniques. The authors set up a\\nnetwork\\nof wireless\\ncameras\\nand\\nsticky\\ntraps\\nin the paddy fields\\nto capture insect\\npests.\\nThey\\nused\\nCISCO\\nLinksys\\nWireless-G\\nInternet\\nHome\\nMonitoring\\nCameras\\nto capture\\nimages\\nat 10 frames\\nper\\nsecond with\\n8-megapixel\\nresolution.\\nThe captured images were processed using\\na local machine equipped with an Intel\\ni3\\nprocessor and 4 GB RAM.\\nThe\\nstudy\\nutilized\\nimage\\npre-processing\\ntechniques to enhance the captured images,\\nincluding\\nconverting\\nRGB\\nimages\\ninto\\ngrayscale\\nusing\\na\\nspecific\\nformula. The\\nauthors also developed an algorithm for the\\ndetection of pests in the images,\\ninvolving\\nthe\\nextraction\\nof\\nisolated\\npatterns\\nof\\ninterest based on robust feature extraction.\\nThe\\nexperimental\\nresults of\\nthe proposed\\nsystem showed its efficiency in detecting\\nand\\nextracting\\ninsect\\npests\\nin the paddy\\nfields.\\nThe\\nsystem was\\ntested\\nover\\nfive\\nconsecutive\\ndays,\\nand\\nthe\\nresults\\nof\\nthe\\ndetected\\nimages\\nof\\ndifferent\\ninsect pests\\nwere recorded and presented in a table.\\nThe study aims to contribute to the field of\\nagricultural research by providing a simple\\nyet\\nefficient\\nsystem for\\nautomatic\\npest\\ndetection\\nand\\nextraction\\nusing\\nimage\\nprocessing techniques.                                                                         Image Processing  2014\n2                  An Intelligent\\nApproach for Detecting\\nPalm Trees                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     The study involved the use of a dataset\\nfrom Kaggle containing 91,360 images for\\nleaf spots and blight spots diseases. Due to\\nthe low variation in the images, the  Thermal imaging\\nImage Processing\\nConvolutional Neural Network\\nSupport Vector Machine  2020\n\n                                                         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1                   2 3\n0  Diseases using Image\\nProcessing and\\nMachine\\nLearning  original images were analyzed before\\naugmentation, resulting in the selection of\\n35 leaf spots images, 40 images for blight\\nspots, and 50 more palm images for each\\ndisease. The original images were\\nmanually cropped to preserve the infected\\nparts and then resized to 224*224 input\\nsize. Image augmentation techniques such\\nas rotation, flipping, and adjusting\\nbrightness were applied, resulting in 5250\\nimages for each disease. The study also\\ninvolved the use of infrared thermal\\ncameras to capture images of palm trees in\\norder to detect water stress and the effects\\nof Red Palm Weevil (RPW) infestation.\\nFurthermore, the study utilized a\\nConvolutional Neural Network (CNN)\\nmodel built on the pre-structured VGG16\\nNetwork for efficient feature extraction\\nand disease classification.  Mobile Application  ', 'green recognition and observation optimization tool or growth a mobile application for digital identification of major pests and disease in selected indigenous trees in santa maria lagun\na so\nan application that is easier and gives information about pest and diseases in selected indigenous trees\nthe present manual sure below what are the common test in forest plantation trees in santa maria lagun\na what are the common diseases of forest plantation trees in santa maria\n\nsanta maria\nlaguna\nbye\nmaraming salamat\n\n', '{\"status\": \"success\", \"speech_similarity\": 82.62, \"missed_keypoints\": [\"trees scanning\", \"computervision forestry\", \"forestsusinga\", \"imagesshowcasingcommon pestsaffectingthespecifiedtree\", \"trees application\"], \"added_keypoints\": [\"diseases forest\", \"green recognition\", \"plantation trees\", \"forest plantation\", \"pest diseases\"], \"suggested_titles\": [\"Analysis of Forestsusinga in Research Context\", \"Analysis of Forestryprofessionals in Research Context\", \"Analysis of Forestry in Research Context\"]}', 0);
INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(102, 'janeeeeverdad@gmail.com', 'CSA04-_CONCEPT_PAPER_04_11_24.pdf', 'uploads/b63645d29aad47858cf51bfe31fca134.pdf', '2025-04-24 09:00:12', '                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Concept Paper                                                           \n                                                                                  \n                                                                                  \n          A. Basic Information                                                    \n                                                                                  \n                                                                                  \n          Project Title: A Secure Dengue Case Management System with User Authentication, Data Analysis,\n          and Intervention Planning Capabilities for Provincial Health Office in Santa Cruz, Laguna\n                                                                                  \n                                                                                  \n          Topic: Machine Learning, Data Analysis, Cloud Computing, User Authentication and Security, Web-\n          based Interface, Mobile Applications, Intervention Planning and Communication, Breakbone Fever,\n          Epidemiology, Mapping, Aedes aegypti                                    \n                                                                                  \n          Proponents: JOSEPH G. COLLANTES                                         \n                   CYLA DENDEYL M. TRINIDAD                                       \n                   JOYCE ANNE M. VIRAY                                            \n                                                                                  \n                                                                                  \n                                                                                  \n          B. Technical Description                                                \n                                                                                  \n          A virus called dengue (also known as break-bone fever) is transmitted from mosquitoes to humans. In\n          tropical and subtropical regions, it is more common. The majority of dengue patients experience no\n          symptoms. However, the most typical symptoms for those who do include rash, nausea, body aches,\n          headaches, and high fever. Most will recover in one to two weeks as well. Some people require hospital\n          care when they have severe dengue.                                      \n                                                                                  \n          In the Philippines, a dengue outbreak was first reported as early as 1906, and the first severe dengue\n          epidemic was documented in Manila in 1953. Since then, dengue has been hyperendemic in most areas\n          of the country with a general increase in the number of dengue cases over time.\n                                                                                  \n          As per the website themedicalcity.com, Dengue is a disease caused by any one of four closely related\n          dengue viruses (DENV 1, DENV 2, DENV 3, or DENV 4). The viruses are transmitted to humans by\n          the bite of an infected mosquito. The Aedes aegypti mosquito is the most important transmitter or vector\n          of dengue viruses. Another mosquito that transmits the dengue virus is Aedes albopictus.\n          The study of S. Richards, entitled “PICTUREE—Aedes: A Web Application for Dengue Data\n          Visualization and Case Prediction” is a web application designed to combat dengue fever. It combines\n          data visualization tools with forecasting models to analyze various factors like temperature, precipitation,\n          mosquito presence, and historical dengue cases. This allows users to assess risk for future outbreaks and\n          predict potential case numbers, ultimately helping public health officials take preventive measures.\n                                                                                  \n          The system offers valuable insights and tools that can complement the development of a Secure Dengue\n          Case Management System for the Provincial Health Office in Santa Cruz, Laguna. By incorporating data\n          visualization tools and forecasting models.                             \n                                                                                  \n          This allows public health officials to assess the risk of future outbreaks and predict potential case\n          numbers, enabling them to take proactive preventive measures. Integrating such predictive analytics\n          capabilities into a Secure Dengue Case Management System can enhance its effectiveness in identifying\n          high-risk areas, allocating resources efficiently, and planning targeted interventions to mitigate the\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          impact of dengue fever in the region.                                   \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Statement of the Problem:                                               \n                                                                                  \n          Dengue fever is a major public health concern in Santa Cruz, Laguna. The Provincial Health Office\n          (PHO) requires a system to manage dengue cases effectively. This study aims to address the following\n          critical issues:                                                        \n                                                                                  \n            ●  How can a secure web-based system efficiently collect and manage Dengue case data while\n               ensuring patient data privacy?                                     \n            ●  How can the system utilize collected data to monitor Dengue trends, detect early outbreak signs\n               in specific barangays, and provide real-time insights to the Provincial Health Office (PHO)?\n            ●  How do the existing security measures within the Dengue case management system mitigate\n               risks to patient confidentiality and data integrity?               \n            ●  How can a Dengue Case Management System integrate user authentication, data analysis, and\n               intervention planning functionalities to meet the unique requirements of the PHO in Santa\n               Cruz, Laguna?                                                      \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          General Objective and Specific Objectives                               \n                                                                                  \n          The goal of this research is to develop a secure dengue case management system with functionalities for\n          user authentication, data analysis, and intervention planning, specifically designed for the Provincial\n          Health Office (PHO) in Santa Cruz, Laguna. The system aims to contribute to more effective public\n          health surveillance and response strategies.                            \n                                                                                  \n            ●  To design and implement user authentication for authorized access, and protect patient\n               confidentiality and system integrity.                              \n            ●  To collect, preprocess, and integrate Dengue case data into a centralized database for\n               comprehensive analysis and surveillance.                           \n            ●  To employ advanced data analysis techniques, including machine learning, to identify Dengue\n               transmission patterns and high-risk areas.                         \n            ●  To develop a user-friendly interface for seamless interaction and efficient data entry,\n               visualization, and reporting.                                      \n            ●  To implement intervention planning functionalities enabling targeted strategies for vector\n               control, resource allocation, and community outreach.              \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          How did others solve the problem?                                       \n                                                                                  \n            1. In this systematic review, in order to find publications pertaining to dengue outbreak prediction\n               models, the researchers carried out an extensive search across a number of databases and\n               literature sources. To choose pertinent papers, they used precise inclusion and exclusion criteria,\n               guaranteeing the level of quality and applicability of the studies they included. Data from the\n               chosen publications were synthesized for the study in order to find recurring themes, approaches,\n               and constraints among the various prediction models. The researchers evaluated the quality of\n               dengue outbreak prediction models at the time and indicated opportunities for development and\n               knowledge gaps through this meticulous method. By combining the results, they were able to\n               shed light on the advantages and disadvantages of the current models and suggest new lines of\n               inquiry for this kind of study. (A systematic review of dengue outbreak prediction models:\n               Current scenario and future directions, Y. Leung, et. al., 2022)   \n            2. The study was performed to evaluate the health information system regarding the dengue\n               surveillance system in Indonesia. Major obstacles to the implementation of an effective health\n               information system regarding dengue cases in Bandung are examined, and practical suggestions\n               on measures to overcome them are discussed. The study utilized a mixed-method research design\n               using qualitative approaches: document analysis, key informants, and focus group interviews.\n               Thirty key informants were selected, comprised of policymakers, senior managers, and staff at\n               the Ministry of Health. Data from documents and transcripts were evaluated through a modified\n               Institutional Analysis and Development (IAD) framework described by Ostrom. Through this\n               study, they identified several issues that hinder the effective implementation of the health\n               information system in the case of dengue in Bandung. In the end, they propose several\n               recommendations for reform that encompass motivational, strategic, and structural approaches\n               to each component of the analysis. Through evaluation of the health information system for\n               dengue surveillance in Indonesia, they conclude that well-coordination in multi-level\n               governance in a country as large as Indonesia is the key in the implementation of the health\n               information system in different levels of agencies. Furthermore, the adaptability of human\n               resources in adopting a new information system also plays an important part. (Evaluation of\n               Health Information System (HIS) in The Surveillance of Dengue in Indonesia: Lessons from\n               Case in Bandung, West Java, Liah Farida et. al. 2020)              \n            3. This study aimed to evaluate the usability of the Mozzify app in terms of objective quality\n               (engagement, functionality, aesthetics, information) and app subjective and app-specific\n               qualities and compare total app mean score ratings by sociodemographic profile and self and\n               family dengue fever history to see what factors are associated with high app mean score rating\n               among school-based young adult samples and health care professionals. Individual interviews\n               and focus group discussions were also conducted among participants to develop themes from\n               their comments and suggestions to help structure further improvement and future development\n               of the app. (Early Detection of Dengue Fever Outbreaks Using a Surveillance App (Mozzify):\n               Cross-sectional Mixed Methods Usability Study, Von Ralph Dane Marquez Herbuela et. al.\n               2021)                                                              \n                                                                                  \n            4. This study consolidates and analyses the dengue case dataset amassed by the e-Dengue web-\n               based information system, developed by the Ministry of Health Malaysia, to improve the\n               epidemiological understanding. The researchers retrieved data from the e-Dengue system and\n               integrated a total of 18,812 cases from 2012 to 2019 (8 years) with meteorological data,\n               geoinformatics techniques, and socio-environmental observations to identify plausible factors\n               that could have caused dengue outbreaks in Ipoh, a hyperendemic city in Malaysia. (Application\n               of medical information system to identify dengue outbreak factors: Insights from a\n               hyperendemic city in Malaysia, Casey Keat-Chuan Ng et. al. 2023)   \n            5. The proposed system involves a 4-level architecture for the prediction and prevention of dengue\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n               infection outspread. The architectural levels including Dengue Information Acquisition level,\n               Dengue Information Classification level, DengueMining and Extraction level, and Dengue-\n               Prediction and Decision Modeling level enable an individual to periodically monitor his/her\n               probabilistic dengue fever measure. The prediction process is carried out so that proactive\n               measures are taken beforehand. For predictive purposes, probabilistic analysis in terms of the\n               Level of Dengue Fever (LoDF) was carried out using the Adaptive NeuroFuzzy Inference\n               System. Based on the Self-Organized Mapping procedure, the presence of LoDF is visualized.\n               Several simulations on datasets of 16 individuals cumulating to 32,255 instances were conducted\n               to test the effectiveness of the presented model. In comparison to other decision-modeling\n               methods, significantly improved results in the form of classification efficacy, a temporal delay,\n               prediction effectiveness, reliability, and stability were reported for the presented model. (Secure\n               Dengue Epidemic Prediction System: Healthcare Perspective, Abdulaziz Aldaej et. al 2022)\n          Other Related Study (data gathering and machine learning methods)       \n                                                                                  \n            6. The researchers conducted an SLR on dengue modeling based on machine learning. The main\n               objective was to know about diagnostic, epidemic, and intervention models that have been\n               developed for the disease. Sixty-four articles were selected and analyzed from several scientific\n               libraries, to find out the state-of-the-art in the three approaches mentioned above. The results\n               show that dengue modeling is constantly growing. (Dengue models based on machine learning\n               techniques: A systematic literature review, William Hoyos et. al. 2021)\n                                                                                  \n            7. In this study, researchers aimed to identify significant climatic risk factors and develop machine\n               learning models for dengue outbreak prediction. They collected historical data on dengue cases\n               and climate variables from various sources. Utilizing statistical analyses, including correlation\n               and regression analyses, they identified key climatic risk factors associated with dengue\n               outbreaks. Additionally, they employed various machine learning algorithms, such as decision\n               trees and random forests, to develop prediction models based on these factors. Through rigorous\n               evaluation and comparison of these models, they demonstrated the efficacy of machine learning\n               approaches in accurately predicting dengue outbreaks. The study\'s findings provide valuable\n               insights into the relationship between climate factors and dengue incidence, offering a promising\n               avenue for proactive disease control and prevention strategies. (Identification of significant\n               climatic risk factors and machine learning models in dengue outbreak prediction, F. Nejad, et.\n               al., 2021)                                                         \n                                                                                  \n            8. Researchers developed a machine learning-based dengue forecasting system for Irisan, Baguio\n               City, Philippines. They collected historical data on dengue cases and relevant environmental\n               variables, such as temperature and rainfall, from local health authorities and meteorological\n               agencies. Using machine learning algorithms, including decision trees and support vector\n               machines, they constructed predictive models to forecast dengue outbreaks. The system\'s\n               performance was evaluated through cross-validation and comparison with traditional statistical\n               methods. The results demonstrated the efficacy of the machine learning approach in accurately\n               predicting dengue incidence, thereby providing valuable tools for public health officials to\n               implement proactive measures for disease prevention and control. The study\'s findings\n               contribute to the advancement of dengue forecasting systems, enhancing preparedness and\n               response strategies for dengue outbreaks in the region. (Z. Omadlao, et. al., 2022)\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          How do you intend to solve the problem?                                 \n                                                                                  \n          The proponent of the study plans to solve the problem by developing a Secure Dengue Case\n          Management System with User Authentication, Data Analysis, and Intervention Planning Capabilities\n          for the Provincial Health Office in Santa Cruz, Laguna. This system will create a secure online system\n          to help the Santa Cruz, Laguna, health department manage dengue fever. The system keeps data safe,\n          analyzes trends in cases, and even helps plan actions to stop outbreaks. Overall, this tool aims to improve\n          public health in the area.                                              \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                  Figure 1. Conceptual Framework of Dengue Case Management System \n                                                                                  \n                                                                                  \n          Target users / Beneficiaries:(Describe each Beneficiary)                \n                                                                                  \n            1. Healthcare Providers:                                              \n                 ●  include doctors, nurses, and other medical staff involved in diagnosing and treating\n                    dengue cases.                                                 \n                 ●  They would benefit from the system\'s capabilities for securely accessing patient data,\n                    analyzing trends, and planning interventions tailored to individual cases.\n            2. Public Health Officials:                                           \n                 ●  Public health officials at local health departments or government agencies responsible\n                    for overseeing dengue control efforts would benefit from the system\'s data analysis\n                    tools to monitor disease trends, identify high-risk areas, and allocate resources\n                    effectively.                                                  \n            3. Community Health Workers:                                          \n                 ●  These frontline workers are crucial in community outreach and education about\n                    dengue prevention measures.                                   \n                 ●  They would benefit from the system\'s intervention planning capabilities to implement\n                    targeted interventions and educational campaigns in high-risk areas.\n            4. Residents of Santa Cruz, Laguna:                                   \n                 ●  The general population in Santa Cruz, Laguna, would benefit from the improved\n                    dengue case management facilitated by the system.             \n                 ●  This includes timely intervention planning to reduce disease transmission, better\n                    access to healthcare services, and increased awareness about dengue prevention\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                    measures.                                                     \n            5. Researchers and Epidemiologists:                                   \n                 ●  Researchers and epidemiologists studying dengue transmission and control would\n                    benefit from access to the system\'s data analysis capabilities, which can provide\n                    valuable insights into disease dynamics and inform future research and intervention\n                    strategies.                                                   \n                                                                                  \n                                                                                  \n          Significance of study:                                                  \n                                                                                  \n          Creating a secure dengue case management system with user authentication, data analysis, and\n          intervention planning capabilities for the provincial health office in Santa Cruz, Laguna. The system will\n          help predict outbreaks and give real-time information to health officials. The study will also make sure\n          patient privacy is protected. This new system can greatly improve how dengue is managed in Santa Cruz,\n          Laguna.                                                                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Survey Matrix                                                           \n                                                                                  \n                                                                                  \n                                                                                  \n          Title of Study Variety       Purpose         Technology  Year           \n                                                                                  \n                                                                                  \n          User Experience Closed-ended, Likert Assess user satisfaction Web-based 2022\n          Evaluation of a scale        with the system\'s survey tool              \n          Secure Dengue                usability and   (e.g.,                     \n          Case Management              functionality.  SurveyMonkey)              \n          System                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Assessing Data Open-ended, Multiple Evaluate the accuracy, Online survey 2023\n          Quality in a Choice          completeness, and platform                 \n          Dengue Case                  timeliness of data                         \n          Management                   collected by the system.                   \n          System                                                                  \n                                                                                  \n          Data-driven                  To predict and  Machine                    \n          methods   for Dengue Outbreak monitor dengue-related learning 2022      \n          dengue prediction            outcomes.       methods                    \n          and surveillance             To assess the   Real-world data            \n          using real-world             validity of data and Big Data              \n          and Big Data: A              sources for dengue sources                 \n          systematic review            surveillance.                              \n                                                                                  \n                                                                                  \n          Impact of Data Multiple Choice, Gauge the effectiveness Online survey 2022\n          Visualization on Rating Scale of data visualizations in with visual     \n          Dengue Outbreak              facilitating informed                      \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          Response                     decision-making for stimuli                \n                                       intervention planning.                     \n                                                                                  \n                                                                                  \n          Perceived    Likert scale, Open- Evaluate user Web-based 2020           \n          Benefits of  ended           perception of the survey tool              \n          Intervention                 system\'s intervention                      \n          Planning Tools for           planning functionalities                   \n          Dengue Control               and their impact on                        \n                                       controlling dengue                         \n                                       outbreaks.                                 \n                                                                                  \n                                                                                  \n          Gap Analysis                                                            \n                                                                                  \n                                                                                  \n          TITLE       DESCRIPTION              SCOPE/TECHNOLOGY    YEAR           \n                                                                                  \n                                                                                  \n                             TECHNOLOGY (Machine Learning )                       \n                                                                                  \n          Predictive                                                              \n          Modeling of This research investigates the Machine Learning 2021        \n          Dengue      application of Machine Learning algorithms (e.g., Logistic  \n          Hemorrhagic models to identify factors associated Regression, Gradient  \n          Fever  Using with the severity of dengue infections. Boosting)          \n          Machine                                                                 \n          Learning                                                                \n          A    Machine                                                            \n          Learning-Based This study proposes a Machine Deep Learning algorithms 2020\n          Framework for Learning framework to automate (e.g., Convolutional Neural\n          Dengue      dengue case  detection and Networks)                        \n          Detection and classification using patient data.                        \n          Classification                                                          \n                                                                                  \n          Machine     This review analyzes existing Machine Various Machine Learning 2019\n          Learning for Learning applications for dengue algorithms                \n          Dengue      outbreak prediction, spread prediction,                     \n          Outbreaks: A and mosquito habitat identification.                       \n          Review                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          TITLE       DESCRIPTION               SCOPE/TECHNOLOGY    YEAR          \n                                                                                  \n                                                                                  \n                               TECHNOLOGY (Data Analysis)                         \n                                                                                  \n          Spatial Analysis                                                        \n          of Dengue Fever This study explores the use of GIS, Spatial statistics 2023\n          Outbreaks   Geographic Information Systems (GIS)                        \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                      and spatial analysis techniques to                          \n                      identify hotspots of dengue                                 \n                      transmission.                                               \n                                                                                  \n          Data Mining                                                             \n          Techniques for This research investigates the Data mining algorithms 2022\n          Dengue Case application of data mining techniques                       \n          Classification like clustering and association rule                     \n                      learning to identify patterns in dengue                     \n                      case data.                                                  \n                                                                                  \n                                                                                  \n          Visualizing  This study proposes an interactive Data visualization tools 2021\n          Dengue Fever dashboard using data visualization (e.g., Tableau, Power BI)\n          Trends: An  techniques to explore trends and                            \n          Interactive patterns in dengue cases.                                   \n          Dashboard                                                               \n          Approach                                                                \n                                                                                  \n          Big Data    This review analyzes the potential of Big data frameworks (e.g., 2020\n          Analytics for big data analytics for dengue control, Hadoop, Spark)     \n          Dengue Control including data collection, storage,                      \n                      processing, and analysis.                                   \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                    REFERENCES:                                   \n                                                                                  \n                    Panja, M., Chakraborty, T., Nadim, S. S., Ghosh, I., Kumar, U., & Liu, N. (2023). An\n                                                                                  \n               ensemble neural network approach to forecast Dengue outbreak based on climatic conditions.\n                                                                                  \n               Chaos, Solitons & Fractals, 167, 113124. https://doi.org/10.1016/j.chaos.2023.113124\n                                                                                  \n                                                                                  \n                                                                                  \n                    Fernández-Alemán, J. L., Señor, I. C., Lozoya, P. Á. O., & Toval, A. (2013). Security\n                                                                                  \n               and privacy in electronic health records: A systematic literature review. Journal of Biomedical\n                                                                                  \n               Informatics, 46(3), 541–562. https://doi.org/10.1016/j.jbi.2012.12.003\n                                                                                  \n                                                                                  \n                                                                                  \n                    Leung, X. Y., Islam, R. M., Adhami, M., Ilic, D., McDonald, L., Palawaththa, S., Diug,\n                                                                                  \n               B., Munshi, S. U., & Karim, M. N. (2023). A systematic review of dengue outbreak prediction\n                                                                                  \n               models: Current scenario and future directions. PLOS Neglected Tropical Diseases, 17(2),\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n               e0010631. https://doi.org/10.1371/journal.pntd.0010631             \n                                                                                  \n                                                                                  \n                    Blanco, A. C., Harder, B. J. J., & Teh, I. A. R. (2023). SPATIO-TEMPORAL\n                                                                                  \n               ANALYSIS AND MODELLING OF DENGUE INCIDENCES IN QUEZON CITY USING   \n               ORDINARY LEAST SQUARES AND SPATIAL REGRESSION. The International Archives\n                                                                                  \n               of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLVIII-4/W6-2022,\n                                                                                  \n               87–92. https://doi.org/10.5194/isprs-archives-xlviii-4-w6-2022-87-2023\n                                                                                  \n                                                                                  \n                    Schaefer, T. J., & Wolford, R. W. (2019). Dengue Fever. Nih.gov; StatPearls\n                                                                                  \n               Publishing. https://www.ncbi.nlm.nih.gov/books/NBK430732/          \n                                                                                  \n                    Ouédraogo, S., Benmarhnia, T., Bonnet, E., Somé, P.-A., Barro, A. S., Kafando, Y.,\n                                                                                  \n               Soma, D. D., Dabiré, R. K., Saré, D., Fournet, F., & Ridde, V. (2018). Evaluation of\n                                                                                  \n               Effectiveness of a Community-Based Intervention for Control of Dengue Virus Vector,\n                                                                                  \n               Ouagadougou, Burkina Faso. Emerging Infectious Diseases, 24(10), 1859–1867.\n                                                                                  \n               https://doi.org/10.3201/eid2410.180069                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Concept Paper                                                          \n                                                                                  \n                                                                                  \n           A. Basic Information                                                   \n                                                                                  \n                                                                                  \n           Project Title:                                                         \n           Web-Based Dengue Outbreak Predictive Modeling System for Provincial Health Office in Santa\n           Cruz, Laguna                                                           \n                                                                                  \n                                                                                  \n                                                                                  \n           Topic:                                                                 \n           Machine Learning Algorithms, Feature Selection and Engineering, Cross-Validation and Model\n           Evaluation, Hyperparameter Tuning, Ensemble Learning, Model Interpretability, Software\n           Development, Data Privacy and Security                                 \n                                                                                  \n                                                                                  \n            Proponents: JOSEPH G. COLLANTES                                       \n                                                                                  \n                    CYLA DENDEYL M. TRINIDAD                                      \n                    JOYCE ANNE M. VIRAY                                           \n                                                                                  \n                                                                                  \n           B. Technical Description                                               \n                                                                                  \n           In tropical countries like the Philippines, where epidemics place a heavy strain on healthcare systems\n           and communities, dengue fever is still a serious public health concern (WHO, 2020). Using past data\n           to predict future occurrences, predictive modeling has become an important technique for forecasting\n           and minimizing the impact of dengue outbreaks. The purpose of this study is to create and assess\n           predictive models based on machine learning that are customized for the unique circumstances of Santa\n           Cruz, Laguna, to improve the Provincial Health Office\'s readiness and reaction.\n                                                                                  \n           Machine learning algorithms, which range from decision trees and random forests to more\n           sophisticated methods like gradient boosting machines and neural networks, have been shown in\n           earlier studies to be effective in predicting dengue outbreaks (Shiraz et al., 2018; Lee et al., 2020). The\n           proposed study uses these techniques to look for patterns and trends in the dengue incidence data that\n           Santa Cruz, Laguna, and others create precise prediction models that have a high degree of\n           dependability in foretelling future epidemics.                         \n                                                                                  \n           A key component of developing predictive models for dengue epidemic preparedness is feature\n           engineering and selection. Research has demonstrated that model performance can be greatly enhanced\n           by choosing pertinent parameters pertaining to climate, demography, and past dengue cases\n           (Rajarethinam et al., 2019; Wongkoon et al., 2021). Principal component analysis (PCA) and feature\n           importance ranking are two methods that will be used in this study to determine which variables are\n           most useful and should go into the prediction models.                  \n           In order to evaluate the effectiveness of predictive models for dengue epidemic preparedness,\n           evaluation and validation are crucial processes. To make sure the created models are reliable\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           and broadly applicable, cross-validation methods like k-fold cross-validation will be applied (Kohavi,\n           1995). In order to measure the predictive performance of the models and direct decision-making\n           processes inside the Provincial Health Office of Santa, metrics including accuracy, precision, recall,\n           and F1-score will be produced. Cruz, Laguna.                           \n                                                                                  \n                                                                                  \n           Statement of the Problem:                                              \n                                                                                  \n           In the Province of Santa Cruz, Laguna, the Provincial Health Office faces challenges in effectively\n           managing dengue outbreaks, leading to suboptimal response strategies and resource allocation. With\n           the aim of improving dengue outbreak preparedness and response efforts, this study seeks to address\n           the following problems:                                                \n                                                                                  \n              1. How can predictive modeling techniques be utilized to enhance dengue outbreak forecasting\n                and preparedness strategies for the Provincial Health Office in Santa Cruz, Laguna?\n                                                                                  \n              2. What machine learning algorithms and data analysis methods are most suitable for developing\n                accurate predictive models for dengue outbreak prediction in the context of Santa Cruz,\n                Laguna?                                                           \n              3. How can the developed predictive models be effectively integrated into the existing workflow\n                of the Provincial Health Office to facilitate timely decision-making and intervention planning?\n              4. What measures can be implemented to ensure the scalability, reliability, and interpretability\n                of the predictive models for dengue outbreak preparedness, considering the resource\n                constraints and technological limitations of the Provincial Health Office in Santa Cruz,\n                                                                                  \n                Laguna?                                                           \n                                                                                  \n           General Objective and Specific Objectives                              \n                                                                                  \n           The main objective of this research is to develop and implement a web-based predictive modeling\n           system to enhance dengue outbreak preparedness and response strategies for the Provincial Health\n           Office in Santa Cruz, Laguna. To develop predictive models using machine learning algorithms to\n           forecast dengue outbreaks in Santa Cruz, Laguna, based on historical dengue case data.\n                                                                                  \n                                                                                  \n              1. Design and develop a user-friendly web-based platform that integrates predictive modeling\n                techniques using machine learning algorithms to forecast dengue outbreaks in Santa Cruz,\n                Laguna, based on historical dengue case data.                     \n              2. Evaluate and compare the performance of different machine learning algorithms for dengue\n                outbreak prediction in the context of Santa Cruz, Laguna, within the web-based system.\n              3. Integrate the developed predictive modeling system into the workflow of the Provincial Health\n                Office, enabling stakeholders to access and utilize the forecasting capabilities for\n                timely decision-making and intervention planning.                 \n              4. Optimize the scalability, reliability, and interpretability of the web-based predictive modeling\n                                                                                  \n                system, considering the resource constraints and technological limitations of the Provincial\n                Health Office in Santa Cruz, Laguna, to ensure its effectiveness and usability in real-world\n                applications.                                                     \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           How did others solve the problem?                                      \n                                                                                  \n              1. The researchers conducted a comprehensive review of machine learning approaches utilized\n                for dengue outbreak prediction. They evaluated various machine learning algorithms and\n                techniques applied in different regions to forecast dengue outbreaks. The study highlighted\n                the importance of feature selection, model optimization, and data preprocessing in achieving\n                accurate predictions. The findings of the review contribute to the understanding of the\n                effectiveness of machine learning in dengue outbreak prediction, providing insights for\n                researchers and public health practitioners (Singh, A., Choudhary, P., & Gupta, S., 2020).\n                                                                                  \n              2. In their research, the researchers investigated predictive modeling techniques for dengue\n                outbreak forecasting in Southeast Asia. They analyzed historical dengue case data from\n                                                                                  \n                multiple countries in the region and developed predictive models using machine learning\n                algorithms. The study emphasized the significance of incorporating environmental and\n                demographic factors in predictive modeling to enhance accuracy. By identifying the factors\n                contributing to dengue outbreaks in Southeast Asia, the research contributes to the\n                development of targeted intervention strategies in the region (Jones, C., Smith, T., & Nguyen,\n                H., 2019).                                                        \n                                                                                  \n              3. The researchers conducted a study on the integration of predictive modeling in public health\n                decision-making, focusing on dengue control programs in Latin America. They assessed the\n                                                                                  \n                impact of predictive models on decision-making processes and resource allocation strategies.\n                The study emphasized the importance of collaboration between researchers and public health\n                authorities for effective implementation. By incorporating predictive modeling into decision-\n                making processes, public health agencies can improve their response to dengue outbreaks and\n                allocate resources more efficiently (Lopez, J., Perez, M., & Garcia, A., 2018).\n                                                                                  \n              4. This systematic review evaluated the effectiveness of web-based decision support systems for\n                dengue outbreak management. The researchers reviewed existing literature on web-based\n                platforms developed for dengue surveillance, prediction, and response. They identified key\n                                                                                  \n                features and functionalities that contribute to the success of such systems. The findings\n                highlight the potential of web-based decision support systems to enhance dengue outbreak\n                management through improved data collection, analysis, and decision-making processes\n                (Garcia, F., Ramirez, L., & Espinoza, R., 2017).                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n              5. The researchers conducted case studies on optimizing dengue outbreak response strategies\n                using machine learning techniques in urban settings. They analyzed dengue surveillance data\n                from densely populated areas and developed predictive models to identify high-risk areas and\n                prioritize intervention efforts. Their findings underscored the importance of data-driven\n                decision-making in effective outbreak response. By leveraging machine learning techniques,\n                public health authorities can proactively identify and respond to dengue outbreaks, reducing\n                the burden of the disease on urban populations (Shah, S., Khan, A., & Ahmed, S., 2021).\n                                                                                  \n              6. The researchers conducted a study on the utilization of data-driven approaches for dengue\n                                                                                  \n                outbreak prediction and management. They analyzed historical dengue case data and\n                environmental variables to develop predictive models using machine learning algorithms. The\n                study focused on identifying spatiotemporal patterns and risk factors associated with dengue\n                transmission. By integrating data-driven approaches into public health practices, the research\n                aims to enhance early warning systems and improve outbreak response strategies (Gupta, R.,\n                Paul, S., & Chakraborty, S., 2019).                               \n                                                                                  \n              7. This research explored the role of community engagement and citizen science in dengue\n                outbreak surveillance and response. The researchers implemented participatory approaches,\n                involving local communities in data collection, analysis, and decision-making processes. The\n                                                                                  \n                study emphasized the importance of community-based interventions, such as vector control\n                measures and health education campaigns, in preventing and mitigating dengue outbreaks. By\n                empowering communities to take an active role in dengue control efforts, the research aims to\n                strengthen resilience and promote sustainable strategies for disease prevention (Telle, O.,\n                Vignolles, C., & Diallo, M., 2015).                               \n                                                                                  \n                                                                                  \n                                                                                  \n            How do you intend to solve the problem?                               \n                                                                                  \n           To deal with the control of the dengue outbreak in Santa Cruz, Laguna, we provide a comprehensive\n           approach using innovative technology and methods based on data. First, we\'ll use machine learning\n           algorithms to create and deploy a predictive modeling system. The system aims to predict the\n           probability and intensity of future dengue outbreaks by examining historical dengue case data,\n           demographic data, environmental conditions, and other pertinent variables. Our goal is to utilize\n           machine learning to produce precise and timely forecasts that allow health authorities to make\n           proactive decisions. Real-time monitoring and alerting functions will also be included in the system,\n                                                                                  \n           enabling quick responses to new outbreaks and the distribution of resources to high-risk locations.\n                                                                                  \n           In addition, we will create and implement a web-based infrastructure that acts as the main hub for\n           managing the dengue outbreak in Santa Cruz, Laguna. By making data gathering, visualization, and\n           analysis easier, this platform will provide local health authorities with useful information for initiatives\n           related to prevention and control. Stakeholders will have access to full data on dengue incidence, risk\n           factors, and intervention techniques through user-friendly             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           interfaces and interactive dashboards. Furthermore, the platform would facilitate cooperation and\n           information exchange between various community stakeholders and organizations, promoting a\n           proactive and well-coordinated approach to dengue prevention. Our technology seeks to transform\n           dengue outbreak management by combining predictive modeling with an accessible web interface,\n           therefore lessening the disease\'s overall impact on the population.    \n                                                                                  \n                                    Data Collection                               \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                    Data Processing                               \n                                                                                  \n                                                                                  \n                                                                                  \n                                    Model Training                                \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                  Predictive Modeling                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                  Web-Based Platform                              \n                                     Development                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                    Integration and                               \n                                     Deployment                                   \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                     Continuous                                   \n                                                                                  \n                                    Improvement                                   \n                                                                                  \n                                                                                  \n                                                                                  \n                                    Monitoring and                                \n                                     Evaluation                                   \n                                                                                  \n                                                                                  \n                           Figure 1. Processing Framework for Web-                \n                          Based Dengue Outbreak Predictive Modeling               \n                                      System                                      \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          The processing framework begins with the collection and preprocessing of historical dengue case data,\n          demographic information, and environmental factors. Machine learning models are then trained on the\n          preprocessed data to predict future dengue outbreaks. These predictive models are integrated into a\n          web-based platform for real-time monitoring, alerting, and collaboration among stakeholders,\n          facilitating proactive decision-making and response efforts. Continuous monitoring, evaluation, and\n          improvement ensure the effectiveness and relevance of the system over time.\n                                                                                  \n                                                                                  \n                               Dengue Outbreak Management                         \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                           Input Data       Web-Based Platform                    \n                                                                                  \n                      - Historical Dengue Case - Real-Time                        \n                     Monitoring Data      - Data Visualization                    \n                     - Demographic Information - Collaboration Tools              \n                                                                                  \n                     - Environment Factors - Decision Support                     \n                                                                                  \n                                                                                  \n                                                                                  \n                                  Predictive Modeling                             \n                                                                                  \n                                                                                  \n                                Dengue Outbreak Prediction                        \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                 Decision Support System                          \n                                                                                  \n                                                                                  \n                                                                                  \n                               Dengue Outbreak Management                         \n                                                                                  \n                                                                                  \n                              Figure 2. Conceptual Framework                      \n                                                                                  \n           This figure illustrates the flow of data and processes in the proposed solution for dengue outbreak\n           management in Santa Cruz, Laguna. Input data, including historical dengue case data and demographic\n           information, is used for predictive modeling to forecast future outbreaks. The output of the predictive\n           modeling informs the decision support system, which utilizes real-time monitoring and collaboration\n           tools provided by the web-based platform to assist stakeholders in making informed decisions for\n           dengue outbreak management.                                            \n                                                                                  \n            The proposed system for dengue outbreak management in Santa Cruz, Laguna, integrates predictive\n                modeling, decision support, and real-time monitoring through a comprehensive web-\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n          based platform. The system begins with the collection of input data, including historical dengue case\n          data, demographic information, and environmental factors, which are fed into the predictive modeling\n          component. Using advanced machine learning algorithms, the predictive modeling component analyzes\n          this data to forecast future dengue outbreaks, providing valuable insights into the likelihood and severity\n          of outbreaks.                                                           \n                                                                                  \n           The output of the predictive modeling serves as input for the decision support system, which assists\n           stakeholders in making informed decisions for dengue outbreak management. This decision support\n           system leverages real-time monitoring data and collaboration tools provided by the web-based\n           platform to enable proactive decision-making and resource allocation, ultimately enhancing the\n           effectiveness of dengue prevention and control efforts in the municipality.\n           The objectives of the system are multifaceted, aiming to improve the management of dengue outbreaks\n           in Santa Cruz, Laguna, through data-driven approaches. Firstly, the system seeks to provide accurate\n           and timely predictions of future dengue outbreaks, enabling proactive measures to be taken to mitigate\n           their impact. Secondly, it aims to facilitate informed decision-making by stakeholders through the\n           integration of real-time monitoring data and decision-support tools.   \n           Additionally, the system aims to enhance collaboration among stakeholders and promote transparency\n           in dengue outbreak management practices.                               \n                                                                                  \n           Overall, the system is designed to improve the efficiency and effectiveness of dengue prevention and\n           control efforts, ultimately reducing the burden of the disease on the community\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Target users / Beneficiaries:(Describe each Beneficiary)               \n                                                                                  \n           This study will be beneficial to the users as follows:                 \n                                                                                  \n              ●  Provincial Health Office of Santa Cruz, Laguna: Responsible for public health management,\n                 including dengue outbreak preparedness and response.             \n              ●  Local Health Authorities: Health officials and practitioners involved in monitoring,\n                 surveillance, and intervention strategies for dengue prevention and control.\n              ●  Community Health Workers: Frontline healthcare workers responsible for implementing\n                 dengue prevention programs and providing healthcare services at the community level.\n                                                                                  \n              ●  Residents of Santa Cruz, Laguna: General population residing in the municipality who benefit\n                 from improved dengue prevention measures and timely outbreak response efforts.\n              ●  Educational Institutions: Schools and educational facilities in Santa Cruz, Laguna, which may\n                 implement dengue awareness and prevention programs to protect students and staff from\n                 dengue infections.                                               \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Significance of study:                                                 \n                                                                                  \n           The study\'s potential to improve the efficacy of Santa Cruz dengue outbreak preparedness and\n           response activities is what makes it notable. Cruz, Laguna. Tropical countries like the Philippines\n           continue to face serious public health risks from dengue fever, as epidemics can result in high rates of\n           illness, mortality, and financial hardship. The purpose of this project is to give the Provincial Health\n           Office of Santa Cruz with insights into the local context through the development and application of\n           predictive modeling tools. Cruz, Laguna, has important resources for predicting and reducing the\n           effects of dengue outbreaks. By facilitating proactive decision-making, these prediction models can\n           help health authorities better allocate resources and carry out focused treatments aimed at stopping the\n                                                                                  \n           disease\'s spread.                                                      \n                                                                                  \n           Implications for public health research and practice from this study. It adds to the expanding body of\n           knowledge on infectious disease epidemiology and outbreak prediction by utilizing machine learning\n           and data analysis approaches. The knowledge gathered from this study can help develop dengue\n           prevention tactics outside of Santa Cruz, Laguna, as well as in other areas dealing with comparable\n           issues. Furthermore, the creation of a web-based predictive modeling system offers a platform that is\n           accessible and scalable, allowing other public health organizations and municipalities to adopt and use\n           it. In the end, this study\'s conclusions may help prevent dengue fever-related deaths, lower medical\n           expenses, and enhance the general health and wellbeing of dengue-affected communities.\n                                                                                  \n                                                                                  \n                                                                                  \n          Survey Matrix                                                           \n                                                                                  \n                                                                                  \n               Title of Study        Purpo             Technology   Year          \n                                      se                                          \n                                                                                  \n                                                                                  \n           \"Machine Learning  To review the effectiveness Machine   2020          \n           Approaches for Dengue of machine learning Learning                     \n           Outbreak Prediction: A approaches for dengue Algorithms                \n           Review\"           outbreak prediction.                                 \n                                                                                  \n                                                                                  \n                                                                                  \n           \"Community         To explore the role of Community      2019          \n           Engagement and Citizen community engagement and Engagement,            \n           Science in Dengue citizen science in dengue Citizen Science            \n           Outbreak Surveillance\" outbreak surveillance.                          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           \"Web-Based Decision To evaluate the effectiveness Web-Based 2021       \n           Support Systems for of web-based decision Technologies                 \n           Dengue Outbreak                                                        \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           Management: A     support systems for dengue                           \n           Systematic        outbreak management.                                 \n           Review\"                                                                \n                                                                                  \n           \"Predictive Modeling of To develop predictive Predictive  2019         \n           Dengue Outbreaks Using models for dengue outbreak Modeling,            \n           Historical Data: Case forecasting in Southeast Asia. Machine Learning  \n           Studies from Southeast                  Algorithms                     \n           Asia\"                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n           \"Integration of    To assess the impact of Predictive Modeling, 2022   \n           Predictive Modeling in predictive modeling on public Public Health Decision-\n           Public Health Decision- health decision-making in Making               \n                                                                                  \n           Making: Lessons from dengue control programs.                          \n           Dengue Control                                                         \n           Programs\"                                                              \n                                                                                  \n                                                                                  \n                                                                                  \n          Gap Analysis                                                            \n                                                                                  \n                                                                                  \n               TITLE           DESCRIPTION        SCOPE/TECHNOLOGY   YEA          \n                                                                     R            \n                                                                                  \n                             TECHNOLOGY  (Machine Learning )                      \n                                                                                  \n           \"Assessing the                                                         \n           Effectiveness of Evaluates the performance of Machine     2021         \n                         various machine learning Learning                        \n           Machine                                                                \n                         algorithms in predicting dengue Algorithms               \n           Learning                                                               \n                         outbreaks based on historical                            \n           Algorithms for                                                         \n                         data.                                                    \n           Dengue Outbreak                                                        \n           Prediction\"                                                            \n           \"Improving                                                             \n           Predictive    Investigates methods to enhance Predictive  2023         \n                         the accuracy and reliability of Modeling, Machine        \n           Modeling                                                               \n                         predictive models for dengue Learning                    \n           Techniques for                                                         \n                         outbreak forecasting using Algorithms                    \n           Dengue                                                                 \n                         machine learning.                                        \n           Outbreak                                                               \n           Forecasting\"                                                           \n           \"Addressing the Explores techniques to address Imbalanced Data 2022    \n           Challenges of imbalanced datasets commonly Handling, Machine           \n           Imbalanced Data in encountered in dengue outbreak Learning             \n           Dengue Outbreak prediction.            Algorithms                      \n           Prediction\"                                                            \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n              TITLE          DESCRIPTION       SCOPE/TECHNOLOGY     YEAR          \n                                                                                  \n                                                                                  \n                               TECHNOLOGY (Data Analysis)                         \n                                                                                  \n           \"Exploring                                                             \n           Advanced     Explores advanced statistical Advanced Statistical 2022   \n                        methods, such as time series Methods, Data Analysis       \n           Statistical                                                            \n                        analysis and spatial modeling, to Techniques              \n           Methods                                                                \n                        uncover complex patterns and                              \n           for                                                                    \n                        trends in dengue outbreak data                            \n           Dengue                                                                 \n                        for more accurate analysis and                            \n           Outbreak     prediction.                                               \n           Analysis\"                                                              \n           \"Integrating                                                           \n           Geographic   Investigates the integration of Geographic 2020           \n                        geographic information systems Information Systems        \n           Information                                                            \n                        (GIS) to enhance the spatial (GIS), Data Analysis         \n           Systems (GIS)                                                          \n                        analysis of dengue outbreak Techniques                    \n           in Dengue                                                              \n                        data, providing valuable insights                         \n           Outbreak                                                               \n                        into the spatial distribution and                         \n           Analysis\"    spread of the disease.                                    \n           \"Automating  Focuses on developing  Automated Data Analysis, 2023      \n           Data Analysis automated data analysis Data Analysis Techniques         \n           Processes for processes and algorithms to                              \n           Efficient    streamline dengue outbreak                                \n           Dengue       surveillance and response                                 \n           Outbreak     efforts, enabling timely                                  \n           Surveillance\" intervention and resource                                \n                        allocation.                                               \n           \"Utilizing Big Explores the potential of big data Big Data Analytics, Data 2021\n           Data Analytics analytics to analyze large Analysis Techniques          \n           for          volumes of heterogeneous data                             \n           Comprehensive sources, including social media                          \n           Dengue       and environmental data, for                               \n           Outbreak     comprehensive dengue outbreak                             \n           Management\"  management and prediction.                                \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Project Title: A Secure Dengue Case Management System with User Authentication, Data Analysis,  \\nand Intervention Planning Capabilities for Provincial Health Office in Santa Cruz, Laguna\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Topic: Machine Learning, Data Analysis, Cloud Computing, User Authentication and Security, Web-\\nbased  Interface,  Mobile  Applications,  Intervention  Planning  and  Communication,  Breakbone  Fever, \\nEpidemiology, Mapping, Aedes aegypti\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Proponents:  JOSEPH G. COLLANTES \\n                       CYLA DENDEYL M. TRINIDAD \\n                       JOYCE ANNE M. VIRAY\n5  B. Technical Description \\nA virus called dengue (also known as break-bone fever) is transmitted from mosquitoes to humans. In \\ntropical  and  subtropical  regions,  it  is  more  common.  The  majority  of  dengue  patients  experience  no \\nsymptoms. However, the most typical symptoms for those who do include rash, nausea,  body aches, \\nheadaches, and high fever. Most will recover in one to two weeks as well. Some people require hospital \\ncare when they have severe dengue. \\nIn the Philippines, a dengue outbreak was first reported as early as 1906, and the first severe dengue \\nepidemic was documented in Manila in 1953. Since then, dengue has been hyperendemic in most areas \\nof the country with a general increase in the number of dengue cases over time. \\nAs per the website themedicalcity.com, Dengue is a disease caused by any one of four closely related \\ndengue viruses (DENV 1, DENV 2, DENV 3, or DENV 4). The viruses are transmitted to humans by \\nthe bite of an infected mosquito. The Aedes aegypti mosquito is the most important transmitter or vector \\nof dengue viruses. Another mosquito that transmits the dengue virus is Aedes albopictus. \\nThe  study  of  S.  Richards,  entitled  “PICTUREE—Aedes:  A  Web  Application  for  Dengue  Data \\nVisualization and Case Prediction” is a web application designed to combat dengue fever. It combines \\ndata visualization tools with forecasting models to analyze various factors like temperature, precipitation, \\nmosquito presence, and historical dengue cases. This allows users to assess risk for future outbreaks and \\npredict potential case numbers, ultimately helping public health officials take preventive measures. \\nThe system offers valuable insights and tools that can complement the development of a Secure Dengue \\nCase Management System for the Provincial Health Office in Santa Cruz, Laguna. By incorporating data \\nvisualization tools and forecasting models.  \\nThis  allows  public  health  officials  to  assess  the  risk  of  future  outbreaks  and  predict  potential  case \\nnumbers,  enabling  them  to  take  proactive  preventive  measures.  Integrating  such  predictive  analytics \\ncapabilities into a Secure Dengue Case Management System can enhance its effectiveness in identifying \\nhigh-risk  areas,  allocating  resources  efficiently,  and  planning  targeted  interventions  to  mitigate  the\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               impact of dengue fever in the region.\n1                                                                                                                                                                                                           Statement of the Problem: \\nDengue  fever  is  a  major  public  health  concern  in  Santa  Cruz, Laguna.  The  Provincial  Health  Office \\n(PHO) requires a system to manage dengue cases effectively. This study aims to address the following \\ncritical issues:  \\n● \\nHow  can  a  secure  web-based  system  efficiently  collect  and  manage  Dengue  case  data  while \\nensuring patient data privacy? \\n● \\nHow can the system utilize collected data to monitor Dengue trends, detect early outbreak signs \\nin specific barangays, and provide real-time insights to the Provincial Health Office (PHO)? \\n● \\nHow do the existing security measures within the Dengue case management  system mitigate \\nrisks to patient confidentiality and data integrity? \\n● \\nHow can a Dengue Case Management System integrate user authentication, data analysis, and \\nintervention planning functionalities to meet the unique requirements of the PHO in Santa \\nCruz, Laguna?\n2  General Objective and Specific Objectives \\nThe goal of this research is to develop a secure dengue case management system with functionalities for \\nuser  authentication,  data  analysis,  and  intervention  planning,  specifically  designed  for  the  Provincial \\nHealth Office (PHO) in Santa Cruz, Laguna. The system aims to  contribute to more effective public \\nhealth surveillance and response strategies. \\n● \\nTo  design  and \\nimplement  user  authentication  for  authorized  access,  and  protect  patient \\nconfidentiality and system integrity. \\n● \\nTo  collect,  preprocess,  and \\nintegrate  Dengue  case  data \\ninto  a  centralized  database \\nfor \\ncomprehensive analysis and surveillance. \\n● \\nTo employ advanced data analysis techniques, including machine learning, to identify Dengue \\ntransmission patterns and high-risk areas. \\n● \\nTo  develop  a  user-friendly \\ninterface \\nfor \\nseamless \\ninteraction  and  efficient  data  entry, \\nvisualization, and reporting. \\n● \\nTo  implement  intervention  planning  functionalities  enabling  targeted  strategies  for  vector \\ncontrol, resource allocation, and community outreach.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               0 1 2 3 4 5 6\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       How do you intend to solve the problem? \\n The  proponent  of \\nthe  study  plans \\nto  solve \\nthe  problem  by  developing  a  Secure  Dengue  Case \\nManagement System with User Authentication, Data Analysis, and Intervention Planning Capabilities \\nfor the Provincial Health Office in Santa Cruz, Laguna. This system will create a secure online system \\nto help the Santa Cruz, Laguna, health department manage dengue fever. The system keeps data safe, \\nanalyzes trends in cases, and even helps plan actions to stop outbreaks. Overall, this tool aims to improve \\npublic health in the area. \\n \\nFigure 1.  Conceptual Framework of Dengue Case Management System            \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n5  Target users / Beneficiaries:(Describe each Beneficiary) \\n1.  Healthcare Providers:  \\n● \\ninclude  doctors,  nurses,  and  other  medical  staff  involved  in  diagnosing  and  treating \\ndengue cases.  \\n● \\nThey would benefit from the system\'s capabilities for securely accessing patient data, \\nanalyzing trends, and planning interventions tailored to individual cases. \\n2. \\nPublic Health Officials: \\n● \\n Public health officials at local health departments or government agencies responsible \\nfor overseeing dengue control efforts would benefit from the system\'s data analysis \\ntools to monitor disease trends, identify high-risk areas, and allocate resources \\neffectively. \\n3.  Community Health Workers:  \\n● \\nThese frontline workers are crucial in community outreach and education about \\ndengue prevention measures.  \\n● \\nThey would benefit from the system\'s intervention planning capabilities to implement \\ntargeted interventions and educational campaigns in high-risk areas. \\n4.  Residents of Santa Cruz, Laguna:  \\n● \\nThe general population in Santa Cruz, Laguna, would benefit from the improved \\ndengue case management facilitated by the system.  \\n● \\nThis includes timely intervention planning to reduce disease transmission, better \\naccess to healthcare services, and increased awareness about dengue prevention            \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0\n0                                                                                                                                                measures. \\n5.  Researchers and Epidemiologists:  \\n● \\nResearchers and epidemiologists studying dengue transmission and control would \\nbenefit from access to the system\'s data analysis capabilities, which can provide \\nvaluable insights into disease dynamics and inform future research and intervention \\nstrategies.\n1  Significance of study: \\nCreating  a  secure  dengue  case  management  system  with  user  authentication,  data  analysis,  and \\nintervention planning capabilities for the provincial health office in Santa Cruz, Laguna. The system will \\nhelp predict outbreaks and give real-time information to health officials. The study will also make sure \\npatient privacy is protected. This new system can greatly improve how dengue is managed in Santa Cruz, \\nLaguna.\n\n                                                                                                                                     0                                1                                                                                                                                 2                                                                            3     4\n0                                                                                                                       Title of Study                          Variety                                                                                                                           Purpose                                                                   Technology  Year\n1                                                         User Experience \\nEvaluation of a \\nSecure Dengue \\nCase Management \\nSystem     Closed-ended, Likert \\nscale                                                     Assess user satisfaction \\nwith the system\'s \\nusability and \\nfunctionality.                             Web-based \\nsurvey tool \\n(e.g., \\nSurveyMonkey)  2022\n2                                                                    Assessing Data \\nQuality in a \\nDengue Case \\nManagement \\nSystem    Open-ended, Multiple \\nChoice                                        Evaluate the accuracy, \\ncompleteness, and \\ntimeliness of data \\ncollected by the system.                                                     Online survey \\nplatform  2023\n3  Data-driven \\nmethods \\nfor \\ndengue  prediction \\nand \\nsurveillance \\nusing \\nreal-world \\nand  Big  Data:  A \\nsystematic review                  Dengue Outbreak  To predict and \\nmonitor  dengue-related \\noutcomes. \\nTo assess the \\nvalidity of data \\nsources \\nfor \\ndengue \\nsurveillance.  Machine \\nlearning \\nmethods \\nReal-world  data \\nand \\nBig  Data \\nsources  2022\n4                                                                                  Impact of Data \\nVisualization on \\nDengue Outbreak  Multiple Choice, \\nRating Scale                                                       Gauge the effectiveness \\nof data visualizations in \\nfacilitating informed                                                  Online survey \\nwith visual  2022\n\n                                                                              0                           1                                                                                                                                             2                        3     4\n0                                                                      Response                                                                                                                              decision-making for \\nintervention planning.                  stimuli      \n1  Perceived \\nBenefits of \\nIntervention \\nPlanning Tools for \\nDengue Control  Likert scale, Open-\\nended  Evaluate user \\nperception of the \\nsystem\'s intervention \\nplanning functionalities \\nand their impact on \\ncontrolling dengue \\noutbreaks.  Web-based \\nsurvey tool  2020\n\n                                                                                            0                                                                                                                                                                  1                                                                                         2     3\n0                                               TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                                                                                   \n1                                                              TECHNOLOGY (Machine Learning )                                                                                                                                                                                                                                                                   \n2      Predictive \\nModeling \\nof \\nDengue \\nHemorrhagic \\nFever \\nUsing \\nMachine \\nLearning  This \\nresearch \\ninvestigates \\nthe \\napplication \\nof  Machine \\nLearning \\nmodels  to  identify  factors  associated \\nwith the severity of dengue infections.  Machine \\nLearning \\nalgorithms \\n(e.g., \\nLogistic \\nRegression, \\nGradient \\nBoosting)  2021\n3  A \\nMachine \\nLearning-Based \\nFramework \\nfor \\nDengue \\nDetection \\nand \\nClassification                 This \\nstudy \\nproposes \\na  Machine \\nLearning \\nframework \\nto \\nautomate \\ndengue \\ncase \\ndetection \\nand \\nclassification using patient data.                  Deep \\nLearning \\nalgorithms \\n(e.g.,  Convolutional  Neural \\nNetworks)  2020\n4                                 Machine \\nLearning \\nfor \\nDengue \\nOutbreaks: \\nA \\nReview    This review analyzes existing Machine \\nLearning \\napplications \\nfor \\ndengue \\noutbreak prediction, spread prediction, \\nand mosquito habitat identification.                                                   Various  Machine  Learning \\nalgorithms  2019\n\n                                                                                                                                                            0\n0                                                                                                               TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR\n1                                                                                                                                  TECHNOLOGY (Data Analysis)\n2  Spatial Analysis \\nof Dengue Fever \\n This study explores the use of \\n GIS, Spatial statistics \\n 2023 \\nGeographic Information Systems (GIS) \\nOutbreaks\n\n                                                                              0                                                                                                                                                                     1                                                     2     3\n0                                                                                                                                                                    and spatial analysis techniques to \\nidentify hotspots of dengue \\ntransmission.                                                            \n1                   Data Mining \\nTechniques for \\nDengue Case \\nClassification  This research investigates the \\napplication of data mining techniques \\nlike clustering and association rule \\nlearning to identify patterns in dengue \\ncase data.                                Data mining algorithms  2022\n2  Visualizing \\nDengue Fever \\nTrends: An \\nInteractive \\nDashboard \\nApproach                                This study proposes an interactive \\ndashboard using data visualization \\ntechniques to explore trends and \\npatterns in dengue cases.  Data visualization tools \\n(e.g., Tableau, Power BI)  2021\n3                                     Big Data \\nAnalytics for \\nDengue Control                      This review analyzes the potential of \\nbig data analytics for dengue control, \\nincluding data collection, storage, \\nprocessing, and analysis.           Big data frameworks (e.g., \\nHadoop, Spark)  2020\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      A. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Project Title: \\nWeb-Based Dengue Outbreak Predictive Modeling System for Provincial Health Office in Santa \\nCruz, Laguna\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Topic: \\nMachine  Learning  Algorithms,  Feature  Selection  and  Engineering,  Cross-Validation  and  Model \\nEvaluation,  Hyperparameter \\nTuning, \\nEnsemble \\nLearning,  Model \\nInterpretability, \\nSoftware \\nDevelopment, Data Privacy and Security\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Proponents: JOSEPH G. COLLANTES \\n                        CYLA DENDEYL M. TRINIDAD \\n                         JOYCE ANNE M. VIRAY\n5  B. Technical Description \\n \\nIn tropical countries like the Philippines, where epidemics place a heavy strain on healthcare systems \\nand communities, dengue fever is still a serious public health concern (WHO, 2020). Using past data \\nto predict future occurrences, predictive modeling has become an important technique for forecasting \\nand  minimizing  the  impact  of  dengue  outbreaks.  The  purpose  of  this  study  is  to  create  and  assess \\npredictive models based on machine learning that are customized for the unique circumstances of Santa \\nCruz, Laguna, to improve the Provincial Health Office\'s readiness and reaction. \\n \\nMachine \\nlearning  algorithms,  which \\nrange \\nfrom  decision \\ntrees  and \\nrandom \\nforests \\nto  more \\nsophisticated  methods  like  gradient  boosting  machines  and  neural  networks,  have  been  shown  in \\nearlier studies to be effective in predicting dengue outbreaks (Shiraz et al., 2018; Lee et al., 2020). The \\nproposed study uses these techniques to look for patterns and trends in the dengue incidence data that \\nSanta  Cruz,  Laguna,  and  others  create  precise  prediction  models \\nthat  have  a  high  degree  of \\ndependability in foretelling future epidemics. \\n \\nA  key  component  of  developing  predictive  models  for  dengue  epidemic  preparedness  is  feature \\nengineering and selection. Research has demonstrated that model performance can be greatly enhanced \\nby  choosing  pertinent  parameters  pertaining \\nto  climate,  demography,  and  past  dengue  cases \\n(Rajarethinam et al., 2019; Wongkoon et al., 2021). Principal component analysis (PCA) and feature \\nimportance ranking are two methods that will be used in this study to determine which variables are \\nmost useful and should go into the prediction models. \\nIn  order  to  evaluate  the  effectiveness  of  predictive  models  for  dengue  epidemic  preparedness, \\nevaluation and validation are crucial processes. To make sure the created models are reliable\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              and broadly applicable, cross-validation methods like k-fold cross-validation will be applied (Kohavi, \\n1995).  In  order  to  measure  the  predictive  performance  of  the  models  and  direct  decision-making \\nprocesses inside the Provincial Health Office of Santa, metrics including accuracy, precision, recall, \\nand F1-score will be produced. Cruz, Laguna.\n1                                                                                                                                                                                           Statement of the Problem: \\n \\nIn the Province of Santa Cruz, Laguna, the Provincial Health Office faces challenges in effectively \\nmanaging dengue outbreaks, leading to suboptimal response strategies and resource allocation. With \\nthe aim of improving dengue outbreak preparedness and response efforts, this study seeks to address \\nthe following problems: \\n \\n1.  How can predictive modeling techniques be utilized to enhance dengue outbreak forecasting \\nand preparedness strategies for the Provincial Health Office in Santa Cruz, Laguna? \\n2.  What machine learning algorithms and data analysis methods are most suitable for developing \\naccurate  predictive  models  for  dengue  outbreak  prediction  in  the  context  of  Santa  Cruz, \\nLaguna? \\n3.  How can the developed predictive models be effectively integrated into the existing workflow \\nof the Provincial Health Office to facilitate timely decision-making and intervention planning? \\n4.  What measures can be implemented to ensure the scalability, reliability, and interpretability \\nof \\nthe  predictive  models \\nfor  dengue  outbreak  preparedness,  considering \\nthe \\nresource \\nconstraints  and  technological  limitations  of  the  Provincial  Health  Office  in  Santa  Cruz, \\nLaguna?\n2  General Objective and Specific Objectives \\n \\nThe  main  objective  of  this  research  is  to  develop  and  implement  a web-based  predictive  modeling \\nsystem  to  enhance  dengue  outbreak  preparedness  and  response  strategies  for  the  Provincial  Health \\nOffice  in  Santa  Cruz,  Laguna.  To develop  predictive  models  using  machine  learning  algorithms  to \\nforecast dengue outbreaks in Santa Cruz, Laguna, based on historical dengue case data. \\n \\n1.  Design and develop a user-friendly web-based platform that integrates predictive modeling \\ntechniques  using  machine  learning  algorithms  to  forecast  dengue  outbreaks  in  Santa  Cruz, \\nLaguna, based on historical dengue case data. \\n2. \\nEvaluate and compare the performance of different machine learning algorithms for dengue \\noutbreak prediction in the context of Santa Cruz, Laguna, within the web-based system. \\n3. \\nIntegrate the developed predictive modeling system into the workflow of the Provincial Health \\nOffice, enabling stakeholders to access and utilize the forecasting capabilities for \\ntimely decision-making and intervention planning. \\n4. Optimize the scalability, reliability, and interpretability of the web-based predictive modeling \\nsystem, considering the resource constraints  and technological limitations of the Provincial \\nHealth Office in Santa Cruz, Laguna, to ensure its effectiveness and usability in real-world \\napplications.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n0  5. \\nThe  researchers  conducted  case  studies  on  optimizing  dengue  outbreak  response  strategies \\nusing machine learning techniques in urban settings. They analyzed dengue surveillance data \\nfrom densely populated areas and developed predictive models to identify high-risk areas and \\nprioritize  intervention  efforts.  Their  findings  underscored  the  importance  of  data-driven \\ndecision-making in effective outbreak response. By leveraging machine learning techniques, \\npublic health authorities can proactively identify and respond to dengue outbreaks, reducing \\nthe burden of the disease on urban populations (Shah, S., Khan, A., & Ahmed, S., 2021). \\n \\n6. \\nThe  researchers  conducted  a  study  on  the  utilization  of  data-driven  approaches  for  dengue \\noutbreak  prediction  and  management.  They  analyzed  historical  dengue  case  data  and \\nenvironmental variables to develop predictive models using machine learning algorithms. The \\nstudy focused on identifying spatiotemporal patterns and risk factors associated with dengue \\ntransmission. By integrating data-driven approaches into public health practices, the research \\naims to enhance early warning systems and improve outbreak response strategies (Gupta, R., \\nPaul, S., & Chakraborty, S., 2019). \\n \\n7. \\nThis  research  explored  the  role  of  community  engagement  and  citizen  science  in  dengue \\noutbreak surveillance and response. The researchers implemented participatory approaches, \\ninvolving local communities in data collection, analysis, and decision-making processes. The \\nstudy emphasized the importance of community-based interventions, such as vector control \\nmeasures and health education campaigns, in preventing and mitigating dengue outbreaks. By \\nempowering communities to take an active role in dengue control efforts, the research aims to \\nstrengthen  resilience  and  promote  sustainable  strategies  for  disease  prevention  (Telle,  O., \\nVignolles, C., & Diallo, M., 2015).\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     How do you intend to solve the problem? \\n \\nTo deal with the control of the dengue outbreak in Santa Cruz, Laguna, we provide a comprehensive \\napproach using innovative technology and methods based on data. First, we\'ll use machine learning \\nalgorithms  to  create  and  deploy  a  predictive  modeling  system.  The  system  aims  to  predict  the \\nprobability  and  intensity  of  future  dengue  outbreaks  by  examining  historical  dengue  case  data, \\ndemographic  data,  environmental  conditions,  and  other  pertinent  variables.  Our  goal  is  to  utilize \\nmachine  learning  to  produce  precise  and  timely  forecasts  that  allow  health  authorities  to  make \\nproactive decisions. Real-time monitoring and alerting functions will also be included in the system, \\nenabling quick responses to new outbreaks and the distribution of resources to high-risk locations. \\nIn addition, we will create and implement a  web-based infrastructure that acts as  the main hub for \\nmanaging the dengue outbreak in Santa Cruz, Laguna. By making data gathering, visualization, and \\nanalysis easier, this platform will provide local health authorities with useful information for initiatives \\nrelated to prevention and control. Stakeholders will have access to full data on dengue incidence, risk \\nfactors, and intervention techniques through user-friendly\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n0  based platform. The system begins with the collection of input data, including historical dengue case \\ndata, demographic information, and environmental factors, which are fed into the predictive modeling \\ncomponent. Using advanced machine learning algorithms, the predictive modeling component analyzes \\nthis data to forecast future dengue outbreaks, providing valuable insights into the likelihood and severity \\nof outbreaks. \\n \\nThe output of the predictive modeling serves as input for the decision support system, which assists \\nstakeholders in making informed decisions for dengue outbreak management. This decision support \\nsystem  leverages  real-time  monitoring  data  and  collaboration  tools  provided  by  the  web-based \\nplatform  to  enable  proactive  decision-making  and  resource  allocation,  ultimately  enhancing  the \\neffectiveness of dengue prevention and control efforts in the municipality. \\n \\nThe objectives of the system are multifaceted, aiming to improve the management of dengue outbreaks \\nin Santa Cruz, Laguna, through data-driven approaches. Firstly, the system seeks to provide accurate \\nand timely predictions of future dengue outbreaks, enabling proactive measures to be taken to mitigate \\ntheir  impact.  Secondly,  it  aims  to  facilitate  informed  decision-making  by  stakeholders  through  the \\nintegration of real-time monitoring data and decision-support tools. \\nAdditionally, the system aims to enhance collaboration among stakeholders and promote transparency \\nin dengue outbreak management practices. \\n \\nOverall, the system is designed to improve the efficiency and effectiveness of dengue prevention and \\ncontrol efforts, ultimately reducing the burden of the disease on the community\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Target users / Beneficiaries:(Describe each Beneficiary) \\n \\nThis study will be beneficial to the users as follows: \\n \\n● \\nProvincial Health Office of Santa Cruz, Laguna: Responsible for public health management, \\nincluding dengue outbreak preparedness and response. \\n● \\nLocal  Health  Authorities:  Health  officials  and  practitioners \\ninvolved \\nin  monitoring, \\nsurveillance, and intervention strategies for dengue prevention and control. \\n● \\nCommunity  Health  Workers:  Frontline  healthcare  workers  responsible  for  implementing \\ndengue prevention programs and providing healthcare services at the community level. \\n● \\nResidents of Santa Cruz, Laguna: General population residing in the municipality who benefit \\nfrom improved dengue prevention measures and timely outbreak response efforts. \\n● \\nEducational Institutions: Schools and educational facilities in Santa Cruz, Laguna, which may \\nimplement  dengue  awareness  and  prevention  programs  to  protect  students  and  staff  from \\ndengue infections.\n\n                                                                                  0                                                                                                       1                                          2     3\n0                                                                    Title of Study                                                                                               Purpo\\nse                                 Technology  Year\n1      \"Machine Learning \\nApproaches for Dengue \\nOutbreak Prediction: A \\nReview\"        To review the effectiveness \\nof machine learning \\napproaches for dengue \\noutbreak prediction.            Machine \\nLearning \\nAlgorithms  2020\n2  \"Community \\nEngagement and Citizen \\nScience in Dengue \\nOutbreak Surveillance\"  To explore the role of \\ncommunity engagement and \\ncitizen science in dengue \\noutbreak surveillance.  Community \\nEngagement, \\nCitizen Science  2019\n3                       \"Web-Based Decision \\nSupport Systems for \\nDengue Outbreak                                                   To evaluate the effectiveness \\nof web-based decision                   Web-Based \\nTechnologies  2021\n\n                                                                                                                        0                                                                                                               1                                                        2     3\n0                                                                                    Management: A \\nSystematic \\nReview\"                                                               support systems for dengue \\noutbreak management.                                                               \n1               \"Predictive Modeling of \\nDengue Outbreaks Using \\nHistorical Data: Case \\nStudies from Southeast \\nAsia\"                             To develop predictive \\nmodels for dengue outbreak \\nforecasting in Southeast Asia.   Predictive \\nModeling, \\nMachine Learning \\nAlgorithms  2019\n2  \"Integration of \\nPredictive Modeling in \\nPublic Health Decision- \\nMaking: Lessons from \\nDengue Control \\nPrograms\"  To assess the impact of \\npredictive modeling on public \\nhealth decision-making in \\ndengue control programs.  Predictive Modeling, \\nPublic Health Decision- \\nMaking  2022\n\n                                                                                                         0                                                                                                                                                  1                                                            2     3\n0                                                          TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEA\\nR                                                                                                                                                                                                                      \n1                                                                           TECHNOLOGY (Machine Learning )                                                                                                                                                                                                                      \n2  \"Assessing the \\nEffectiveness of \\nMachine \\nLearning \\nAlgorithms for \\nDengue Outbreak \\nPrediction\"                  Evaluates the performance of \\nvarious machine learning \\nalgorithms in predicting dengue \\noutbreaks based on historical \\ndata.                              Machine \\nLearning \\nAlgorithms  2021\n3                   \"Improving \\nPredictive \\nModeling \\nTechniques for \\nDengue \\nOutbreak \\nForecasting\"  Investigates methods to enhance \\nthe accuracy and reliability of \\npredictive models for dengue \\noutbreak forecasting using \\nmachine learning.       Predictive \\nModeling, Machine \\nLearning \\nAlgorithms  2023\n4                     \"Addressing the \\nChallenges of \\nImbalanced Data in \\nDengue Outbreak \\nPrediction\"                                  Explores  techniques  to  address \\nimbalanced  datasets  commonly \\nencountered in dengue outbreak \\nprediction.  Imbalanced Data \\nHandling, Machine \\nLearning \\nAlgorithms  2022\n\n                                                                                             0                                                                                                                                                                                                                               1                                                                     2     3\n0                                                TITLE \\nDESCRIPTION \\nSCOPE/TECHNOLOGY \\nYEAR                                                                                                                                                                                                                                                                                                            \n1                                                                   TECHNOLOGY (Data Analysis)                                                                                                                                                                                                                                                                                                            \n2          \"Exploring \\nAdvanced \\nStatistical \\nMethods \\nfor \\nDengue \\nOutbreak \\nAnalysis\"                 Explores advanced statistical \\nmethods, such as time series \\nanalysis and spatial modeling, to \\nuncover complex patterns and \\ntrends in dengue outbreak data \\nfor more accurate analysis and \\nprediction.            Advanced Statistical \\nMethods, Data Analysis \\nTechniques  2022\n3   \"Integrating \\nGeographic \\nInformation \\nSystems (GIS) \\nin Dengue \\nOutbreak \\nAnalysis\"  Investigates the integration of \\ngeographic information systems \\n(GIS) to enhance the spatial \\nanalysis of dengue outbreak \\ndata, providing valuable insights \\ninto the spatial distribution and \\nspread of the disease.  Geographic \\nInformation Systems \\n(GIS), Data Analysis \\nTechniques  2020\n4  \"Automating \\nData Analysis \\nProcesses for \\nEfficient \\nDengue \\nOutbreak \\nSurveillance\"                     Focuses on developing \\nautomated data analysis \\nprocesses and algorithms to \\nstreamline dengue outbreak \\nsurveillance and response \\nefforts, enabling timely \\nintervention and resource \\nallocation.                   Automated Data Analysis, \\nData Analysis Techniques  2023\n5      \"Utilizing Big \\nData Analytics \\nfor \\nComprehensive \\nDengue \\nOutbreak \\nManagement\"    Explores the potential of big data \\nanalytics to analyze large \\nvolumes of heterogeneous data \\nsources, including social media \\nand environmental data, for \\ncomprehensive dengue outbreak \\nmanagement and prediction.                        Big Data Analytics, Data \\nAnalysis Techniques  2021', 'hello good day my name is margarine el gallardo and i will be proposing a secure dengue case management system with user application data analysis and intervention planning capabilities provision of health office in santa cruz laguna\n', '{\"status\": \"success\", \"speech_similarity\": 85.14, \"missed_keypoints\": [\"dengue epidemic\", \"dengue patients\", \"dengue disease\", \"dengue fever\", \"dengue outbreaks\"], \"added_keypoints\": [\"secure dengue\", \"dengue case\", \"dengue\", \"case management\", \"proposing secure\"], \"suggested_titles\": [\"Analysis of Dengue in Research Context\", \"Analysis of Denguemining in Research Context\", \"Analysis of Fever in Research Context\"]}', 0);
INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(103, 'mia.villarica@gmail.com', 'ChatVet_Concept_Paper.pdf', 'uploads/e47136d71a354be59ce24b1d3cfed5e9.pdf', '2025-04-25 03:48:06', '                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                    Concept Paper                                 \n                                                                                  \n           A. Basic Information                                                   \n                                                                                  \n                                                                                  \n           Project Title:                                                         \n           ChatVet: Enhancing Access to Veterinary Care for Pet Owners in Santa Cruz, Laguna\n                                                                                  \n                                                                                  \n           Topic: Natural Language Processing, Machine Learning, Chatbot, Pets, Pet Owners,\n           Veterinarian and Veterinary Clinic                                     \n                                                                                  \n                                                                                  \n                                                                                  \n           Proponent: LESLY-ANN B. VICTORIA                                       \n                                                                                  \n                                                                                  \n           B. Technical Description                                               \n                                                                                  \n                                                                                  \n           Having a pet is fun, but taking them to the vet can be challenging, especially in Santa Cruz,\n           Laguna. This project aims to tackle these challenges by creating ChatVet, an innovative\n           solution using natural language processing and machine learning. ChatVet will provide pet\n           owners with convenient access to veterinary consultation, guidance, and recommendations\n           via a user-friendly chatbot interface accessible through web development.\n                                                                                  \n           Pet ownership in Santa Cruz, Laguna, faces difficulties in accessing timely and affordable\n                                                                                  \n           veterinary care, much like other places. Pet owners often struggle to balance their pets\'\n           health needs with busy schedules. Additionally, the distance to veterinary clinics and\n           associated costs worsens the situation. To address these challenges, ChatVet will act as a\n           virtual veterinary assistant, providing pet owners with immediate access to professional\n           guidance and recommendations. By using advanced technologies like natural language\n           processing and artificial intelligence, ChatVet will provide a user-friendly platform where\n           pet owners can seek advice on various concerns, from general pet health questions to\n           specific medical issues. Through this platform, pet owners can get timely support without\n           needing to physically visit a clinic, saving both time and resources. However, if severe\n           symptoms of a pet are detected, ChatVet will automatically suggest nearby vet clinics.\n                                                                                  \n           ChatVet will work as an interactive chatbot accessible through a web-based platform. The\n           chatbot will use natural language processing algorithms to understand and respond to user\n           inquiries in real-time. By leveraging artificial intelligence, ChatVet will continuously learn\n           and improve its responses based on user interactions and feedback.     \n                                                                                  \n                                                                                  \n           According to a study by Tengco N. (2023), the average cost of vet consultations in the\n           Philippines ranges from PHP 250 to PHP 1,000. These consultations typically include a\n           general examination of the pet and a discussion of its health status. For many pet owners,\n           the expense of immediate consultations with vets is a deterrent, particularly when the pet\'s\n           condition is not severe, and their busy schedules make it difficult to visit vet clinics.\n                                                                                  \n                                                                       1          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n           Moreover, pet owners struggle to find nearby veterinary care, and while they may attempt\n           to search for symptoms on Google, there is no guarantee of accuracy.   \n                                                                                  \n           A study by D. Huang and H. Chueh (2021) titled \"Chatbot Usage Intention Analysis:\n           Veterinary Consultation\" explores the application of artificial intelligence and big data\n           technologies to develop a chatbot prototype for veterinary consultations. This addresses the\n           growing need for innovative solutions in pet healthcare. By adapting the technology\n           acceptance model, they construct a usage intention model specific to veterinary\n           consultation chatbots, aiming to understand pet owners\' inclinations toward utilizing such\n           technology. Through data collection via Google Forms and analysis using partial least\n           squares structural equation modeling, their findings underscore the significance of\n           perceived accuracy, completeness, and ease of use in enhancing user satisfaction with the\n           chatbot. Moreover, they highlight the pivotal role of perceived convenience in driving pet\n           owners\' intention to utilize the chatbot for veterinary consultations. \n                                                                                  \n                                                                                  \n                                                                                  \n           Statement of the Problem:                                              \n           In Santa Cruz, Laguna, pet owners face challenges in accessing timely and reliable\n           veterinary care.                                                       \n                                                                                  \n             1. How can acquired datasets be processed effectively for algorithm development in\n                pet health support systems?                                       \n             2. How can technology help pet owners in addressing their pet’s health concerns and\n                needs effectively?                                                \n             3. What are the differences in accuracy between online search results and ChatVet\'s\n                                                                                  \n                recommendations?                                                  \n             4. How can ChatVet ensure accuracy, reliability, and effectiveness in delivering timely\n                pet care information, tailored to Santa Cruz pet owners\' needs?   \n                                                                                  \n                                                                                  \n                                                                                  \n           Objectives: General and Specific General Objective:                    \n           The main objective of this study is to design and develop a ChatVet to enhance access to\n           veterinary care for pet owners in Santa Cruz, Laguna.                  \n                                                                                  \n           Specifically, it aims to:                                              \n                                                                                  \n             1. Process acquired datasets effectively for algorithm development in pet health\n                support systems, ensuring that ChatVet provides accurate and reliable\n                recommendations to pet owners.                                    \n                                                                                  \n             2. Utilize technology to effectively address pet owners\' pet health concerns and needs,\n                providing accessible and timely guidance through the ChatVet platform.\n             3. Determine the differences in accuracy between online search results and ChatVet\'s\n                recommendations, thereby evaluating the reliability of ChatVet as a resource for pet\n                owners.                                                           \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       2          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n             4. Ensure that ChatVet maintains accuracy, reliability, and effectiveness in delivering\n                timely pet care information tailored to Santa Cruz pet owners\' needs by\n                incorporating user feedback and refining the chatbot\'s algorithms accordingly.\n                                                                                  \n                                                                                  \n           How did others solve the problem?                                      \n                                                                                  \n             1. The researchers describe their study on the application of artificial intelligence and\n                big data technologies to develop a chatbot prototype for veterinary consultations.\n                Their work addresses a growing need for innovative solutions in pet healthcare. By\n                adapting the technology acceptance model, they construct a usage intention model\n                specific to veterinary consultation chatbots, aiming to grasp pet owners\' behavioral\n                inclinations towards utilizing such technology. Through data collection via Google\n                Forms and analysis using partial least squares structural equation modeling, their\n                findings underscore the significance of perceived accuracy, completeness, and ease\n                of use in enhancing user satisfaction with the chatbot. Moreover, they highlight the\n                pivotal role of perceived convenience in driving pet owners\' intention to utilize the\n                chatbot for veterinary consultations. (Chatbot usage intention analysis: Veterinary\n                                                                                  \n                consultation, D. Huang and H. Chueh, 2021).                       \n                                                                                  \n             2. The researchers conducted a study to assess the impact of telemedicine on patient\n                care and the traditional veterinarian-client-patient relationship (VCPR) using a\n                single communication platform. They developed a multi-level survey and\n                distributed it to pet owners participating in a popular telemedicine website over a\n                period of five months. The survey gathered responses from 398 participants,\n                predominantly female residing in urban or suburban areas. Findings revealed that\n                the majority of respondents had an existing traditional care veterinarian (TCV), and\n                most of them expressed willingness to utilize alternative methods of communication\n                (AMC) if provided by their TCV. Those without a TCV often requested referral to\n                one. Consultations frequently resulted in recommendations to follow up with a TCV,\n                with a high rate of compliance among owners. Subsequent interactions with\n                traditional care veterinarians were perceived positively by owners, leading to better\n                communication and feeling more informed. Traditional care veterinarians also\n                tended to agree with the telemedicine service recommendations. The study suggests\n                that incorporating telemedicine into the traditional VCPR is generally viewed\n                                                                                  \n                favorably by pet owners. (Impact of Telemedicine on the Traditional\n                Veterinarian-Client-Patient Relationship, R. Y. Roca & R. J. McCarthy, 2019).\n                                                                                  \n             3. The researchers studied the increasing demand for pet-related services, particularly\n                in health and medical care, due to more families adopting companion animals. They\n                identified challenges in providing these services outside of veterinary hospitals,\n                emphasizing the need for expert analysis of user input to offer tailored solutions\n                based on the animal\'s symptoms. To address these challenges, they proposed an\n                expert system capable of providing specialized knowledge through appropriate\n                inference processes, responding to user-entered symptoms in natural language\n                through chat mode. They highlighted the importance of user feedback to improve\n                the accuracy of diagnoses and enhance the effectiveness of information provision.\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       3          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                (Development of Dog’s Health Care System Using Chatbot and Rule-based Expert\n                System, J. S. Im, et al., 2018)                                   \n                                                                                  \n             4. The researchers propose the development of a smart computer software, known as a\n                chatbot, which employs AI and NLP to mimic human interaction efficiently. This\n                chatbot is tailored for the field of animal healthcare, aiming to treat animals well\n                and enhance overall efficiency. Functioning as a health chatbot, it analyzes\n                user-provided information in natural language to triage patients and guide them to\n                appropriate care, thereby offering dependable and secure assistance compared to\n                conventional internet searches for symptom origins. The primary objective is to\n                create a medical chatbot leveraging artificial intelligence to recognize medical\n                conditions and provide basic information preemptively, thus reducing healthcare\n                costs and improving access to medical knowledge. (Virtual Conversational\n                AI-Assistant Chatbot for Animal Healthcare: PET-O-CARE, L. Tembhare, et al.,\n                2023)                                                             \n                                                                                  \n                                                                                  \n             5. The researchers utilized the technology acceptance model and media\n                synchronization theory to formulate a use intention model tailored for a pet disease\n                consultation chatbot. Conducting a survey within an online pet community, they\n                gathered data and employed clustering analysis through data mining techniques for\n                examination. Findings revealed that younger individuals, particularly women, and\n                                                                                  \n                those with prior experience in transporting pets to veterinary clinics exhibited higher\n                satisfaction levels with chatbot-mediated pet disease consultations. Notably,\n                perceived convenience emerged as a crucial factor, suggesting a significant\n                opportunity for veterinary clinics to enhance their services through pet disease\n                consultation chatbots. This study lays a foundational framework for evaluating\n                intelligent medical solutions in the realm of pet health and care. (An Analysis of\n                Use Intention of Pet Disease Consultation Chatbot, D. H. Huang & H. E. Chueh,\n                2020)                                                             \n                                                                                  \n           Other Related Study (Natural Language Processing, Machine Learning)    \n                                                                                  \n             6. The researchers demonstrated the effectiveness of PetBERT-mortality, a novel\n                forecasting tool, in accurately identifying deceased companion animals with\n                                                                                  \n                precision and recall rates exceeding 98% and 97% respectively, utilizing a vast\n                dataset of over 8 million electronic health records from first-opinion veterinary\n                practices. This comprehensive analysis identified 92,548 deceased cats and dogs,\n                enabling the identification of 4,146 premature deaths and elucidating their causes\n                through syndromic ICD-11 disease coding. Additionally, the tool forecasted\n                expected mortality with up to 73% predictive accuracy over 12 months, leveraging\n                past consultation events and associated factors such as age, sex, and geographical\n                                                                                  \n                circumstances. The study highlighted the potential of PetBERT-mortality to promote\n                animal welfare and support veterinary clinicians in delivering optimal care by\n                enhancing mortality monitoring and facilitating end-of-life discussions during\n                consultations. (Natural Language Processing for Forecasting Mortality and\n                Premature Death in Companion Animals, F. S. Noble, & N. A. Moubayed, 2023).\n                                                                                  \n                                                                                  \n                                                                       4          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n             7. The researchers utilized natural language processing (NLP) techniques to analyze\n                clinical records of antimicrobial usage in companion animals from January 1, 2013,\n                to December 31, 2017. A total of 343,668 records for dogs and 109,719 records for\n                cats were examined, with NLP algorithms successfully extracting dose, duration of\n                therapy, and diagnosis for a subset of records. Skin disorders and traumatic injuries\n                were identified as the most common reasons for antimicrobial administration in\n                dogs and cats, respectively. However, only 39% of records for dogs and 37% for\n                                                                                  \n                cats had complete clinical data. Of those, 73% adhered to guideline\n                recommendations for dosage. The findings underscore the potential of NLP in\n                analyzing large datasets to understand antimicrobial usage patterns, but highlight the\n                importance of data completeness and the need for improved adherence to guideline\n                recommendations for dosage in veterinary practice. (Evaluating the dose, indication\n                and agreement with guidelines of antimicrobial use in companion animal practice\n                with natural language processing, B. Hur, et al., 2022)           \n                                                                                  \n                                                                                  \n             8. The researchers have developed a large-scale algorithm capable of automatically\n                predicting all 4577 standard veterinary diagnosis codes from free text, overcoming\n                the longstanding challenge posed by the lack of systematic coding in veterinary\n                records. Leveraging a curated dataset of over 100K expert-labeled veterinary notes\n                and over one million unlabeled notes, their algorithm, based on an adapted\n                                                                                  \n                Transformer architecture, demonstrates significant improvement through large-scale\n                language modeling via pretraining and supervised learning. They systematically\n                evaluate model performance and various baselines, particularly emphasizing\n                challenging settings with substantial domain shifts between hospitals. Moreover,\n                they introduce hierarchical training to address severe data imbalances for\n                fine-grained diagnosis and provide insights into the interpretability of deep\n                networks, showcasing the potential of unsupervised learning in clinical natural\n                                                                                  \n                language processing within veterinary medicine. (VetTag: improving automated\n                veterinary diagnosis coding via large-scale language modeling, Y. Zhang, et al.,\n                2019)                                                             \n                                                                                  \n             9. The researchers applied four machine-learning algorithms to predict future\n                diagnoses of Cushing’s syndrome in dogs using clinical data from the VetCompass\n                programme in the UK. Dogs suspected of having Cushing\'s syndrome were\n                                                                                  \n                analyzed based on their final reported diagnosis. Demographic and clinical features\n                available at the first suspicion of the syndrome were included in the models. The\n                machine-learning methods effectively classified the recorded Cushing’s syndrome\n                diagnoses, with the LASSO penalized regression model demonstrating the best\n                overall performance on the test set, achieving an AUROC of 0.85 (95% CI\n                0.80–0.89), sensitivity of 0.71, specificity of 0.82, PPV of 0.75, and NPV of 0.78.\n                These findings suggest that machine-learning methods could assist practicing\n                                                                                  \n                veterinarians in predicting future diagnoses, potentially improving clinical\n                decision-making and contributing to better diagnosis of Cushing’s syndrome in\n                                                                                  \n                                                                                  \n                                                                       5          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                dogs. (Machine-learning based prediction of Cushing’s syndrome in dogs attending\n                UK primary-care veterinary practice, I. Schofield, et al, 2021)   \n                                                                                  \n             10. The researchers developed machine-learning prediction models (MLMs) utilizing\n                clinical variables from the first day of hospitalization to enhance early diagnosis of\n                leptospirosis in dogs. Incorporating patient signalment and clinicopathologic data,\n                with or without Leptospira-specific serum antibodies obtained at patient intake, the\n                                                                                  \n                models achieved high sensitivity and specificity. Trained with data from 91\n                confirmed leptospirosis cases and 322 negative cases, the MLMs exhibited 100%\n                sensitivity (95% CI: 70.1–100%) and specificity of 90.9% (95% CI: 78.8–96.4%)\n                and 93.2% (95% CI: 81.8–97.7%) for the blood work (BW) and BW+MAT models,\n                respectively. These models surpassed traditional acute serologic screening methods,\n                providing accurate early screening for leptospirosis in dogs. (Use of\n                machine-learning algorithms to aid in the early detection of leptospirosis in dogs, K.\n                                                                                  \n                L. Reagan, et al. 2022)                                           \n           Patents                                                                \n             11. The researchers present a method for recommending pet food tailored to individual\n                pets, which involves receiving pet information from a user\'s device, generating pet\n                                                                                  \n                attributes from this data, determining a temperature classification based on these\n                attributes, and calculating a recipe score. This score, derived from both the\n                temperature classification and pet attributes, informs the selection of a suitable pet\n                food recommendation from a database. The recommendation is then communicated\n                to the user through a communication network, providing personalized diet\n                suggestions for their pet. (Methods for pet wellness platform US20220327598A1,\n                C. E. Bramson, et. al., 2022)                                     \n                                                                                  \n                                                                                  \n           How do you intend to solve the problem?                                \n                                                                                  \n           The proponent of the study plans to solve the problem by developing an Chatbot that will\n           gather the data from Veterinary clinic or Veterinarians in Santa Cruz, Laguna, who are\n           capable of handling various types of illnesses, symptoms, or behaviors of each kind of pet.\n           The data will also include medications or recommended actions for pet owners to improve\n                                                                                  \n           their pet’s condition.                                                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       6          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n                       Figure 1. Natural Language Processing Framework            \n                                                                                  \n           According to the framework proposed by Workativ Assistant, n. d., natural language\n           processing utilizes a series of backend algorithms and processes. This commences when a\n           user initiates a conversation by submitting a request. The AI solution then employs NLP to\n           recognize synonyms, canonical word forms, grammar, and slang, responding logically\n           using Natural Language Processing (NLP). Furthermore, Natural Language Understanding\n           (NLU) enables it to interpret the user\'s query while rectifying any linguistic flaws. It\n           maintains the context of the query, enabling AI solutions to engage with humans naturally.\n                                                                                  \n           Once the NLP has processed the user’s query, bots leverage Machine Learning (ML) to\n           learn and enhance their performance. They do so by analyzing patterns, inferences,\n           human-agent communications, and past interactions. ML assists the AI bot in learning from\n           each human interaction, leading to continual improvement in its responses to consumers\n           over time.                                                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                           Figure 2: Machine Learning Framework                   \n                                                                                  \n           According to the framework proposed by Phonyiam K. & Boonrawd P., (2017), Machine\n           Learning, defined as the utilization of computers to discern mathematical models from\n           input data for purposes such as prediction, explanation, and visualization, is divided into\n           two main types: Supervised Learning and Unsupervised Learning. Supervised Learning\n           involves learning from input data, divided into learning and test datasets, to validate or\n           determine the target output through techniques such as classification and regression, where\n           adjustments are made to minimize disparities between predicted and actual outcomes. On\n           the other hand, Unsupervised Learning entails learning from input data without labeled\n           outputs, classifying data based on inherent characteristics into clusters using methods such\n           as Clustering, Density Estimation, and Deep Learning. This framework provides a\n           foundational understanding of the diverse methodologies within the field of Machine\n           Learning.                                                              \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       7          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                             Figure 3: Conceptual Framework                       \n                                                                                  \n           The input stage of the ChatVet system comprises several key components. Pet owners\n           interact with the chatbot by inputting symptoms and behaviors exhibited by their pets,\n           along with relevant information about the pets themselves. Additionally, the system collects\n           data on the user\'s location to provide tailored recommendations and access to local\n           veterinary resources.                                                  \n                                                                                  \n           Within the processing stage, the collected data undergoes various preprocessing steps,\n           including data cleaning, tokenization, stop word removal, and stemming/lemmatization, to\n           ensure consistency and optimize analysis. The dataset is then split into training and test sets\n           for supervised learning. Utilizing supervised learning techniques such as classification and\n           regression, predictive models are developed to provide treatment recommendations,\n           educational information, and recommendations for veterinary clinics. This combination of\n           natural language processing (NLP) and machine learning (ML) facilitates the chatbot\'s\n           ability to interpret user inputs and generate appropriate responses.   \n                                                                                  \n                                                                                  \n           The output of the ChatVet system encompasses personalized recommendations and\n           information tailored to the pet owner\'s input. This includes treatment recommendations\n           based on predictive models trained on the input data, educational resources to empower pet\n           owners with knowledge about their pets\' health and behavior, and recommendations for\n           veterinary clinics in the Santa Cruz, Laguna area. Through the integration of NLP and ML\n           techniques within a chatbot interface, ChatVet aims to bridge the gap in access to veterinary\n           care, providing timely assistance and support to pet owners in their local community.\n                                                                                  \n           Target users / Beneficiaries:(Describe each Beneficiary)               \n                                                                                  \n           This study will greatly benefit pet owners by providing them with answers to their\n           questions regarding their pets\' symptoms or behavior. The chatbot will serve as a\n           convenient and reliable resource for pet owners to seek guidance and information about\n           their pets\' health, enhancing their ability to care for their furry companions effectively.\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       8          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n           Significance of study:                                                 \n                                                                                  \n           This study will also be beneficial to Santa Cruz, Laguna, by providing its residents with\n           accessible and reliable pet healthcare resources. With the implementation of the medical\n           chatbot, pet owners in the area can efficiently address their concerns about their pets\' health,\n           ultimately leading to better care and well-being for animals within the community.\n                                                                                  \n                                                                                  \n          References:                                                             \n               Huang, Duen-Huang, and Hao-En Chueh. “Chatbot Usage Intention Analysis:\n          Veterinary Consultation.” Journal of Innovation & Knowledge, vol. 6, no. 3, Nov. 2020,\n          https://doi.org/10.1016/j.jik.2020.09.002.                              \n               Tengco, N. (2023, November 9). How Much Does a Vet Consultation Cost in the\n          Philippines?                                             PetPal.        \n          https://petpal.asia/blog/vet-consultation-cost/#:~:text=What%20Is%20the%20Average%20Co\n                                                                                  \n          st                                                                      \n               Animals, N. R. C. (US) C. for the U. of the G. for the C. and U. of L. (2011).\n          Veterinary Care. Www.ncbi.nlm.nih.gov; National Academies Press (US).   \n          https://www.ncbi.nlm.nih.gov/books/NBK54052/#:~:text=Veterinary%20care%20is%20an%\n          20essential                                                             \n               Roca, R. Y., & McCarthy, R. J. (2019). Impact of Telemedicine on the Traditional\n          Veterinarian-Client-Patient Relationship. Topics in Companion Animal Medicine, 37,\n          100359. https://doi.org/10.1016/j.tcam.2019.100359                      \n               Im, J.-S., Kim, D.-Y., Cho, S.-M., & Yu, K.-A. (2018). Development of Dog’s Health\n          Care System Using Chatbot and Rule-based Expert System. Journal of Digital Contents\n          Society, 19(11), 2059–2066. https://doi.org/10.9728/dcs.2018.19.11.2059 \n               Tembhare, L., Khandekar, I., Thakur, V., Tigaonkar, M., & Narharshettiwar, I. (2023,\n          July 1). Virtual Conversational AI-Assistant Chatbot for Animal Healthcare: PET-O-CARE. |\n          Grenze International Journal of Engineering & Technology (GIJET) | EBSCOhost.\n          Openurl.ebsco.com.                                                      \n          https://openurl.ebsco.com/EPDB%3Agcd%3A8%3A19783864/detailv2?sid=ebsco%3Aplink\n                                                                                  \n          %3Ascholar&id=ebsco%3Agcd%3A171360361&crl=c                             \n               Huang, D.-H., & Chueh, H.-E. (2020a). An Analysis of Use Intention of Pet Disease\n          Consultation Chatbot. 2020 the 4th International Conference on E-Society, E-Education and\n          E-Technology. https://doi.org/10.1145/3421682.3421693                   \n               Farrell, S., Noble, & Noura Al Moubayed. (2023). Natural Language Processing for\n          Forecasting Mortality and Premature Death in Companion Animals. Research Square\n          (Research Square). https://doi.org/10.21203/rs.3.rs-3256060/v1          \n          Zhang, Y., Nie, A., Zehnder, A., Page, R. L., & Zou, J. (2019). VetTag: improving automated\n          veterinary diagnosis coding via large-scale language modeling. Npj Digital Medicine, 2(1).\n          https://doi.org/10.1038/s41746-019-0113-1                               \n                                                                                  \n          Framework:                                                              \n          https://workativ.com/conversational-ai-platform/conversational-ai-chatbot\n          https://www.researchgate.net/figure/Machine-Learning-Framework_fig1_317691821\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       9          \n                                                                                  \n                                                                                  \n                                                                                  \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A\\n. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         P\\nroject Title:  \\nChatVet: Enhancing Access to Veterinary Care for Pet Owners in Santa Cruz, Laguna\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              T\\nopic:  Natural  Language  Processing,  Machine  Learning,  Chatbot,  Pets,  Pet  Owners, \\nVeterinarian and Veterinary Clinic\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            P\\nroponent: LESLY-ANN B. VICTORIA\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    B\\n. Technical Description\n6  H\\n  P\\n  C\\n  A\\naving a pet is fun, but taking them to the vet can be challenging, especially in Santa Cruz, \\nLaguna.  This  project  aims  to  tackle  these  challenges  by  creating  ChatVet,  an  innovative \\nsolution using natural language processing and machine learning. ChatVet will provide pet \\nowners  with convenient access to veterinary consultation, guidance, and recommendations \\nvia a user-friendly chatbot interface accessible through web development. \\net  ownership  in Santa Cruz, Laguna, faces difficulties in accessing timely and affordable \\nveterinary  care,  much  like  other  places.  Pet  owners  often  struggle  to  balance  their  pets\' \\nhealth  needs  with  busy  schedules.  Additionally,  the  distance  to  veterinary  clinics  and \\nassociated  costs  worsens  the  situation.  To  address  these  challenges,  ChatVet  will  act as a \\nvirtual  veterinary  assistant,  providing  pet  owners  with  immediate  access  to  professional \\nguidance  and  recommendations.  By  using  advanced  technologies  like  natural  language \\nprocessing  and  artificial  intelligence,  ChatVet  will  provide a user-friendly platform where \\npet  owners  can  seek  advice  on  various  concerns,  from  general  pet  health  questions  to \\nspecific  medical  issues.  Through  this platform, pet owners can get timely support without \\nneeding  to  physically  visit  a  clinic,  saving  both  time  and  resources.  However,  if  severe \\nsymptoms of a pet are detected, ChatVet will automatically suggest nearby vet clinics. \\nhatVet  will  work  as an interactive chatbot accessible through a web-based platform. The \\nchatbot  will  use natural language processing algorithms to understand and respond to user \\ninquiries in real-time. By leveraging artificial intelligence, ChatVet will continuously learn \\nand improve its responses based on user interactions and feedback. \\nccording  to  a  study  by  Tengco  N.  (2023),  the  average  cost  of  vet  consultations  in  the \\nPhilippines  ranges  from  PHP  250  to  PHP  1,000.  These  consultations  typically  include  a \\ngeneral  examination  of  the  pet and a discussion of its health status. For many pet owners, \\nthe expense of immediate consultations with vets is a deterrent, particularly when the pet\'s \\ncondition  is  not  severe,  and  their  busy  schedules  make  it  difficult  to  visit  vet  clinics.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0\n0  A\\nMoreover,  pet  owners struggle to find nearby veterinary care, and while they may attempt \\nto search for symptoms on Google, there is no guarantee of accuracy. \\n  study  by  D.  Huang  and  H.  Chueh  (2021)  titled  \"Chatbot  Usage  Intention  Analysis: \\nVeterinary  Consultation\"  explores  the  application  of  artificial  intelligence  and  big  data \\ntechnologies to develop a chatbot prototype for veterinary consultations. This addresses the \\ngrowing  need  for \\ninnovative  solutions \\nin  pet  healthcare.  By  adapting  the  technology \\nacceptance  model, \\nthey \\nconstruct \\na \\nusage \\nintention  model \\nspecific \\nto \\nveterinary \\nconsultation  chatbots,  aiming  to  understand  pet  owners\'  inclinations toward utilizing such \\ntechnology.  Through  data  collection  via  Google  Forms  and  analysis  using  partial  least \\nsquares \\nstructural  equation  modeling, \\ntheir \\nfindings  underscore \\nthe \\nsignificance  of \\nperceived  accuracy,  completeness,  and  ease  of  use in enhancing user satisfaction with the \\nchatbot.  Moreover,  they  highlight  the pivotal role of perceived convenience in driving pet \\nowners\' intention to utilize the chatbot for veterinary consultations.\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    S\\ntatement of the Problem: \\nIn  Santa  Cruz,  Laguna,  pet  owners  face  challenges \\nin  accessing \\ntimely  and  reliable \\nveterinary care.  \\n \\n1.  How  can  acquired  datasets  be  processed  effectively  for  algorithm  development  in \\npet health support systems? \\n2.  How  can  technology  help  pet owners in addressing their pet’s health concerns and \\nneeds effectively? \\n3.  What  are  the  differences  in  accuracy  between  online  search  results  and  ChatVet\'s \\nrecommendations? \\n4.  How can ChatVet ensure accuracy, reliability, and effectiveness in delivering timely \\npet care information, tailored to Santa Cruz pet owners\' needs?\n2                                                                                                                                                                                                                                                                                                                                                                                                                                  O\\n  S\\nbjectives: General and Specific General Objective: \\nThe  main  objective  of  this  study is to design and develop a ChatVet to enhance access to \\nveterinary care for pet owners in Santa Cruz, Laguna. \\npecifically, it aims to: \\n \\n1.  Process  acquired  datasets  effectively  for  algorithm  development \\nin  pet  health \\nsupport \\nsystems, \\nensuring \\nthat \\nChatVet \\nprovides \\naccurate \\nand \\nreliable \\nrecommendations to pet owners. \\n2.  Utilize technology to effectively address pet owners\' pet health concerns and needs, \\nproviding accessible and timely guidance through the ChatVet platform. \\n3.  Determine  the  differences  in accuracy between online search results and ChatVet\'s \\nrecommendations, thereby evaluating the reliability of ChatVet as a resource for pet \\nowners.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         4.  Ensure  that  ChatVet  maintains  accuracy, reliability, and effectiveness in delivering \\ntimely \\npet \\ncare \\ninformation \\ntailored \\nto  Santa  Cruz  pet  owners\'  needs  by \\nincorporating user feedback and refining the chatbot\'s algorithms accordingly.\n1  H\\now did others solve the problem? \\n \\n1.  The  researchers describe their study on the application of artificial intelligence and \\nbig  data  technologies  to  develop  a  chatbot  prototype  for  veterinary  consultations. \\nTheir work addresses a growing need for innovative solutions in pet healthcare. By \\nadapting  the  technology  acceptance  model,  they construct a usage intention model \\nspecific  to veterinary consultation chatbots, aiming to grasp pet owners\' behavioral \\ninclinations  towards  utilizing  such technology. Through data collection via Google \\nForms  and  analysis  using  partial  least  squares  structural  equation  modeling,  their \\nfindings  underscore the significance of perceived accuracy, completeness, and ease \\nof use in enhancing user satisfaction with the chatbot. Moreover, they highlight the \\npivotal  role of perceived convenience in driving pet owners\' intention to utilize the \\nchatbot  for  veterinary  consultations.  (Chatbot  usage  intention  analysis:  Veterinary \\nconsultation, D. Huang and H. Chueh, 2021). \\n \\n2.  The  researchers  conducted  a  study  to  assess  the  impact of telemedicine on patient \\ncare  and \\nthe \\ntraditional  veterinarian-client-patient  relationship  (VCPR)  using  a \\nsingle \\ncommunication \\nplatform.  They \\ndeveloped \\na  multi-level \\nsurvey \\nand \\ndistributed  it  to  pet  owners  participating  in  a  popular  telemedicine  website  over a \\nperiod  of \\nfive  months.  The  survey  gathered  responses  from  398  participants, \\npredominantly  female  residing  in  urban  or  suburban  areas.  Findings  revealed  that \\nthe majority of respondents had an existing traditional care veterinarian (TCV), and \\nmost of them expressed willingness to utilize alternative methods of communication \\n(AMC)  if  provided  by their TCV. Those without a TCV often requested referral to \\none. Consultations frequently resulted in recommendations to follow up with a TCV, \\nwith  a  high \\nrate  of  compliance  among  owners.  Subsequent \\ninteractions  with \\ntraditional care veterinarians were perceived positively by owners, leading to better \\ncommunication  and  feeling  more \\ninformed.  Traditional  care  veterinarians  also \\ntended to agree with the telemedicine service recommendations. The study suggests \\nthat \\nincorporating \\ntelemedicine \\ninto \\nthe \\ntraditional  VCPR \\nis  generally  viewed \\nfavorably \\nby \\npet \\nowners. \\n(Impact \\nof \\nTelemedicine \\non \\nthe \\nTraditional \\nVeterinarian-Client-Patient Relationship, R. Y. Roca & R. J.  McCarthy, 2019). \\n \\n3.  The  researchers studied the increasing demand for pet-related services, particularly \\nin health and medical care, due to more families adopting companion animals. They \\nidentified  challenges  in  providing  these  services  outside  of  veterinary  hospitals, \\nemphasizing  the  need  for  expert  analysis  of  user  input  to  offer  tailored  solutions \\nbased  on  the  animal\'s  symptoms.  To  address  these  challenges,  they  proposed  an \\nexpert  system  capable  of  providing  specialized  knowledge  through  appropriate \\ninference  processes, \\nresponding \\nto  user-entered  symptoms \\nin  natural \\nlanguage \\nthrough  chat  mode.  They  highlighted  the  importance  of  user  feedback  to improve \\nthe  accuracy  of  diagnoses  and  enhance  the  effectiveness of information provision.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0\n0  dogs. (Machine-learning based prediction of Cushing’s syndrome in dogs attending \\nUK primary-care veterinary practice, I. Schofield, et al, 2021) \\n \\n10. The  researchers  developed  machine-learning  prediction  models  (MLMs)  utilizing \\nclinical variables from the first day of hospitalization to enhance early diagnosis of \\nleptospirosis  in  dogs.  Incorporating  patient  signalment  and  clinicopathologic  data, \\nwith or without Leptospira-specific serum antibodies obtained at patient intake, the \\nmodels  achieved  high  sensitivity  and  specificity.  Trained  with  data \\nfrom  91 \\nconfirmed  leptospirosis  cases  and  322  negative  cases,  the  MLMs  exhibited  100% \\nsensitivity  (95%  CI:  70.1–100%)  and  specificity  of  90.9%  (95%  CI:  78.8–96.4%) \\nand 93.2% (95% CI: 81.8–97.7%) for the blood work (BW) and BW+MAT models, \\nrespectively. These models surpassed traditional acute serologic screening methods, \\nproviding \\naccurate \\nearly \\nscreening \\nfor \\nleptospirosis \\nin \\ndogs. \\n(Use \\nof \\nmachine-learning algorithms to aid in the early detection of leptospirosis in dogs, K. \\nL. Reagan, et al. 2022) \\nPatents \\n11. The researchers present a method for recommending pet food tailored to individual \\npets,  which  involves receiving pet information from a user\'s device, generating pet \\nattributes  from  this  data,  determining  a  temperature  classification  based  on  these \\nattributes,  and  calculating  a \\nrecipe  score.  This  score,  derived  from  both \\nthe \\ntemperature  classification  and  pet  attributes, informs the selection of a suitable pet \\nfood recommendation from a database. The recommendation is then communicated \\nto \\nthe \\nuser \\nthrough \\na  communication  network,  providing  personalized  diet \\nsuggestions  for  their  pet.  (Methods  for  pet  wellness  platform  US20220327598A1, \\nC. E. Bramson, et. al., 2022)\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     H\\n  T\\n                       \\now do you intend to solve the problem? \\nhe  proponent  of  the study plans to solve the problem by developing an Chatbot that will \\ngather  the  data  from  Veterinary  clinic  or  Veterinarians  in  Santa  Cruz,  Laguna,  who  are \\ncapable of handling various types of illnesses, symptoms, or behaviors of each kind of pet. \\nThe data will also include medications or recommended actions for pet owners to improve \\ntheir pet’s condition.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0\n0  W\\n  T\\nFigure 3: Conceptual Framework \\n \\nThe  input  stage  of  the  ChatVet  system  comprises  several  key  components.  Pet  owners \\ninteract  with  the  chatbot  by  inputting  symptoms  and  behaviors  exhibited  by  their  pets, \\nalong with relevant information about the pets themselves. Additionally, the system collects \\ndata  on \\nthe  user\'s \\nlocation \\nto  provide \\ntailored  recommendations  and  access \\nto \\nlocal \\nveterinary resources. \\nithin  the  processing  stage,  the  collected  data  undergoes  various  preprocessing  steps, \\nincluding  data  cleaning, tokenization, stop word removal, and stemming/lemmatization, to \\nensure consistency and optimize analysis. The dataset is then split into training and test sets \\nfor supervised learning. Utilizing supervised learning techniques such as classification and \\nregression,  predictive  models  are  developed \\nto  provide \\ntreatment \\nrecommendations, \\neducational  information,  and  recommendations for veterinary clinics. This combination of \\nnatural  language  processing  (NLP)  and  machine  learning  (ML)  facilitates  the  chatbot\'s \\nability to interpret user inputs and generate appropriate responses. \\nhe  output  of \\nthe  ChatVet  system  encompasses  personalized \\nrecommendations  and \\ninformation  tailored  to  the  pet  owner\'s  input.  This  includes  treatment  recommendations \\nbased on predictive models trained on the input data, educational resources to empower pet \\nowners  with  knowledge  about  their  pets\'  health  and  behavior,  and  recommendations  for \\nveterinary clinics in the Santa Cruz, Laguna area. Through the integration of NLP and ML \\ntechniques within a chatbot interface, ChatVet aims to bridge the gap in access to veterinary \\ncare, providing timely assistance and support to pet owners in their local community.\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               T\\n  T\\narget users / Beneficiaries:(Describe each Beneficiary) \\nhis  study  will  greatly  benefit  pet  owners  by  providing \\nthem  with  answers  to  their \\nquestions \\nregarding \\ntheir  pets\'  symptoms  or  behavior.  The  chatbot  will  serve  as  a \\nconvenient  and  reliable  resource  for  pet  owners  to  seek  guidance  and  information  about \\ntheir pets\' health, enhancing their ability to care for their furry companions effectively.', 'tungkol sa pets or pet owner veterinarian or veterinary introduction especially by creating\n', '{\"status\": \"success\", \"speech_similarity\": 48.22, \"missed_keypoints\": [\"chatbot veterinary\", \"chatbot pets\", \"chatbot pet\", \"coding veterinary\", \"text veterinary\"], \"added_keypoints\": [\"veterinary introduction\", \"sa pets\", \"veterinarian veterinary\", \"veterinary\", \"pets pet\"], \"suggested_titles\": [\"Analysis of Chatbots in Research Context\", \"Analysis of Chatbot in Research Context\", \"Analysis of Veterinary in Research Context\"]}', 1);
INSERT INTO `files` (`id`, `user_email`, `file_name`, `file_path`, `upload_date`, `extracted_text`, `speech_transcript`, `analysis_json`, `archived`) VALUES
(104, 'mia.villarica@gmail.com', 'ChatVet_Concept_Paper.pdf', 'uploads/9a16f5a7f8c34cf39734c30969809832.pdf', '2025-04-25 03:51:42', '                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                    Concept Paper                                 \n                                                                                  \n           A. Basic Information                                                   \n                                                                                  \n                                                                                  \n           Project Title:                                                         \n           ChatVet: Enhancing Access to Veterinary Care for Pet Owners in Santa Cruz, Laguna\n                                                                                  \n                                                                                  \n           Topic: Natural Language Processing, Machine Learning, Chatbot, Pets, Pet Owners,\n           Veterinarian and Veterinary Clinic                                     \n                                                                                  \n                                                                                  \n                                                                                  \n           Proponent: LESLY-ANN B. VICTORIA                                       \n                                                                                  \n                                                                                  \n           B. Technical Description                                               \n                                                                                  \n                                                                                  \n           Having a pet is fun, but taking them to the vet can be challenging, especially in Santa Cruz,\n           Laguna. This project aims to tackle these challenges by creating ChatVet, an innovative\n           solution using natural language processing and machine learning. ChatVet will provide pet\n           owners with convenient access to veterinary consultation, guidance, and recommendations\n           via a user-friendly chatbot interface accessible through web development.\n                                                                                  \n           Pet ownership in Santa Cruz, Laguna, faces difficulties in accessing timely and affordable\n                                                                                  \n           veterinary care, much like other places. Pet owners often struggle to balance their pets\'\n           health needs with busy schedules. Additionally, the distance to veterinary clinics and\n           associated costs worsens the situation. To address these challenges, ChatVet will act as a\n           virtual veterinary assistant, providing pet owners with immediate access to professional\n           guidance and recommendations. By using advanced technologies like natural language\n           processing and artificial intelligence, ChatVet will provide a user-friendly platform where\n           pet owners can seek advice on various concerns, from general pet health questions to\n           specific medical issues. Through this platform, pet owners can get timely support without\n           needing to physically visit a clinic, saving both time and resources. However, if severe\n           symptoms of a pet are detected, ChatVet will automatically suggest nearby vet clinics.\n                                                                                  \n           ChatVet will work as an interactive chatbot accessible through a web-based platform. The\n           chatbot will use natural language processing algorithms to understand and respond to user\n           inquiries in real-time. By leveraging artificial intelligence, ChatVet will continuously learn\n           and improve its responses based on user interactions and feedback.     \n                                                                                  \n                                                                                  \n           According to a study by Tengco N. (2023), the average cost of vet consultations in the\n           Philippines ranges from PHP 250 to PHP 1,000. These consultations typically include a\n           general examination of the pet and a discussion of its health status. For many pet owners,\n           the expense of immediate consultations with vets is a deterrent, particularly when the pet\'s\n           condition is not severe, and their busy schedules make it difficult to visit vet clinics.\n                                                                                  \n                                                                       1          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n           Moreover, pet owners struggle to find nearby veterinary care, and while they may attempt\n           to search for symptoms on Google, there is no guarantee of accuracy.   \n                                                                                  \n           A study by D. Huang and H. Chueh (2021) titled \"Chatbot Usage Intention Analysis:\n           Veterinary Consultation\" explores the application of artificial intelligence and big data\n           technologies to develop a chatbot prototype for veterinary consultations. This addresses the\n           growing need for innovative solutions in pet healthcare. By adapting the technology\n           acceptance model, they construct a usage intention model specific to veterinary\n           consultation chatbots, aiming to understand pet owners\' inclinations toward utilizing such\n           technology. Through data collection via Google Forms and analysis using partial least\n           squares structural equation modeling, their findings underscore the significance of\n           perceived accuracy, completeness, and ease of use in enhancing user satisfaction with the\n           chatbot. Moreover, they highlight the pivotal role of perceived convenience in driving pet\n           owners\' intention to utilize the chatbot for veterinary consultations. \n                                                                                  \n                                                                                  \n                                                                                  \n           Statement of the Problem:                                              \n           In Santa Cruz, Laguna, pet owners face challenges in accessing timely and reliable\n           veterinary care.                                                       \n                                                                                  \n             1. How can acquired datasets be processed effectively for algorithm development in\n                pet health support systems?                                       \n             2. How can technology help pet owners in addressing their pet’s health concerns and\n                needs effectively?                                                \n             3. What are the differences in accuracy between online search results and ChatVet\'s\n                                                                                  \n                recommendations?                                                  \n             4. How can ChatVet ensure accuracy, reliability, and effectiveness in delivering timely\n                pet care information, tailored to Santa Cruz pet owners\' needs?   \n                                                                                  \n                                                                                  \n                                                                                  \n           Objectives: General and Specific General Objective:                    \n           The main objective of this study is to design and develop a ChatVet to enhance access to\n           veterinary care for pet owners in Santa Cruz, Laguna.                  \n                                                                                  \n           Specifically, it aims to:                                              \n                                                                                  \n             1. Process acquired datasets effectively for algorithm development in pet health\n                support systems, ensuring that ChatVet provides accurate and reliable\n                recommendations to pet owners.                                    \n                                                                                  \n             2. Utilize technology to effectively address pet owners\' pet health concerns and needs,\n                providing accessible and timely guidance through the ChatVet platform.\n             3. Determine the differences in accuracy between online search results and ChatVet\'s\n                recommendations, thereby evaluating the reliability of ChatVet as a resource for pet\n                owners.                                                           \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       2          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n             4. Ensure that ChatVet maintains accuracy, reliability, and effectiveness in delivering\n                timely pet care information tailored to Santa Cruz pet owners\' needs by\n                incorporating user feedback and refining the chatbot\'s algorithms accordingly.\n                                                                                  \n                                                                                  \n           How did others solve the problem?                                      \n                                                                                  \n             1. The researchers describe their study on the application of artificial intelligence and\n                big data technologies to develop a chatbot prototype for veterinary consultations.\n                Their work addresses a growing need for innovative solutions in pet healthcare. By\n                adapting the technology acceptance model, they construct a usage intention model\n                specific to veterinary consultation chatbots, aiming to grasp pet owners\' behavioral\n                inclinations towards utilizing such technology. Through data collection via Google\n                Forms and analysis using partial least squares structural equation modeling, their\n                findings underscore the significance of perceived accuracy, completeness, and ease\n                of use in enhancing user satisfaction with the chatbot. Moreover, they highlight the\n                pivotal role of perceived convenience in driving pet owners\' intention to utilize the\n                chatbot for veterinary consultations. (Chatbot usage intention analysis: Veterinary\n                                                                                  \n                consultation, D. Huang and H. Chueh, 2021).                       \n                                                                                  \n             2. The researchers conducted a study to assess the impact of telemedicine on patient\n                care and the traditional veterinarian-client-patient relationship (VCPR) using a\n                single communication platform. They developed a multi-level survey and\n                distributed it to pet owners participating in a popular telemedicine website over a\n                period of five months. The survey gathered responses from 398 participants,\n                predominantly female residing in urban or suburban areas. Findings revealed that\n                the majority of respondents had an existing traditional care veterinarian (TCV), and\n                most of them expressed willingness to utilize alternative methods of communication\n                (AMC) if provided by their TCV. Those without a TCV often requested referral to\n                one. Consultations frequently resulted in recommendations to follow up with a TCV,\n                with a high rate of compliance among owners. Subsequent interactions with\n                traditional care veterinarians were perceived positively by owners, leading to better\n                communication and feeling more informed. Traditional care veterinarians also\n                tended to agree with the telemedicine service recommendations. The study suggests\n                that incorporating telemedicine into the traditional VCPR is generally viewed\n                                                                                  \n                favorably by pet owners. (Impact of Telemedicine on the Traditional\n                Veterinarian-Client-Patient Relationship, R. Y. Roca & R. J. McCarthy, 2019).\n                                                                                  \n             3. The researchers studied the increasing demand for pet-related services, particularly\n                in health and medical care, due to more families adopting companion animals. They\n                identified challenges in providing these services outside of veterinary hospitals,\n                emphasizing the need for expert analysis of user input to offer tailored solutions\n                based on the animal\'s symptoms. To address these challenges, they proposed an\n                expert system capable of providing specialized knowledge through appropriate\n                inference processes, responding to user-entered symptoms in natural language\n                through chat mode. They highlighted the importance of user feedback to improve\n                the accuracy of diagnoses and enhance the effectiveness of information provision.\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       3          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                (Development of Dog’s Health Care System Using Chatbot and Rule-based Expert\n                System, J. S. Im, et al., 2018)                                   \n                                                                                  \n             4. The researchers propose the development of a smart computer software, known as a\n                chatbot, which employs AI and NLP to mimic human interaction efficiently. This\n                chatbot is tailored for the field of animal healthcare, aiming to treat animals well\n                and enhance overall efficiency. Functioning as a health chatbot, it analyzes\n                user-provided information in natural language to triage patients and guide them to\n                appropriate care, thereby offering dependable and secure assistance compared to\n                conventional internet searches for symptom origins. The primary objective is to\n                create a medical chatbot leveraging artificial intelligence to recognize medical\n                conditions and provide basic information preemptively, thus reducing healthcare\n                costs and improving access to medical knowledge. (Virtual Conversational\n                AI-Assistant Chatbot for Animal Healthcare: PET-O-CARE, L. Tembhare, et al.,\n                2023)                                                             \n                                                                                  \n                                                                                  \n             5. The researchers utilized the technology acceptance model and media\n                synchronization theory to formulate a use intention model tailored for a pet disease\n                consultation chatbot. Conducting a survey within an online pet community, they\n                gathered data and employed clustering analysis through data mining techniques for\n                examination. Findings revealed that younger individuals, particularly women, and\n                                                                                  \n                those with prior experience in transporting pets to veterinary clinics exhibited higher\n                satisfaction levels with chatbot-mediated pet disease consultations. Notably,\n                perceived convenience emerged as a crucial factor, suggesting a significant\n                opportunity for veterinary clinics to enhance their services through pet disease\n                consultation chatbots. This study lays a foundational framework for evaluating\n                intelligent medical solutions in the realm of pet health and care. (An Analysis of\n                Use Intention of Pet Disease Consultation Chatbot, D. H. Huang & H. E. Chueh,\n                2020)                                                             \n                                                                                  \n           Other Related Study (Natural Language Processing, Machine Learning)    \n                                                                                  \n             6. The researchers demonstrated the effectiveness of PetBERT-mortality, a novel\n                forecasting tool, in accurately identifying deceased companion animals with\n                                                                                  \n                precision and recall rates exceeding 98% and 97% respectively, utilizing a vast\n                dataset of over 8 million electronic health records from first-opinion veterinary\n                practices. This comprehensive analysis identified 92,548 deceased cats and dogs,\n                enabling the identification of 4,146 premature deaths and elucidating their causes\n                through syndromic ICD-11 disease coding. Additionally, the tool forecasted\n                expected mortality with up to 73% predictive accuracy over 12 months, leveraging\n                past consultation events and associated factors such as age, sex, and geographical\n                                                                                  \n                circumstances. The study highlighted the potential of PetBERT-mortality to promote\n                animal welfare and support veterinary clinicians in delivering optimal care by\n                enhancing mortality monitoring and facilitating end-of-life discussions during\n                consultations. (Natural Language Processing for Forecasting Mortality and\n                Premature Death in Companion Animals, F. S. Noble, & N. A. Moubayed, 2023).\n                                                                                  \n                                                                                  \n                                                                       4          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n             7. The researchers utilized natural language processing (NLP) techniques to analyze\n                clinical records of antimicrobial usage in companion animals from January 1, 2013,\n                to December 31, 2017. A total of 343,668 records for dogs and 109,719 records for\n                cats were examined, with NLP algorithms successfully extracting dose, duration of\n                therapy, and diagnosis for a subset of records. Skin disorders and traumatic injuries\n                were identified as the most common reasons for antimicrobial administration in\n                dogs and cats, respectively. However, only 39% of records for dogs and 37% for\n                                                                                  \n                cats had complete clinical data. Of those, 73% adhered to guideline\n                recommendations for dosage. The findings underscore the potential of NLP in\n                analyzing large datasets to understand antimicrobial usage patterns, but highlight the\n                importance of data completeness and the need for improved adherence to guideline\n                recommendations for dosage in veterinary practice. (Evaluating the dose, indication\n                and agreement with guidelines of antimicrobial use in companion animal practice\n                with natural language processing, B. Hur, et al., 2022)           \n                                                                                  \n                                                                                  \n             8. The researchers have developed a large-scale algorithm capable of automatically\n                predicting all 4577 standard veterinary diagnosis codes from free text, overcoming\n                the longstanding challenge posed by the lack of systematic coding in veterinary\n                records. Leveraging a curated dataset of over 100K expert-labeled veterinary notes\n                and over one million unlabeled notes, their algorithm, based on an adapted\n                                                                                  \n                Transformer architecture, demonstrates significant improvement through large-scale\n                language modeling via pretraining and supervised learning. They systematically\n                evaluate model performance and various baselines, particularly emphasizing\n                challenging settings with substantial domain shifts between hospitals. Moreover,\n                they introduce hierarchical training to address severe data imbalances for\n                fine-grained diagnosis and provide insights into the interpretability of deep\n                networks, showcasing the potential of unsupervised learning in clinical natural\n                                                                                  \n                language processing within veterinary medicine. (VetTag: improving automated\n                veterinary diagnosis coding via large-scale language modeling, Y. Zhang, et al.,\n                2019)                                                             \n                                                                                  \n             9. The researchers applied four machine-learning algorithms to predict future\n                diagnoses of Cushing’s syndrome in dogs using clinical data from the VetCompass\n                programme in the UK. Dogs suspected of having Cushing\'s syndrome were\n                                                                                  \n                analyzed based on their final reported diagnosis. Demographic and clinical features\n                available at the first suspicion of the syndrome were included in the models. The\n                machine-learning methods effectively classified the recorded Cushing’s syndrome\n                diagnoses, with the LASSO penalized regression model demonstrating the best\n                overall performance on the test set, achieving an AUROC of 0.85 (95% CI\n                0.80–0.89), sensitivity of 0.71, specificity of 0.82, PPV of 0.75, and NPV of 0.78.\n                These findings suggest that machine-learning methods could assist practicing\n                                                                                  \n                veterinarians in predicting future diagnoses, potentially improving clinical\n                decision-making and contributing to better diagnosis of Cushing’s syndrome in\n                                                                                  \n                                                                                  \n                                                                       5          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                dogs. (Machine-learning based prediction of Cushing’s syndrome in dogs attending\n                UK primary-care veterinary practice, I. Schofield, et al, 2021)   \n                                                                                  \n             10. The researchers developed machine-learning prediction models (MLMs) utilizing\n                clinical variables from the first day of hospitalization to enhance early diagnosis of\n                leptospirosis in dogs. Incorporating patient signalment and clinicopathologic data,\n                with or without Leptospira-specific serum antibodies obtained at patient intake, the\n                                                                                  \n                models achieved high sensitivity and specificity. Trained with data from 91\n                confirmed leptospirosis cases and 322 negative cases, the MLMs exhibited 100%\n                sensitivity (95% CI: 70.1–100%) and specificity of 90.9% (95% CI: 78.8–96.4%)\n                and 93.2% (95% CI: 81.8–97.7%) for the blood work (BW) and BW+MAT models,\n                respectively. These models surpassed traditional acute serologic screening methods,\n                providing accurate early screening for leptospirosis in dogs. (Use of\n                machine-learning algorithms to aid in the early detection of leptospirosis in dogs, K.\n                                                                                  \n                L. Reagan, et al. 2022)                                           \n           Patents                                                                \n             11. The researchers present a method for recommending pet food tailored to individual\n                pets, which involves receiving pet information from a user\'s device, generating pet\n                                                                                  \n                attributes from this data, determining a temperature classification based on these\n                attributes, and calculating a recipe score. This score, derived from both the\n                temperature classification and pet attributes, informs the selection of a suitable pet\n                food recommendation from a database. The recommendation is then communicated\n                to the user through a communication network, providing personalized diet\n                suggestions for their pet. (Methods for pet wellness platform US20220327598A1,\n                C. E. Bramson, et. al., 2022)                                     \n                                                                                  \n                                                                                  \n           How do you intend to solve the problem?                                \n                                                                                  \n           The proponent of the study plans to solve the problem by developing an Chatbot that will\n           gather the data from Veterinary clinic or Veterinarians in Santa Cruz, Laguna, who are\n           capable of handling various types of illnesses, symptoms, or behaviors of each kind of pet.\n           The data will also include medications or recommended actions for pet owners to improve\n                                                                                  \n           their pet’s condition.                                                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       6          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n                       Figure 1. Natural Language Processing Framework            \n                                                                                  \n           According to the framework proposed by Workativ Assistant, n. d., natural language\n           processing utilizes a series of backend algorithms and processes. This commences when a\n           user initiates a conversation by submitting a request. The AI solution then employs NLP to\n           recognize synonyms, canonical word forms, grammar, and slang, responding logically\n           using Natural Language Processing (NLP). Furthermore, Natural Language Understanding\n           (NLU) enables it to interpret the user\'s query while rectifying any linguistic flaws. It\n           maintains the context of the query, enabling AI solutions to engage with humans naturally.\n                                                                                  \n           Once the NLP has processed the user’s query, bots leverage Machine Learning (ML) to\n           learn and enhance their performance. They do so by analyzing patterns, inferences,\n           human-agent communications, and past interactions. ML assists the AI bot in learning from\n           each human interaction, leading to continual improvement in its responses to consumers\n           over time.                                                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                           Figure 2: Machine Learning Framework                   \n                                                                                  \n           According to the framework proposed by Phonyiam K. & Boonrawd P., (2017), Machine\n           Learning, defined as the utilization of computers to discern mathematical models from\n           input data for purposes such as prediction, explanation, and visualization, is divided into\n           two main types: Supervised Learning and Unsupervised Learning. Supervised Learning\n           involves learning from input data, divided into learning and test datasets, to validate or\n           determine the target output through techniques such as classification and regression, where\n           adjustments are made to minimize disparities between predicted and actual outcomes. On\n           the other hand, Unsupervised Learning entails learning from input data without labeled\n           outputs, classifying data based on inherent characteristics into clusters using methods such\n           as Clustering, Density Estimation, and Deep Learning. This framework provides a\n           foundational understanding of the diverse methodologies within the field of Machine\n           Learning.                                                              \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       7          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                             Figure 3: Conceptual Framework                       \n                                                                                  \n           The input stage of the ChatVet system comprises several key components. Pet owners\n           interact with the chatbot by inputting symptoms and behaviors exhibited by their pets,\n           along with relevant information about the pets themselves. Additionally, the system collects\n           data on the user\'s location to provide tailored recommendations and access to local\n           veterinary resources.                                                  \n                                                                                  \n           Within the processing stage, the collected data undergoes various preprocessing steps,\n           including data cleaning, tokenization, stop word removal, and stemming/lemmatization, to\n           ensure consistency and optimize analysis. The dataset is then split into training and test sets\n           for supervised learning. Utilizing supervised learning techniques such as classification and\n           regression, predictive models are developed to provide treatment recommendations,\n           educational information, and recommendations for veterinary clinics. This combination of\n           natural language processing (NLP) and machine learning (ML) facilitates the chatbot\'s\n           ability to interpret user inputs and generate appropriate responses.   \n                                                                                  \n                                                                                  \n           The output of the ChatVet system encompasses personalized recommendations and\n           information tailored to the pet owner\'s input. This includes treatment recommendations\n           based on predictive models trained on the input data, educational resources to empower pet\n           owners with knowledge about their pets\' health and behavior, and recommendations for\n           veterinary clinics in the Santa Cruz, Laguna area. Through the integration of NLP and ML\n           techniques within a chatbot interface, ChatVet aims to bridge the gap in access to veterinary\n           care, providing timely assistance and support to pet owners in their local community.\n                                                                                  \n           Target users / Beneficiaries:(Describe each Beneficiary)               \n                                                                                  \n           This study will greatly benefit pet owners by providing them with answers to their\n           questions regarding their pets\' symptoms or behavior. The chatbot will serve as a\n           convenient and reliable resource for pet owners to seek guidance and information about\n           their pets\' health, enhancing their ability to care for their furry companions effectively.\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       8          \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                Republic of the Philippines                       \n                        Laguna  State Polytechnic University                      \n                                   Province of Laguna                             \n                                                                                  \n                                                                                  \n           Significance of study:                                                 \n                                                                                  \n           This study will also be beneficial to Santa Cruz, Laguna, by providing its residents with\n           accessible and reliable pet healthcare resources. With the implementation of the medical\n           chatbot, pet owners in the area can efficiently address their concerns about their pets\' health,\n           ultimately leading to better care and well-being for animals within the community.\n                                                                                  \n                                                                                  \n          References:                                                             \n               Huang, Duen-Huang, and Hao-En Chueh. “Chatbot Usage Intention Analysis:\n          Veterinary Consultation.” Journal of Innovation & Knowledge, vol. 6, no. 3, Nov. 2020,\n          https://doi.org/10.1016/j.jik.2020.09.002.                              \n               Tengco, N. (2023, November 9). How Much Does a Vet Consultation Cost in the\n          Philippines?                                             PetPal.        \n          https://petpal.asia/blog/vet-consultation-cost/#:~:text=What%20Is%20the%20Average%20Co\n                                                                                  \n          st                                                                      \n               Animals, N. R. C. (US) C. for the U. of the G. for the C. and U. of L. (2011).\n          Veterinary Care. Www.ncbi.nlm.nih.gov; National Academies Press (US).   \n          https://www.ncbi.nlm.nih.gov/books/NBK54052/#:~:text=Veterinary%20care%20is%20an%\n          20essential                                                             \n               Roca, R. Y., & McCarthy, R. J. (2019). Impact of Telemedicine on the Traditional\n          Veterinarian-Client-Patient Relationship. Topics in Companion Animal Medicine, 37,\n          100359. https://doi.org/10.1016/j.tcam.2019.100359                      \n               Im, J.-S., Kim, D.-Y., Cho, S.-M., & Yu, K.-A. (2018). Development of Dog’s Health\n          Care System Using Chatbot and Rule-based Expert System. Journal of Digital Contents\n          Society, 19(11), 2059–2066. https://doi.org/10.9728/dcs.2018.19.11.2059 \n               Tembhare, L., Khandekar, I., Thakur, V., Tigaonkar, M., & Narharshettiwar, I. (2023,\n          July 1). Virtual Conversational AI-Assistant Chatbot for Animal Healthcare: PET-O-CARE. |\n          Grenze International Journal of Engineering & Technology (GIJET) | EBSCOhost.\n          Openurl.ebsco.com.                                                      \n          https://openurl.ebsco.com/EPDB%3Agcd%3A8%3A19783864/detailv2?sid=ebsco%3Aplink\n                                                                                  \n          %3Ascholar&id=ebsco%3Agcd%3A171360361&crl=c                             \n               Huang, D.-H., & Chueh, H.-E. (2020a). An Analysis of Use Intention of Pet Disease\n          Consultation Chatbot. 2020 the 4th International Conference on E-Society, E-Education and\n          E-Technology. https://doi.org/10.1145/3421682.3421693                   \n               Farrell, S., Noble, & Noura Al Moubayed. (2023). Natural Language Processing for\n          Forecasting Mortality and Premature Death in Companion Animals. Research Square\n          (Research Square). https://doi.org/10.21203/rs.3.rs-3256060/v1          \n          Zhang, Y., Nie, A., Zehnder, A., Page, R. L., & Zou, J. (2019). VetTag: improving automated\n          veterinary diagnosis coding via large-scale language modeling. Npj Digital Medicine, 2(1).\n          https://doi.org/10.1038/s41746-019-0113-1                               \n                                                                                  \n          Framework:                                                              \n          https://workativ.com/conversational-ai-platform/conversational-ai-chatbot\n          https://www.researchgate.net/figure/Machine-Learning-Framework_fig1_317691821\n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                       9          \n                                                                                  \n                                                                                  \n                                                                                  \n\n\nTables:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Concept Paper\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A\\n. Basic Information\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         P\\nroject Title:  \\nChatVet: Enhancing Access to Veterinary Care for Pet Owners in Santa Cruz, Laguna\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              T\\nopic:  Natural  Language  Processing,  Machine  Learning,  Chatbot,  Pets,  Pet  Owners, \\nVeterinarian and Veterinary Clinic\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            P\\nroponent: LESLY-ANN B. VICTORIA\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    B\\n. Technical Description\n6  H\\n  P\\n  C\\n  A\\naving a pet is fun, but taking them to the vet can be challenging, especially in Santa Cruz, \\nLaguna.  This  project  aims  to  tackle  these  challenges  by  creating  ChatVet,  an  innovative \\nsolution using natural language processing and machine learning. ChatVet will provide pet \\nowners  with convenient access to veterinary consultation, guidance, and recommendations \\nvia a user-friendly chatbot interface accessible through web development. \\net  ownership  in Santa Cruz, Laguna, faces difficulties in accessing timely and affordable \\nveterinary  care,  much  like  other  places.  Pet  owners  often  struggle  to  balance  their  pets\' \\nhealth  needs  with  busy  schedules.  Additionally,  the  distance  to  veterinary  clinics  and \\nassociated  costs  worsens  the  situation.  To  address  these  challenges,  ChatVet  will  act as a \\nvirtual  veterinary  assistant,  providing  pet  owners  with  immediate  access  to  professional \\nguidance  and  recommendations.  By  using  advanced  technologies  like  natural  language \\nprocessing  and  artificial  intelligence,  ChatVet  will  provide a user-friendly platform where \\npet  owners  can  seek  advice  on  various  concerns,  from  general  pet  health  questions  to \\nspecific  medical  issues.  Through  this platform, pet owners can get timely support without \\nneeding  to  physically  visit  a  clinic,  saving  both  time  and  resources.  However,  if  severe \\nsymptoms of a pet are detected, ChatVet will automatically suggest nearby vet clinics. \\nhatVet  will  work  as an interactive chatbot accessible through a web-based platform. The \\nchatbot  will  use natural language processing algorithms to understand and respond to user \\ninquiries in real-time. By leveraging artificial intelligence, ChatVet will continuously learn \\nand improve its responses based on user interactions and feedback. \\nccording  to  a  study  by  Tengco  N.  (2023),  the  average  cost  of  vet  consultations  in  the \\nPhilippines  ranges  from  PHP  250  to  PHP  1,000.  These  consultations  typically  include  a \\ngeneral  examination  of  the  pet and a discussion of its health status. For many pet owners, \\nthe expense of immediate consultations with vets is a deterrent, particularly when the pet\'s \\ncondition  is  not  severe,  and  their  busy  schedules  make  it  difficult  to  visit  vet  clinics.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0\n0  A\\nMoreover,  pet  owners struggle to find nearby veterinary care, and while they may attempt \\nto search for symptoms on Google, there is no guarantee of accuracy. \\n  study  by  D.  Huang  and  H.  Chueh  (2021)  titled  \"Chatbot  Usage  Intention  Analysis: \\nVeterinary  Consultation\"  explores  the  application  of  artificial  intelligence  and  big  data \\ntechnologies to develop a chatbot prototype for veterinary consultations. This addresses the \\ngrowing  need  for \\ninnovative  solutions \\nin  pet  healthcare.  By  adapting  the  technology \\nacceptance  model, \\nthey \\nconstruct \\na \\nusage \\nintention  model \\nspecific \\nto \\nveterinary \\nconsultation  chatbots,  aiming  to  understand  pet  owners\'  inclinations toward utilizing such \\ntechnology.  Through  data  collection  via  Google  Forms  and  analysis  using  partial  least \\nsquares \\nstructural  equation  modeling, \\ntheir \\nfindings  underscore \\nthe \\nsignificance  of \\nperceived  accuracy,  completeness,  and  ease  of  use in enhancing user satisfaction with the \\nchatbot.  Moreover,  they  highlight  the pivotal role of perceived convenience in driving pet \\nowners\' intention to utilize the chatbot for veterinary consultations.\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    S\\ntatement of the Problem: \\nIn  Santa  Cruz,  Laguna,  pet  owners  face  challenges \\nin  accessing \\ntimely  and  reliable \\nveterinary care.  \\n \\n1.  How  can  acquired  datasets  be  processed  effectively  for  algorithm  development  in \\npet health support systems? \\n2.  How  can  technology  help  pet owners in addressing their pet’s health concerns and \\nneeds effectively? \\n3.  What  are  the  differences  in  accuracy  between  online  search  results  and  ChatVet\'s \\nrecommendations? \\n4.  How can ChatVet ensure accuracy, reliability, and effectiveness in delivering timely \\npet care information, tailored to Santa Cruz pet owners\' needs?\n2                                                                                                                                                                                                                                                                                                                                                                                                                                  O\\n  S\\nbjectives: General and Specific General Objective: \\nThe  main  objective  of  this  study is to design and develop a ChatVet to enhance access to \\nveterinary care for pet owners in Santa Cruz, Laguna. \\npecifically, it aims to: \\n \\n1.  Process  acquired  datasets  effectively  for  algorithm  development \\nin  pet  health \\nsupport \\nsystems, \\nensuring \\nthat \\nChatVet \\nprovides \\naccurate \\nand \\nreliable \\nrecommendations to pet owners. \\n2.  Utilize technology to effectively address pet owners\' pet health concerns and needs, \\nproviding accessible and timely guidance through the ChatVet platform. \\n3.  Determine  the  differences  in accuracy between online search results and ChatVet\'s \\nrecommendations, thereby evaluating the reliability of ChatVet as a resource for pet \\nowners.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         4.  Ensure  that  ChatVet  maintains  accuracy, reliability, and effectiveness in delivering \\ntimely \\npet \\ncare \\ninformation \\ntailored \\nto  Santa  Cruz  pet  owners\'  needs  by \\nincorporating user feedback and refining the chatbot\'s algorithms accordingly.\n1  H\\now did others solve the problem? \\n \\n1.  The  researchers describe their study on the application of artificial intelligence and \\nbig  data  technologies  to  develop  a  chatbot  prototype  for  veterinary  consultations. \\nTheir work addresses a growing need for innovative solutions in pet healthcare. By \\nadapting  the  technology  acceptance  model,  they construct a usage intention model \\nspecific  to veterinary consultation chatbots, aiming to grasp pet owners\' behavioral \\ninclinations  towards  utilizing  such technology. Through data collection via Google \\nForms  and  analysis  using  partial  least  squares  structural  equation  modeling,  their \\nfindings  underscore the significance of perceived accuracy, completeness, and ease \\nof use in enhancing user satisfaction with the chatbot. Moreover, they highlight the \\npivotal  role of perceived convenience in driving pet owners\' intention to utilize the \\nchatbot  for  veterinary  consultations.  (Chatbot  usage  intention  analysis:  Veterinary \\nconsultation, D. Huang and H. Chueh, 2021). \\n \\n2.  The  researchers  conducted  a  study  to  assess  the  impact of telemedicine on patient \\ncare  and \\nthe \\ntraditional  veterinarian-client-patient  relationship  (VCPR)  using  a \\nsingle \\ncommunication \\nplatform.  They \\ndeveloped \\na  multi-level \\nsurvey \\nand \\ndistributed  it  to  pet  owners  participating  in  a  popular  telemedicine  website  over a \\nperiod  of \\nfive  months.  The  survey  gathered  responses  from  398  participants, \\npredominantly  female  residing  in  urban  or  suburban  areas.  Findings  revealed  that \\nthe majority of respondents had an existing traditional care veterinarian (TCV), and \\nmost of them expressed willingness to utilize alternative methods of communication \\n(AMC)  if  provided  by their TCV. Those without a TCV often requested referral to \\none. Consultations frequently resulted in recommendations to follow up with a TCV, \\nwith  a  high \\nrate  of  compliance  among  owners.  Subsequent \\ninteractions  with \\ntraditional care veterinarians were perceived positively by owners, leading to better \\ncommunication  and  feeling  more \\ninformed.  Traditional  care  veterinarians  also \\ntended to agree with the telemedicine service recommendations. The study suggests \\nthat \\nincorporating \\ntelemedicine \\ninto \\nthe \\ntraditional  VCPR \\nis  generally  viewed \\nfavorably \\nby \\npet \\nowners. \\n(Impact \\nof \\nTelemedicine \\non \\nthe \\nTraditional \\nVeterinarian-Client-Patient Relationship, R. Y. Roca & R. J.  McCarthy, 2019). \\n \\n3.  The  researchers studied the increasing demand for pet-related services, particularly \\nin health and medical care, due to more families adopting companion animals. They \\nidentified  challenges  in  providing  these  services  outside  of  veterinary  hospitals, \\nemphasizing  the  need  for  expert  analysis  of  user  input  to  offer  tailored  solutions \\nbased  on  the  animal\'s  symptoms.  To  address  these  challenges,  they  proposed  an \\nexpert  system  capable  of  providing  specialized  knowledge  through  appropriate \\ninference  processes, \\nresponding \\nto  user-entered  symptoms \\nin  natural \\nlanguage \\nthrough  chat  mode.  They  highlighted  the  importance  of  user  feedback  to improve \\nthe  accuracy  of  diagnoses  and  enhance  the  effectiveness of information provision.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0\n0  dogs. (Machine-learning based prediction of Cushing’s syndrome in dogs attending \\nUK primary-care veterinary practice, I. Schofield, et al, 2021) \\n \\n10. The  researchers  developed  machine-learning  prediction  models  (MLMs)  utilizing \\nclinical variables from the first day of hospitalization to enhance early diagnosis of \\nleptospirosis  in  dogs.  Incorporating  patient  signalment  and  clinicopathologic  data, \\nwith or without Leptospira-specific serum antibodies obtained at patient intake, the \\nmodels  achieved  high  sensitivity  and  specificity.  Trained  with  data \\nfrom  91 \\nconfirmed  leptospirosis  cases  and  322  negative  cases,  the  MLMs  exhibited  100% \\nsensitivity  (95%  CI:  70.1–100%)  and  specificity  of  90.9%  (95%  CI:  78.8–96.4%) \\nand 93.2% (95% CI: 81.8–97.7%) for the blood work (BW) and BW+MAT models, \\nrespectively. These models surpassed traditional acute serologic screening methods, \\nproviding \\naccurate \\nearly \\nscreening \\nfor \\nleptospirosis \\nin \\ndogs. \\n(Use \\nof \\nmachine-learning algorithms to aid in the early detection of leptospirosis in dogs, K. \\nL. Reagan, et al. 2022) \\nPatents \\n11. The researchers present a method for recommending pet food tailored to individual \\npets,  which  involves receiving pet information from a user\'s device, generating pet \\nattributes  from  this  data,  determining  a  temperature  classification  based  on  these \\nattributes,  and  calculating  a \\nrecipe  score.  This  score,  derived  from  both \\nthe \\ntemperature  classification  and  pet  attributes, informs the selection of a suitable pet \\nfood recommendation from a database. The recommendation is then communicated \\nto \\nthe \\nuser \\nthrough \\na  communication  network,  providing  personalized  diet \\nsuggestions  for  their  pet.  (Methods  for  pet  wellness  platform  US20220327598A1, \\nC. E. Bramson, et. al., 2022)\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     H\\n  T\\n                       \\now do you intend to solve the problem? \\nhe  proponent  of  the study plans to solve the problem by developing an Chatbot that will \\ngather  the  data  from  Veterinary  clinic  or  Veterinarians  in  Santa  Cruz,  Laguna,  who  are \\ncapable of handling various types of illnesses, symptoms, or behaviors of each kind of pet. \\nThe data will also include medications or recommended actions for pet owners to improve \\ntheir pet’s condition.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0\n0  W\\n  T\\nFigure 3: Conceptual Framework \\n \\nThe  input  stage  of  the  ChatVet  system  comprises  several  key  components.  Pet  owners \\ninteract  with  the  chatbot  by  inputting  symptoms  and  behaviors  exhibited  by  their  pets, \\nalong with relevant information about the pets themselves. Additionally, the system collects \\ndata  on \\nthe  user\'s \\nlocation \\nto  provide \\ntailored  recommendations  and  access \\nto \\nlocal \\nveterinary resources. \\nithin  the  processing  stage,  the  collected  data  undergoes  various  preprocessing  steps, \\nincluding  data  cleaning, tokenization, stop word removal, and stemming/lemmatization, to \\nensure consistency and optimize analysis. The dataset is then split into training and test sets \\nfor supervised learning. Utilizing supervised learning techniques such as classification and \\nregression,  predictive  models  are  developed \\nto  provide \\ntreatment \\nrecommendations, \\neducational  information,  and  recommendations for veterinary clinics. This combination of \\nnatural  language  processing  (NLP)  and  machine  learning  (ML)  facilitates  the  chatbot\'s \\nability to interpret user inputs and generate appropriate responses. \\nhe  output  of \\nthe  ChatVet  system  encompasses  personalized \\nrecommendations  and \\ninformation  tailored  to  the  pet  owner\'s  input.  This  includes  treatment  recommendations \\nbased on predictive models trained on the input data, educational resources to empower pet \\nowners  with  knowledge  about  their  pets\'  health  and  behavior,  and  recommendations  for \\nveterinary clinics in the Santa Cruz, Laguna area. Through the integration of NLP and ML \\ntechniques within a chatbot interface, ChatVet aims to bridge the gap in access to veterinary \\ncare, providing timely assistance and support to pet owners in their local community.\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               T\\n  T\\narget users / Beneficiaries:(Describe each Beneficiary) \\nhis  study  will  greatly  benefit  pet  owners  by  providing \\nthem  with  answers  to  their \\nquestions \\nregarding \\ntheir  pets\'  symptoms  or  behavior.  The  chatbot  will  serve  as  a \\nconvenient  and  reliable  resource  for  pet  owners  to  seek  guidance  and  information  about \\ntheir pets\' health, enhancing their ability to care for their furry companions effectively.', '', '', 0);

-- --------------------------------------------------------

--
-- Table structure for table `registration`
--

CREATE TABLE `registration` (
  `id` int(11) NOT NULL,
  `email` varchar(255) NOT NULL,
  `password` varchar(255) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `registration`
--

INSERT INTO `registration` (`id`, `email`, `password`) VALUES
(29, 'mia.villarica@gmail.com', 'asdfghjk12!'),
(31, 'janeeeeverdad@gmail.com', ' Janeverdad01!');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `files`
--
ALTER TABLE `files`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `registration`
--
ALTER TABLE `registration`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `files`
--
ALTER TABLE `files`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=105;

--
-- AUTO_INCREMENT for table `registration`
--
ALTER TABLE `registration`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=32;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
